{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Aziz ERDEN - 12.02.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proje [linki](https://www.kaggle.com/competitions/spaceship-titanic/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:31.067009Z",
     "iopub.status.busy": "2023-02-12T00:18:31.066586Z",
     "iopub.status.idle": "2023-02-12T00:18:31.077438Z",
     "shell.execute_reply": "2023-02-12T00:18:31.076531Z",
     "shell.execute_reply.started": "2023-02-12T00:18:31.066973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/spaceship-titanic/sample_submission.csv\n",
      "/kaggle/input/spaceship-titanic/train.csv\n",
      "/kaggle/input/spaceship-titanic/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:31.080587Z",
     "iopub.status.busy": "2023-02-12T00:18:31.079822Z",
     "iopub.status.idle": "2023-02-12T00:18:31.105307Z",
     "shell.execute_reply": "2023-02-12T00:18:31.103681Z",
     "shell.execute_reply.started": "2023-02-12T00:18:31.080538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>9266_02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>9269_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>9271_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>9273_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>9277_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Transported\n",
       "0        0013_01        False\n",
       "1        0018_01        False\n",
       "2        0019_01        False\n",
       "3        0021_01        False\n",
       "4        0023_01        False\n",
       "...          ...          ...\n",
       "4272     9266_02        False\n",
       "4273     9269_01        False\n",
       "4274     9271_01        False\n",
       "4275     9273_01        False\n",
       "4276     9277_01        False\n",
       "\n",
       "[4277 rows x 2 columns]"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv(\"/kaggle/input/spaceship-titanic/sample_submission.csv\")\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:31.107836Z",
     "iopub.status.busy": "2023-02-12T00:18:31.107359Z",
     "iopub.status.idle": "2023-02-12T00:18:31.112943Z",
     "shell.execute_reply": "2023-02-12T00:18:31.111965Z",
     "shell.execute_reply.started": "2023-02-12T00:18:31.107788Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:31.116006Z",
     "iopub.status.busy": "2023-02-12T00:18:31.115384Z",
     "iopub.status.idle": "2023-02-12T00:18:31.175661Z",
     "shell.execute_reply": "2023-02-12T00:18:31.174585Z",
     "shell.execute_reply.started": "2023-02-12T00:18:31.115964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/98/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravior Noxnuther</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1499/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurta Mondalley</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1500/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fayey Connon</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>Celeon Hontichre</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Propsh Hontichre</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n",
       "1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n",
       "2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n",
       "3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n",
       "4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n",
       "...          ...        ...       ...       ...            ...   ...    ...   \n",
       "8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n",
       "8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n",
       "8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
       "8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n",
       "8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1           109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4           303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "...           ...        ...           ...     ...     ...                ...   \n",
       "8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n",
       "8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n",
       "8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n",
       "8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n",
       "8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n",
       "\n",
       "      Transported  \n",
       "0           False  \n",
       "1            True  \n",
       "2           False  \n",
       "3           False  \n",
       "4            True  \n",
       "...           ...  \n",
       "8688        False  \n",
       "8689        False  \n",
       "8690         True  \n",
       "8691        False  \n",
       "8692         True  \n",
       "\n",
       "[8693 rows x 14 columns]"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\")\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:31.178416Z",
     "iopub.status.busy": "2023-02-12T00:18:31.177572Z",
     "iopub.status.idle": "2023-02-12T00:18:31.224770Z",
     "shell.execute_reply": "2023-02-12T00:18:31.223520Z",
     "shell.execute_reply.started": "2023-02-12T00:18:31.178369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nelly Carsoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/4/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lerome Peckers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>C/0/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sabih Unhearfus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>C/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>Meratz Caltilter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/5/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Brence Harperez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>9266_02</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1496/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>34.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jeron Peter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>9269_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>42.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>Matty Scheron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>9271_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>D/296/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jayrin Pore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>9273_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>D/297/P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>Kitakan Conale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>9277_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1498/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>43.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lilace Leonzaley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "0        0013_01      Earth      True     G/3/S    TRAPPIST-1e  27.0  False   \n",
       "1        0018_01      Earth     False     F/4/S    TRAPPIST-1e  19.0  False   \n",
       "2        0019_01     Europa      True     C/0/S    55 Cancri e  31.0  False   \n",
       "3        0021_01     Europa     False     C/1/S    TRAPPIST-1e  38.0  False   \n",
       "4        0023_01      Earth     False     F/5/S    TRAPPIST-1e  20.0  False   \n",
       "...          ...        ...       ...       ...            ...   ...    ...   \n",
       "4272     9266_02      Earth      True  G/1496/S    TRAPPIST-1e  34.0  False   \n",
       "4273     9269_01      Earth     False       NaN    TRAPPIST-1e  42.0  False   \n",
       "4274     9271_01       Mars      True   D/296/P    55 Cancri e   NaN  False   \n",
       "4275     9273_01     Europa     False   D/297/P            NaN   NaN  False   \n",
       "4276     9277_01      Earth      True  G/1498/S  PSO J318.5-22  43.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck              Name  \n",
       "0             0.0        0.0           0.0     0.0     0.0   Nelly Carsoning  \n",
       "1             0.0        9.0           0.0  2823.0     0.0    Lerome Peckers  \n",
       "2             0.0        0.0           0.0     0.0     0.0   Sabih Unhearfus  \n",
       "3             0.0     6652.0           0.0   181.0   585.0  Meratz Caltilter  \n",
       "4            10.0        0.0         635.0     0.0     0.0   Brence Harperez  \n",
       "...           ...        ...           ...     ...     ...               ...  \n",
       "4272          0.0        0.0           0.0     0.0     0.0       Jeron Peter  \n",
       "4273          0.0      847.0          17.0    10.0   144.0     Matty Scheron  \n",
       "4274          0.0        0.0           0.0     0.0     0.0       Jayrin Pore  \n",
       "4275          0.0     2680.0           0.0     0.0   523.0    Kitakan Conale  \n",
       "4276          0.0        0.0           0.0     0.0     0.0  Lilace Leonzaley  \n",
       "\n",
       "[4277 rows x 13 columns]"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = pd.read_csv(\"/kaggle/input/spaceship-titanic/test.csv\")\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:31.227313Z",
     "iopub.status.busy": "2023-02-12T00:18:31.226795Z",
     "iopub.status.idle": "2023-02-12T00:18:31.240495Z",
     "shell.execute_reply": "2023-02-12T00:18:31.238922Z",
     "shell.execute_reply.started": "2023-02-12T00:18:31.227245Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([x_train, x_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:31.243015Z",
     "iopub.status.busy": "2023-02-12T00:18:31.242593Z",
     "iopub.status.idle": "2023-02-12T00:18:31.250422Z",
     "shell.execute_reply": "2023-02-12T00:18:31.249456Z",
     "shell.execute_reply.started": "2023-02-12T00:18:31.242979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12970, 14)"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:31.252561Z",
     "iopub.status.busy": "2023-02-12T00:18:31.251947Z",
     "iopub.status.idle": "2023-02-12T00:18:31.276101Z",
     "shell.execute_reply": "2023-02-12T00:18:31.274797Z",
     "shell.execute_reply.started": "2023-02-12T00:18:31.252523Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId        0\n",
       "HomePlanet       288\n",
       "CryoSleep        310\n",
       "Cabin            299\n",
       "Destination      274\n",
       "Age              270\n",
       "VIP              296\n",
       "RoomService      263\n",
       "FoodCourt        289\n",
       "ShoppingMall     306\n",
       "Spa              284\n",
       "VRDeck           268\n",
       "Name             294\n",
       "Transported     4277\n",
       "dtype: int64"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:31.282145Z",
     "iopub.status.busy": "2023-02-12T00:18:31.281631Z",
     "iopub.status.idle": "2023-02-12T00:18:31.291665Z",
     "shell.execute_reply": "2023-02-12T00:18:31.290514Z",
     "shell.execute_reply.started": "2023-02-12T00:18:31.282094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    12401\n",
       "True       273\n",
       "Name: VIP, dtype: int64"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"VIP\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:31.293976Z",
     "iopub.status.busy": "2023-02-12T00:18:31.293536Z",
     "iopub.status.idle": "2023-02-12T00:18:31.305949Z",
     "shell.execute_reply": "2023-02-12T00:18:31.304990Z",
     "shell.execute_reply.started": "2023-02-12T00:18:31.293933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRAPPIST-1e      8871\n",
       "55 Cancri e      2641\n",
       "PSO J318.5-22    1184\n",
       "Name: Destination, dtype: int64"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Destination\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:31.308107Z",
     "iopub.status.busy": "2023-02-12T00:18:31.307599Z",
     "iopub.status.idle": "2023-02-12T00:18:31.322303Z",
     "shell.execute_reply": "2023-02-12T00:18:31.321103Z",
     "shell.execute_reply.started": "2023-02-12T00:18:31.308063Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"VIP\"][df[\"VIP\"].isnull() == True] = df[\"VIP\"].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:31.324871Z",
     "iopub.status.busy": "2023-02-12T00:18:31.323899Z",
     "iopub.status.idle": "2023-02-12T00:18:31.341510Z",
     "shell.execute_reply": "2023-02-12T00:18:31.340333Z",
     "shell.execute_reply.started": "2023-02-12T00:18:31.324821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G/734/S     8\n",
       "G/160/P     8\n",
       "D/176/S     7\n",
       "G/1476/S    7\n",
       "B/201/P     7\n",
       "           ..\n",
       "E/317/P     1\n",
       "F/1039/P    1\n",
       "F/1038/P    1\n",
       "C/158/P     1\n",
       "G/1498/S    1\n",
       "Name: Cabin, Length: 9825, dtype: int64"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Cabin\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:31.343172Z",
     "iopub.status.busy": "2023-02-12T00:18:31.342744Z",
     "iopub.status.idle": "2023-02-12T00:18:35.781981Z",
     "shell.execute_reply": "2023-02-12T00:18:35.780711Z",
     "shell.execute_reply.started": "2023-02-12T00:18:31.343140Z"
    }
   },
   "outputs": [],
   "source": [
    "aziz = list(df[\"Cabin\"][df[\"Cabin\"].isnull()!=True].index)\n",
    "for i in aziz:\n",
    "    df[\"Cabin\"][i] = df[\"Cabin\"][i][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:35.783997Z",
     "iopub.status.busy": "2023-02-12T00:18:35.783617Z",
     "iopub.status.idle": "2023-02-12T00:18:35.794516Z",
     "shell.execute_reply": "2023-02-12T00:18:35.793234Z",
     "shell.execute_reply.started": "2023-02-12T00:18:35.783963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F    4239\n",
       "G    3781\n",
       "E    1323\n",
       "B    1141\n",
       "C    1102\n",
       "D     720\n",
       "A     354\n",
       "T      11\n",
       "Name: Cabin, dtype: int64"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Cabin\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:35.797123Z",
     "iopub.status.busy": "2023-02-12T00:18:35.796495Z",
     "iopub.status.idle": "2023-02-12T00:18:35.809085Z",
     "shell.execute_reply": "2023-02-12T00:18:35.807842Z",
     "shell.execute_reply.started": "2023-02-12T00:18:35.797083Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Cabin\"][df[\"Cabin\"].isnull()==True] = df[\"Cabin\"].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:35.811190Z",
     "iopub.status.busy": "2023-02-12T00:18:35.810835Z",
     "iopub.status.idle": "2023-02-12T00:18:35.828049Z",
     "shell.execute_reply": "2023-02-12T00:18:35.826765Z",
     "shell.execute_reply.started": "2023-02-12T00:18:35.811157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    8079\n",
       "True     4581\n",
       "Name: CryoSleep, dtype: int64"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"CryoSleep\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:35.832008Z",
     "iopub.status.busy": "2023-02-12T00:18:35.831458Z",
     "iopub.status.idle": "2023-02-12T00:18:35.844811Z",
     "shell.execute_reply": "2023-02-12T00:18:35.843577Z",
     "shell.execute_reply.started": "2023-02-12T00:18:35.831931Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"CryoSleep\"][df[\"CryoSleep\"].isnull() == True] = df[\"CryoSleep\"].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:35.847239Z",
     "iopub.status.busy": "2023-02-12T00:18:35.846686Z",
     "iopub.status.idle": "2023-02-12T00:18:35.862773Z",
     "shell.execute_reply": "2023-02-12T00:18:35.861884Z",
     "shell.execute_reply.started": "2023-02-12T00:18:35.847181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Earth     6865\n",
       "Europa    3133\n",
       "Mars      2684\n",
       "Name: HomePlanet, dtype: int64"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"HomePlanet\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:35.864503Z",
     "iopub.status.busy": "2023-02-12T00:18:35.864122Z",
     "iopub.status.idle": "2023-02-12T00:18:35.883553Z",
     "shell.execute_reply": "2023-02-12T00:18:35.882543Z",
     "shell.execute_reply.started": "2023-02-12T00:18:35.864468Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"HomePlanet\"][df[\"HomePlanet\"].isnull()==True] = df[\"HomePlanet\"].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:35.886442Z",
     "iopub.status.busy": "2023-02-12T00:18:35.884978Z",
     "iopub.status.idle": "2023-02-12T00:18:35.897681Z",
     "shell.execute_reply": "2023-02-12T00:18:35.896416Z",
     "shell.execute_reply.started": "2023-02-12T00:18:35.886398Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Destination\"][df[\"Destination\"].isnull()==True] = df[\"Destination\"].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:35.899522Z",
     "iopub.status.busy": "2023-02-12T00:18:35.898944Z",
     "iopub.status.idle": "2023-02-12T00:18:35.917187Z",
     "shell.execute_reply": "2023-02-12T00:18:35.915779Z",
     "shell.execute_reply.started": "2023-02-12T00:18:35.899485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VIP\n",
       "False    217.200113\n",
       "True     486.349442\n",
       "Name: RoomService, dtype: float64"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"VIP\")[\"RoomService\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:35.919554Z",
     "iopub.status.busy": "2023-02-12T00:18:35.918932Z",
     "iopub.status.idle": "2023-02-12T00:18:35.928201Z",
     "shell.execute_reply": "2023-02-12T00:18:35.927124Z",
     "shell.execute_reply.started": "2023-02-12T00:18:35.919517Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Age\"]=df[\"Age\"].fillna(df.groupby('VIP')[\"Age\"].transform('mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:35.930450Z",
     "iopub.status.busy": "2023-02-12T00:18:35.929809Z",
     "iopub.status.idle": "2023-02-12T00:18:35.942411Z",
     "shell.execute_reply": "2023-02-12T00:18:35.941398Z",
     "shell.execute_reply.started": "2023-02-12T00:18:35.930407Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"RoomService\"]=df[\"RoomService\"].fillna(df.groupby('VIP')[\"RoomService\"].transform('mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:35.950688Z",
     "iopub.status.busy": "2023-02-12T00:18:35.950315Z",
     "iopub.status.idle": "2023-02-12T00:18:35.958373Z",
     "shell.execute_reply": "2023-02-12T00:18:35.957495Z",
     "shell.execute_reply.started": "2023-02-12T00:18:35.950656Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"FoodCourt\"]=df[\"FoodCourt\"].fillna(df.groupby('VIP')[\"FoodCourt\"].transform('mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:35.960383Z",
     "iopub.status.busy": "2023-02-12T00:18:35.959646Z",
     "iopub.status.idle": "2023-02-12T00:18:35.974912Z",
     "shell.execute_reply": "2023-02-12T00:18:35.973769Z",
     "shell.execute_reply.started": "2023-02-12T00:18:35.960348Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"ShoppingMall\"]=df[\"ShoppingMall\"].fillna(df.groupby('VIP')[\"ShoppingMall\"].transform('mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:35.978209Z",
     "iopub.status.busy": "2023-02-12T00:18:35.976809Z",
     "iopub.status.idle": "2023-02-12T00:18:35.987924Z",
     "shell.execute_reply": "2023-02-12T00:18:35.986825Z",
     "shell.execute_reply.started": "2023-02-12T00:18:35.978016Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Spa\"]=df[\"Spa\"].fillna(df.groupby('VIP')[\"Spa\"].transform('mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:35.990678Z",
     "iopub.status.busy": "2023-02-12T00:18:35.989681Z",
     "iopub.status.idle": "2023-02-12T00:18:36.001734Z",
     "shell.execute_reply": "2023-02-12T00:18:36.000362Z",
     "shell.execute_reply.started": "2023-02-12T00:18:35.990629Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"VRDeck\"]=df[\"VRDeck\"].fillna(df.groupby('VIP')[\"VRDeck\"].transform('mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.003864Z",
     "iopub.status.busy": "2023-02-12T00:18:36.003453Z",
     "iopub.status.idle": "2023-02-12T00:18:36.023110Z",
     "shell.execute_reply": "2023-02-12T00:18:36.022051Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.003787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId        0\n",
       "HomePlanet         0\n",
       "CryoSleep          0\n",
       "Cabin              0\n",
       "Destination        0\n",
       "Age                0\n",
       "VIP                0\n",
       "RoomService        0\n",
       "FoodCourt          0\n",
       "ShoppingMall       0\n",
       "Spa                0\n",
       "VRDeck             0\n",
       "Name             294\n",
       "Transported     4277\n",
       "dtype: int64"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.024964Z",
     "iopub.status.busy": "2023-02-12T00:18:36.024196Z",
     "iopub.status.idle": "2023-02-12T00:18:36.046554Z",
     "shell.execute_reply": "2023-02-12T00:18:36.045228Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.024928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12970 entries, 0 to 12969\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   12970 non-null  object \n",
      " 1   HomePlanet    12970 non-null  object \n",
      " 2   CryoSleep     12970 non-null  object \n",
      " 3   Cabin         12970 non-null  object \n",
      " 4   Destination   12970 non-null  object \n",
      " 5   Age           12970 non-null  float64\n",
      " 6   VIP           12970 non-null  object \n",
      " 7   RoomService   12970 non-null  float64\n",
      " 8   FoodCourt     12970 non-null  float64\n",
      " 9   ShoppingMall  12970 non-null  float64\n",
      " 10  Spa           12970 non-null  float64\n",
      " 11  VRDeck        12970 non-null  float64\n",
      " 12  Name          12676 non-null  object \n",
      " 13  Transported   8693 non-null   object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.048501Z",
     "iopub.status.busy": "2023-02-12T00:18:36.047923Z",
     "iopub.status.idle": "2023-02-12T00:18:36.071142Z",
     "shell.execute_reply": "2023-02-12T00:18:36.069942Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.048463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False     B  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False     F  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False     A  TRAPPIST-1e  58.0   True   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck             Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0  Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0     Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0    Altark Susent   \n",
       "\n",
       "  Transported  \n",
       "0       False  \n",
       "1        True  \n",
       "2       False  "
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.074060Z",
     "iopub.status.busy": "2023-02-12T00:18:36.072947Z",
     "iopub.status.idle": "2023-02-12T00:18:36.107818Z",
     "shell.execute_reply": "2023-02-12T00:18:36.106731Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.073986Z"
    }
   },
   "outputs": [],
   "source": [
    "df.replace({False:0, True:1}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.110535Z",
     "iopub.status.busy": "2023-02-12T00:18:36.109732Z",
     "iopub.status.idle": "2023-02-12T00:18:36.130316Z",
     "shell.execute_reply": "2023-02-12T00:18:36.129346Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.110486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet  CryoSleep Cabin  Destination   Age  VIP  \\\n",
       "0     0001_01     Europa          0     B  TRAPPIST-1e  39.0    0   \n",
       "1     0002_01      Earth          0     F  TRAPPIST-1e  24.0    0   \n",
       "2     0003_01     Europa          0     A  TRAPPIST-1e  58.0    1   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck             Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0  Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0     Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0    Altark Susent   \n",
       "\n",
       "   Transported  \n",
       "0          0.0  \n",
       "1          1.0  \n",
       "2          0.0  "
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaratory Data Analysis(EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.132808Z",
     "iopub.status.busy": "2023-02-12T00:18:36.131449Z",
     "iopub.status.idle": "2023-02-12T00:18:36.281932Z",
     "shell.execute_reply": "2023-02-12T00:18:36.280723Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.132772Z"
    }
   },
   "outputs": [],
   "source": [
    "group_person_num = []\n",
    "for i in range(len(df)):\n",
    "    num = int(df.PassengerId[i][-2:])\n",
    "    group_person_num.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.283883Z",
     "iopub.status.busy": "2023-02-12T00:18:36.283535Z",
     "iopub.status.idle": "2023-02-12T00:18:36.293397Z",
     "shell.execute_reply": "2023-02-12T00:18:36.292013Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.283850Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"G_person_num\"] = group_person_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.296196Z",
     "iopub.status.busy": "2023-02-12T00:18:36.295386Z",
     "iopub.status.idle": "2023-02-12T00:18:36.310317Z",
     "shell.execute_reply": "2023-02-12T00:18:36.308734Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.296147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9280\n",
       "2    2135\n",
       "3     840\n",
       "4     338\n",
       "5     184\n",
       "6     108\n",
       "7      66\n",
       "8      19\n",
       "Name: G_person_num, dtype: int64"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.G_person_num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.313093Z",
     "iopub.status.busy": "2023-02-12T00:18:36.311886Z",
     "iopub.status.idle": "2023-02-12T00:18:36.520737Z",
     "shell.execute_reply": "2023-02-12T00:18:36.519045Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.312973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.G_person_num.value_counts().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.522466Z",
     "iopub.status.busy": "2023-02-12T00:18:36.521844Z",
     "iopub.status.idle": "2023-02-12T00:18:36.544774Z",
     "shell.execute_reply": "2023-02-12T00:18:36.543353Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.522430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "      <th>G_person_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet  CryoSleep Cabin  Destination   Age  VIP  \\\n",
       "0     0001_01     Europa          0     B  TRAPPIST-1e  39.0    0   \n",
       "1     0002_01      Earth          0     F  TRAPPIST-1e  24.0    0   \n",
       "2     0003_01     Europa          0     A  TRAPPIST-1e  58.0    1   \n",
       "3     0003_02     Europa          0     A  TRAPPIST-1e  33.0    0   \n",
       "4     0004_01      Earth          0     F  TRAPPIST-1e  16.0    0   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  G_person_num  \n",
       "0          0.0             1  \n",
       "1          1.0             1  \n",
       "2          0.0             1  \n",
       "3          0.0             2  \n",
       "4          1.0             1  "
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.547507Z",
     "iopub.status.busy": "2023-02-12T00:18:36.546792Z",
     "iopub.status.idle": "2023-02-12T00:18:36.577048Z",
     "shell.execute_reply": "2023-02-12T00:18:36.575747Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.547455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CryoSleep      0.460132\n",
       "RoomService    0.242206\n",
       "Spa            0.218780\n",
       "VRDeck         0.204622\n",
       "Name: Transported, dtype: float64"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aziz = abs(df.corr()[\"Transported\"][(abs(df.corr()[\"Transported\"])>.2)&(df.corr()[\"Transported\"]<.9)])\n",
    "aziz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.579331Z",
     "iopub.status.busy": "2023-02-12T00:18:36.578964Z",
     "iopub.status.idle": "2023-02-12T00:18:36.585621Z",
     "shell.execute_reply": "2023-02-12T00:18:36.584472Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.579297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CryoSleep', 'RoomService', 'Spa', 'VRDeck']"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aziz = list(aziz.index)\n",
    "aziz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.588198Z",
     "iopub.status.busy": "2023-02-12T00:18:36.587066Z",
     "iopub.status.idle": "2023-02-12T00:18:36.599945Z",
     "shell.execute_reply": "2023-02-12T00:18:36.598824Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.588149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12970, 15)"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.601823Z",
     "iopub.status.busy": "2023-02-12T00:18:36.601438Z",
     "iopub.status.idle": "2023-02-12T00:18:36.630517Z",
     "shell.execute_reply": "2023-02-12T00:18:36.629308Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.601790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.632846Z",
     "iopub.status.busy": "2023-02-12T00:18:36.632003Z",
     "iopub.status.idle": "2023-02-12T00:18:36.638404Z",
     "shell.execute_reply": "2023-02-12T00:18:36.637312Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.632807Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = df[:len(x_train)]\n",
    "x_test = df[-len(x_test):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.640546Z",
     "iopub.status.busy": "2023-02-12T00:18:36.640064Z",
     "iopub.status.idle": "2023-02-12T00:18:36.650432Z",
     "shell.execute_reply": "2023-02-12T00:18:36.649313Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.640502Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train.reset_index(drop=True, inplace=True)\n",
    "x_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.652565Z",
     "iopub.status.busy": "2023-02-12T00:18:36.652148Z",
     "iopub.status.idle": "2023-02-12T00:18:36.680788Z",
     "shell.execute_reply": "2023-02-12T00:18:36.679580Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.652529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "      <th>G_person_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet  CryoSleep Cabin  Destination   Age  VIP  \\\n",
       "0     0001_01     Europa          0     B  TRAPPIST-1e  39.0    0   \n",
       "1     0002_01      Earth          0     F  TRAPPIST-1e  24.0    0   \n",
       "2     0003_01     Europa          0     A  TRAPPIST-1e  58.0    1   \n",
       "3     0003_02     Europa          0     A  TRAPPIST-1e  33.0    0   \n",
       "4     0004_01      Earth          0     F  TRAPPIST-1e  16.0    0   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  G_person_num  \n",
       "0          0.0             1  \n",
       "1          1.0             1  \n",
       "2          0.0             1  \n",
       "3          0.0             2  \n",
       "4          1.0             1  "
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.682319Z",
     "iopub.status.busy": "2023-02-12T00:18:36.681976Z",
     "iopub.status.idle": "2023-02-12T00:18:36.689215Z",
     "shell.execute_reply": "2023-02-12T00:18:36.687967Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.682287Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train[\"Transported\"] = x_train[\"Transported\"].astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.691391Z",
     "iopub.status.busy": "2023-02-12T00:18:36.690898Z",
     "iopub.status.idle": "2023-02-12T00:18:36.704983Z",
     "shell.execute_reply": "2023-02-12T00:18:36.703832Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.691346Z"
    }
   },
   "outputs": [],
   "source": [
    "x = x_train[['CryoSleep', 'RoomService', 'Spa', 'VRDeck', \"HomePlanet\", \"Cabin\", \"Destination\"]]\n",
    "x_test = x_test[['CryoSleep', 'RoomService', 'Spa', 'VRDeck', \"HomePlanet\", \"Cabin\", \"Destination\"]]\n",
    "y = x_train[\"Transported\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.707450Z",
     "iopub.status.busy": "2023-02-12T00:18:36.706697Z",
     "iopub.status.idle": "2023-02-12T00:18:36.733176Z",
     "shell.execute_reply": "2023-02-12T00:18:36.732323Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.707400Z"
    }
   },
   "outputs": [],
   "source": [
    "x = pd.get_dummies(x, drop_first=True)\n",
    "x_test = pd.get_dummies(x_test, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.734596Z",
     "iopub.status.busy": "2023-02-12T00:18:36.734249Z",
     "iopub.status.idle": "2023-02-12T00:18:36.741515Z",
     "shell.execute_reply": "2023-02-12T00:18:36.740333Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.734566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8693, 15), (4277, 15))"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.744024Z",
     "iopub.status.busy": "2023-02-12T00:18:36.743328Z",
     "iopub.status.idle": "2023-02-12T00:18:36.754928Z",
     "shell.execute_reply": "2023-02-12T00:18:36.753882Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.743986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       0\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "8688    0\n",
       "8689    0\n",
       "8690    1\n",
       "8691    0\n",
       "8692    1\n",
       "Name: Transported, Length: 8693, dtype: int32"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.757399Z",
     "iopub.status.busy": "2023-02-12T00:18:36.756363Z",
     "iopub.status.idle": "2023-02-12T00:18:36.768073Z",
     "shell.execute_reply": "2023-02-12T00:18:36.766877Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.757358Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.770405Z",
     "iopub.status.busy": "2023-02-12T00:18:36.769541Z",
     "iopub.status.idle": "2023-02-12T00:18:36.788085Z",
     "shell.execute_reply": "2023-02-12T00:18:36.786828Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.770369Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(x,y, train_size=0.80, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.790189Z",
     "iopub.status.busy": "2023-02-12T00:18:36.789414Z",
     "iopub.status.idle": "2023-02-12T00:18:36.798968Z",
     "shell.execute_reply": "2023-02-12T00:18:36.797779Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.790150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6954, 6954, 1739, 1739)"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x), len(train_y), len(test_x), len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.801327Z",
     "iopub.status.busy": "2023-02-12T00:18:36.800652Z",
     "iopub.status.idle": "2023-02-12T00:18:36.809604Z",
     "shell.execute_reply": "2023-02-12T00:18:36.808572Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.801253Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.811822Z",
     "iopub.status.busy": "2023-02-12T00:18:36.810883Z",
     "iopub.status.idle": "2023-02-12T00:18:36.852830Z",
     "shell.execute_reply": "2023-02-12T00:18:36.851592Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.811785Z"
    }
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1048,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer='adam',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:18:36.854849Z",
     "iopub.status.busy": "2023-02-12T00:18:36.854396Z",
     "iopub.status.idle": "2023-02-12T00:44:30.485980Z",
     "shell.execute_reply": "2023-02-12T00:44:30.484639Z",
     "shell.execute_reply.started": "2023-02-12T00:18:36.854815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "28/28 [==============================] - 6s 78ms/step - loss: 0.7580 - accuracy: 0.6217 - val_loss: 0.5935 - val_accuracy: 0.7481\n",
      "Epoch 2/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.6368 - accuracy: 0.6721 - val_loss: 0.5765 - val_accuracy: 0.7458\n",
      "Epoch 3/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.6094 - accuracy: 0.6879 - val_loss: 0.5545 - val_accuracy: 0.7435\n",
      "Epoch 4/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5761 - accuracy: 0.7045 - val_loss: 0.5546 - val_accuracy: 0.7464\n",
      "Epoch 5/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.5565 - accuracy: 0.7171 - val_loss: 0.5424 - val_accuracy: 0.7476\n",
      "Epoch 6/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.5502 - accuracy: 0.7238 - val_loss: 0.5337 - val_accuracy: 0.7453\n",
      "Epoch 7/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.5397 - accuracy: 0.7272 - val_loss: 0.5306 - val_accuracy: 0.7447\n",
      "Epoch 8/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5364 - accuracy: 0.7284 - val_loss: 0.5324 - val_accuracy: 0.7453\n",
      "Epoch 9/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5329 - accuracy: 0.7344 - val_loss: 0.5246 - val_accuracy: 0.7458\n",
      "Epoch 10/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.5348 - accuracy: 0.7311 - val_loss: 0.5176 - val_accuracy: 0.7453\n",
      "Epoch 11/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5289 - accuracy: 0.7350 - val_loss: 0.5136 - val_accuracy: 0.7470\n",
      "Epoch 12/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5194 - accuracy: 0.7468 - val_loss: 0.5036 - val_accuracy: 0.7447\n",
      "Epoch 13/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5126 - accuracy: 0.7502 - val_loss: 0.4974 - val_accuracy: 0.7464\n",
      "Epoch 14/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.5144 - accuracy: 0.7476 - val_loss: 0.4916 - val_accuracy: 0.7447\n",
      "Epoch 15/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.5176 - accuracy: 0.7456 - val_loss: 0.4883 - val_accuracy: 0.7510\n",
      "Epoch 16/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5127 - accuracy: 0.7494 - val_loss: 0.4847 - val_accuracy: 0.7493\n",
      "Epoch 17/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5169 - accuracy: 0.7481 - val_loss: 0.4854 - val_accuracy: 0.7504\n",
      "Epoch 18/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.5106 - accuracy: 0.7465 - val_loss: 0.4862 - val_accuracy: 0.7487\n",
      "Epoch 19/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5125 - accuracy: 0.7482 - val_loss: 0.4863 - val_accuracy: 0.7470\n",
      "Epoch 20/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5088 - accuracy: 0.7499 - val_loss: 0.4847 - val_accuracy: 0.7510\n",
      "Epoch 21/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4999 - accuracy: 0.7535 - val_loss: 0.4816 - val_accuracy: 0.7487\n",
      "Epoch 22/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.5056 - accuracy: 0.7565 - val_loss: 0.4790 - val_accuracy: 0.7522\n",
      "Epoch 23/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5018 - accuracy: 0.7522 - val_loss: 0.4792 - val_accuracy: 0.7539\n",
      "Epoch 24/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5051 - accuracy: 0.7604 - val_loss: 0.4801 - val_accuracy: 0.7499\n",
      "Epoch 25/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5024 - accuracy: 0.7577 - val_loss: 0.4808 - val_accuracy: 0.7447\n",
      "Epoch 26/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.5017 - accuracy: 0.7519 - val_loss: 0.4788 - val_accuracy: 0.7504\n",
      "Epoch 27/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.5002 - accuracy: 0.7575 - val_loss: 0.4764 - val_accuracy: 0.7591\n",
      "Epoch 28/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4997 - accuracy: 0.7591 - val_loss: 0.4761 - val_accuracy: 0.7527\n",
      "Epoch 29/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5032 - accuracy: 0.7557 - val_loss: 0.4745 - val_accuracy: 0.7579\n",
      "Epoch 30/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4953 - accuracy: 0.7594 - val_loss: 0.4738 - val_accuracy: 0.7625\n",
      "Epoch 31/1500\n",
      "28/28 [==============================] - 2s 64ms/step - loss: 0.4980 - accuracy: 0.7645 - val_loss: 0.4742 - val_accuracy: 0.7614\n",
      "Epoch 32/1500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5011 - accuracy: 0.7604 - val_loss: 0.4743 - val_accuracy: 0.7556\n",
      "Epoch 33/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4990 - accuracy: 0.7580 - val_loss: 0.4763 - val_accuracy: 0.7470\n",
      "Epoch 34/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4973 - accuracy: 0.7594 - val_loss: 0.4727 - val_accuracy: 0.7642\n",
      "Epoch 35/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4915 - accuracy: 0.7663 - val_loss: 0.4760 - val_accuracy: 0.7493\n",
      "Epoch 36/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4898 - accuracy: 0.7649 - val_loss: 0.4730 - val_accuracy: 0.7493\n",
      "Epoch 37/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4918 - accuracy: 0.7673 - val_loss: 0.4720 - val_accuracy: 0.7504\n",
      "Epoch 38/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4897 - accuracy: 0.7632 - val_loss: 0.4698 - val_accuracy: 0.7539\n",
      "Epoch 39/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4909 - accuracy: 0.7626 - val_loss: 0.4723 - val_accuracy: 0.7493\n",
      "Epoch 40/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4924 - accuracy: 0.7673 - val_loss: 0.4675 - val_accuracy: 0.7602\n",
      "Epoch 41/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4881 - accuracy: 0.7711 - val_loss: 0.4721 - val_accuracy: 0.7539\n",
      "Epoch 42/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4922 - accuracy: 0.7688 - val_loss: 0.4722 - val_accuracy: 0.7694\n",
      "Epoch 43/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4894 - accuracy: 0.7724 - val_loss: 0.4758 - val_accuracy: 0.7614\n",
      "Epoch 44/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4852 - accuracy: 0.7737 - val_loss: 0.4769 - val_accuracy: 0.7648\n",
      "Epoch 45/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4781 - accuracy: 0.7701 - val_loss: 0.4700 - val_accuracy: 0.7677\n",
      "Epoch 46/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4721 - accuracy: 0.7804 - val_loss: 0.4688 - val_accuracy: 0.7510\n",
      "Epoch 47/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4719 - accuracy: 0.7783 - val_loss: 0.4643 - val_accuracy: 0.7694\n",
      "Epoch 48/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4758 - accuracy: 0.7728 - val_loss: 0.4651 - val_accuracy: 0.7677\n",
      "Epoch 49/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4707 - accuracy: 0.7764 - val_loss: 0.4852 - val_accuracy: 0.7579\n",
      "Epoch 50/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4702 - accuracy: 0.7757 - val_loss: 0.4634 - val_accuracy: 0.7740\n",
      "Epoch 51/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4714 - accuracy: 0.7804 - val_loss: 0.4619 - val_accuracy: 0.7700\n",
      "Epoch 52/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4742 - accuracy: 0.7800 - val_loss: 0.4665 - val_accuracy: 0.7660\n",
      "Epoch 53/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4687 - accuracy: 0.7767 - val_loss: 0.4663 - val_accuracy: 0.7660\n",
      "Epoch 54/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4597 - accuracy: 0.7842 - val_loss: 0.4553 - val_accuracy: 0.7780\n",
      "Epoch 55/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4562 - accuracy: 0.7862 - val_loss: 0.4646 - val_accuracy: 0.7706\n",
      "Epoch 56/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4577 - accuracy: 0.7857 - val_loss: 0.4528 - val_accuracy: 0.7815\n",
      "Epoch 57/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4649 - accuracy: 0.7817 - val_loss: 0.4679 - val_accuracy: 0.7700\n",
      "Epoch 58/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4777 - val_accuracy: 0.7591\n",
      "Epoch 59/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4555 - accuracy: 0.7836 - val_loss: 0.4560 - val_accuracy: 0.7757\n",
      "Epoch 60/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4700 - accuracy: 0.7833 - val_loss: 0.4460 - val_accuracy: 0.7832\n",
      "Epoch 61/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4586 - accuracy: 0.7836 - val_loss: 0.4501 - val_accuracy: 0.7803\n",
      "Epoch 62/1500\n",
      "28/28 [==============================] - 2s 64ms/step - loss: 0.4613 - accuracy: 0.7854 - val_loss: 0.4583 - val_accuracy: 0.7792\n",
      "Epoch 63/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4609 - accuracy: 0.7867 - val_loss: 0.4600 - val_accuracy: 0.7740\n",
      "Epoch 64/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4557 - accuracy: 0.7900 - val_loss: 0.4628 - val_accuracy: 0.7694\n",
      "Epoch 65/1500\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.4543 - accuracy: 0.7880 - val_loss: 0.4485 - val_accuracy: 0.7780\n",
      "Epoch 66/1500\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.4572 - accuracy: 0.7886 - val_loss: 0.4496 - val_accuracy: 0.7786\n",
      "Epoch 67/1500\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.4533 - accuracy: 0.7889 - val_loss: 0.4496 - val_accuracy: 0.7775\n",
      "Epoch 68/1500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4568 - accuracy: 0.7854 - val_loss: 0.4539 - val_accuracy: 0.7688\n",
      "Epoch 69/1500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4586 - accuracy: 0.7862 - val_loss: 0.5062 - val_accuracy: 0.7292\n",
      "Epoch 70/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4578 - accuracy: 0.7866 - val_loss: 0.4511 - val_accuracy: 0.7763\n",
      "Epoch 71/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4554 - accuracy: 0.7898 - val_loss: 0.4438 - val_accuracy: 0.7844\n",
      "Epoch 72/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4594 - accuracy: 0.7813 - val_loss: 2.3496 - val_accuracy: 0.7246\n",
      "Epoch 73/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4669 - accuracy: 0.7875 - val_loss: 0.4680 - val_accuracy: 0.7832\n",
      "Epoch 74/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4591 - accuracy: 0.7870 - val_loss: 0.4526 - val_accuracy: 0.7826\n",
      "Epoch 75/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4555 - accuracy: 0.7912 - val_loss: 0.4483 - val_accuracy: 0.7821\n",
      "Epoch 76/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4557 - accuracy: 0.7903 - val_loss: 0.4533 - val_accuracy: 0.7780\n",
      "Epoch 77/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4604 - accuracy: 0.7836 - val_loss: 0.4559 - val_accuracy: 0.7792\n",
      "Epoch 78/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4606 - accuracy: 0.7889 - val_loss: 0.4530 - val_accuracy: 0.7780\n",
      "Epoch 79/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4532 - accuracy: 0.7850 - val_loss: 0.4518 - val_accuracy: 0.7803\n",
      "Epoch 80/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4605 - accuracy: 0.7903 - val_loss: 0.4496 - val_accuracy: 0.7832\n",
      "Epoch 81/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4560 - accuracy: 0.7952 - val_loss: 0.4681 - val_accuracy: 0.7729\n",
      "Epoch 82/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4536 - accuracy: 0.7919 - val_loss: 0.4526 - val_accuracy: 0.7798\n",
      "Epoch 83/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4523 - accuracy: 0.7913 - val_loss: 0.4445 - val_accuracy: 0.7849\n",
      "Epoch 84/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4519 - accuracy: 0.7863 - val_loss: 0.4453 - val_accuracy: 0.7803\n",
      "Epoch 85/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4505 - accuracy: 0.7867 - val_loss: 0.4548 - val_accuracy: 0.7792\n",
      "Epoch 86/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4589 - val_accuracy: 0.7769\n",
      "Epoch 87/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4750 - accuracy: 0.7778 - val_loss: 0.4506 - val_accuracy: 0.7746\n",
      "Epoch 88/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4580 - accuracy: 0.7873 - val_loss: 0.4534 - val_accuracy: 0.7757\n",
      "Epoch 89/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4534 - accuracy: 0.7900 - val_loss: 0.4566 - val_accuracy: 0.7746\n",
      "Epoch 90/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4551 - accuracy: 0.7880 - val_loss: 0.4601 - val_accuracy: 0.7717\n",
      "Epoch 91/1500\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.4511 - accuracy: 0.7922 - val_loss: 0.4492 - val_accuracy: 0.7803\n",
      "Epoch 92/1500\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 0.4450 - accuracy: 0.7903 - val_loss: 0.4481 - val_accuracy: 0.7832\n",
      "Epoch 93/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4524 - accuracy: 0.7911 - val_loss: 0.4599 - val_accuracy: 0.7769\n",
      "Epoch 94/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4568 - accuracy: 0.7801 - val_loss: 0.4639 - val_accuracy: 0.7752\n",
      "Epoch 95/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4555 - accuracy: 0.7816 - val_loss: 0.4517 - val_accuracy: 0.7734\n",
      "Epoch 96/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4461 - accuracy: 0.7903 - val_loss: 0.4455 - val_accuracy: 0.7798\n",
      "Epoch 97/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4481 - accuracy: 0.7922 - val_loss: 0.4525 - val_accuracy: 0.7752\n",
      "Epoch 98/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4549 - accuracy: 0.7908 - val_loss: 0.4407 - val_accuracy: 0.7803\n",
      "Epoch 99/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4483 - accuracy: 0.7925 - val_loss: 0.4467 - val_accuracy: 0.7740\n",
      "Epoch 100/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4500 - accuracy: 0.7885 - val_loss: 0.4472 - val_accuracy: 0.7752\n",
      "Epoch 101/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4484 - accuracy: 0.7902 - val_loss: 0.4462 - val_accuracy: 0.7786\n",
      "Epoch 102/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4486 - accuracy: 0.7936 - val_loss: 0.4385 - val_accuracy: 0.7849\n",
      "Epoch 103/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4424 - accuracy: 0.7938 - val_loss: 0.4420 - val_accuracy: 0.7855\n",
      "Epoch 104/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4556 - accuracy: 0.7919 - val_loss: 0.4431 - val_accuracy: 0.7821\n",
      "Epoch 105/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4477 - accuracy: 0.7929 - val_loss: 0.4402 - val_accuracy: 0.7803\n",
      "Epoch 106/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4488 - accuracy: 0.7935 - val_loss: 0.4385 - val_accuracy: 0.7815\n",
      "Epoch 107/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4479 - accuracy: 0.7905 - val_loss: 0.4420 - val_accuracy: 0.7780\n",
      "Epoch 108/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4500 - accuracy: 0.7902 - val_loss: 0.4424 - val_accuracy: 0.7803\n",
      "Epoch 109/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4460 - accuracy: 0.7900 - val_loss: 0.4515 - val_accuracy: 0.7711\n",
      "Epoch 110/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4412 - accuracy: 0.7892 - val_loss: 0.4377 - val_accuracy: 0.7809\n",
      "Epoch 111/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4472 - accuracy: 0.7925 - val_loss: 0.4430 - val_accuracy: 0.7780\n",
      "Epoch 112/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4457 - accuracy: 0.7939 - val_loss: 0.4434 - val_accuracy: 0.7757\n",
      "Epoch 113/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4454 - accuracy: 0.7900 - val_loss: 0.4395 - val_accuracy: 0.7832\n",
      "Epoch 114/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4492 - accuracy: 0.7951 - val_loss: 0.4497 - val_accuracy: 0.7729\n",
      "Epoch 115/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4470 - accuracy: 0.7938 - val_loss: 0.4429 - val_accuracy: 0.7803\n",
      "Epoch 116/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4467 - accuracy: 0.7944 - val_loss: 0.4425 - val_accuracy: 0.7821\n",
      "Epoch 117/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4467 - accuracy: 0.7913 - val_loss: 0.4735 - val_accuracy: 0.7614\n",
      "Epoch 118/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4473 - accuracy: 0.7916 - val_loss: 0.4406 - val_accuracy: 0.7809\n",
      "Epoch 119/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4448 - accuracy: 0.7883 - val_loss: 0.4457 - val_accuracy: 0.7769\n",
      "Epoch 120/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4461 - accuracy: 0.7922 - val_loss: 0.4414 - val_accuracy: 0.7838\n",
      "Epoch 121/1500\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 0.4460 - accuracy: 0.7909 - val_loss: 0.4389 - val_accuracy: 0.7872\n",
      "Epoch 122/1500\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.4423 - accuracy: 0.7921 - val_loss: 0.4499 - val_accuracy: 0.7775\n",
      "Epoch 123/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4449 - accuracy: 0.7945 - val_loss: 0.4400 - val_accuracy: 0.7809\n",
      "Epoch 124/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4445 - accuracy: 0.7905 - val_loss: 0.4371 - val_accuracy: 0.7872\n",
      "Epoch 125/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4455 - accuracy: 0.7890 - val_loss: 0.4344 - val_accuracy: 0.7809\n",
      "Epoch 126/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4513 - accuracy: 0.7925 - val_loss: 0.4486 - val_accuracy: 0.7752\n",
      "Epoch 127/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4541 - accuracy: 0.7854 - val_loss: 0.4609 - val_accuracy: 0.7752\n",
      "Epoch 128/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4471 - accuracy: 0.7876 - val_loss: 0.4459 - val_accuracy: 0.7757\n",
      "Epoch 129/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4453 - accuracy: 0.7923 - val_loss: 0.4564 - val_accuracy: 0.7711\n",
      "Epoch 130/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4427 - accuracy: 0.7875 - val_loss: 0.4546 - val_accuracy: 0.7688\n",
      "Epoch 131/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4477 - accuracy: 0.7905 - val_loss: 0.4350 - val_accuracy: 0.7861\n",
      "Epoch 132/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4443 - accuracy: 0.7906 - val_loss: 0.4436 - val_accuracy: 0.7786\n",
      "Epoch 133/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4515 - accuracy: 0.7882 - val_loss: 0.4485 - val_accuracy: 0.7803\n",
      "Epoch 134/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4422 - accuracy: 0.7918 - val_loss: 0.4402 - val_accuracy: 0.7855\n",
      "Epoch 135/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4449 - accuracy: 0.7941 - val_loss: 0.4433 - val_accuracy: 0.7769\n",
      "Epoch 136/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4452 - accuracy: 0.7895 - val_loss: 0.4430 - val_accuracy: 0.7809\n",
      "Epoch 137/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4553 - accuracy: 0.7888 - val_loss: 0.4500 - val_accuracy: 0.7711\n",
      "Epoch 138/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4428 - accuracy: 0.7922 - val_loss: 0.4400 - val_accuracy: 0.7849\n",
      "Epoch 139/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4425 - accuracy: 0.7912 - val_loss: 0.4423 - val_accuracy: 0.7838\n",
      "Epoch 140/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4443 - accuracy: 0.7942 - val_loss: 0.4367 - val_accuracy: 0.7803\n",
      "Epoch 141/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4432 - accuracy: 0.7911 - val_loss: 0.4415 - val_accuracy: 0.7734\n",
      "Epoch 142/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4516 - accuracy: 0.7944 - val_loss: 0.4449 - val_accuracy: 0.7780\n",
      "Epoch 143/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4450 - accuracy: 0.7892 - val_loss: 0.4379 - val_accuracy: 0.7826\n",
      "Epoch 144/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4458 - accuracy: 0.7934 - val_loss: 0.4393 - val_accuracy: 0.7775\n",
      "Epoch 145/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4462 - accuracy: 0.7928 - val_loss: 0.4367 - val_accuracy: 0.7786\n",
      "Epoch 146/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4465 - accuracy: 0.7915 - val_loss: 0.4422 - val_accuracy: 0.7792\n",
      "Epoch 147/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4441 - accuracy: 0.7958 - val_loss: 0.4387 - val_accuracy: 0.7844\n",
      "Epoch 148/1500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4414 - accuracy: 0.7918 - val_loss: 0.4403 - val_accuracy: 0.7803\n",
      "Epoch 149/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4464 - accuracy: 0.7928 - val_loss: 0.4428 - val_accuracy: 0.7809\n",
      "Epoch 150/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4444 - accuracy: 0.7913 - val_loss: 0.4516 - val_accuracy: 0.7786\n",
      "Epoch 151/1500\n",
      "28/28 [==============================] - 2s 64ms/step - loss: 0.4452 - accuracy: 0.7954 - val_loss: 0.4448 - val_accuracy: 0.7821\n",
      "Epoch 152/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4438 - accuracy: 0.7915 - val_loss: 0.4393 - val_accuracy: 0.7809\n",
      "Epoch 153/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4424 - accuracy: 0.7892 - val_loss: 0.4417 - val_accuracy: 0.7786\n",
      "Epoch 154/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4440 - accuracy: 0.7951 - val_loss: 0.4388 - val_accuracy: 0.7844\n",
      "Epoch 155/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4476 - accuracy: 0.7964 - val_loss: 0.4442 - val_accuracy: 0.7763\n",
      "Epoch 156/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4520 - accuracy: 0.7869 - val_loss: 0.4578 - val_accuracy: 0.7780\n",
      "Epoch 157/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4469 - accuracy: 0.7918 - val_loss: 0.4475 - val_accuracy: 0.7769\n",
      "Epoch 158/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4476 - accuracy: 0.7935 - val_loss: 0.4366 - val_accuracy: 0.7826\n",
      "Epoch 159/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4415 - accuracy: 0.7945 - val_loss: 0.4370 - val_accuracy: 0.7809\n",
      "Epoch 160/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4405 - accuracy: 0.7947 - val_loss: 0.4565 - val_accuracy: 0.7769\n",
      "Epoch 161/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4570 - accuracy: 0.7873 - val_loss: 0.4510 - val_accuracy: 0.7757\n",
      "Epoch 162/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4425 - accuracy: 0.7883 - val_loss: 0.4443 - val_accuracy: 0.7729\n",
      "Epoch 163/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4392 - accuracy: 0.7952 - val_loss: 0.4499 - val_accuracy: 0.7717\n",
      "Epoch 164/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4519 - accuracy: 0.7915 - val_loss: 0.4583 - val_accuracy: 0.7792\n",
      "Epoch 165/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4489 - accuracy: 0.7931 - val_loss: 0.4488 - val_accuracy: 0.7838\n",
      "Epoch 166/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4464 - accuracy: 0.7921 - val_loss: 0.4497 - val_accuracy: 0.7809\n",
      "Epoch 167/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4475 - accuracy: 0.7944 - val_loss: 0.4448 - val_accuracy: 0.7821\n",
      "Epoch 168/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4476 - accuracy: 0.7928 - val_loss: 0.4479 - val_accuracy: 0.7838\n",
      "Epoch 169/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4469 - accuracy: 0.7959 - val_loss: 0.4465 - val_accuracy: 0.7844\n",
      "Epoch 170/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4450 - accuracy: 0.7945 - val_loss: 0.4501 - val_accuracy: 0.7746\n",
      "Epoch 171/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4482 - accuracy: 0.7931 - val_loss: 0.4513 - val_accuracy: 0.7798\n",
      "Epoch 172/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4478 - accuracy: 0.7939 - val_loss: 0.4449 - val_accuracy: 0.7763\n",
      "Epoch 173/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4499 - accuracy: 0.7892 - val_loss: 0.4538 - val_accuracy: 0.7717\n",
      "Epoch 174/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4474 - accuracy: 0.7938 - val_loss: 0.4449 - val_accuracy: 0.7815\n",
      "Epoch 175/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4448 - accuracy: 0.7944 - val_loss: 0.4498 - val_accuracy: 0.7792\n",
      "Epoch 176/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4486 - accuracy: 0.7911 - val_loss: 0.4508 - val_accuracy: 0.7780\n",
      "Epoch 177/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4463 - accuracy: 0.7929 - val_loss: 0.4507 - val_accuracy: 0.7792\n",
      "Epoch 178/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4449 - accuracy: 0.7947 - val_loss: 0.4560 - val_accuracy: 0.7700\n",
      "Epoch 179/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4445 - accuracy: 0.7971 - val_loss: 0.4485 - val_accuracy: 0.7803\n",
      "Epoch 180/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4442 - accuracy: 0.7965 - val_loss: 0.4540 - val_accuracy: 0.7729\n",
      "Epoch 181/1500\n",
      "28/28 [==============================] - 2s 63ms/step - loss: 0.4440 - accuracy: 0.7921 - val_loss: 0.4426 - val_accuracy: 0.7832\n",
      "Epoch 182/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4446 - accuracy: 0.7919 - val_loss: 0.4503 - val_accuracy: 0.7798\n",
      "Epoch 183/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4439 - accuracy: 0.7971 - val_loss: 0.4476 - val_accuracy: 0.7775\n",
      "Epoch 184/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4400 - accuracy: 0.7954 - val_loss: 0.4604 - val_accuracy: 0.7780\n",
      "Epoch 185/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4463 - accuracy: 0.7954 - val_loss: 0.4471 - val_accuracy: 0.7763\n",
      "Epoch 186/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4450 - accuracy: 0.7974 - val_loss: 0.4494 - val_accuracy: 0.7769\n",
      "Epoch 187/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4483 - accuracy: 0.7915 - val_loss: 0.4459 - val_accuracy: 0.7723\n",
      "Epoch 188/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4438 - accuracy: 0.7982 - val_loss: 0.4542 - val_accuracy: 0.7688\n",
      "Epoch 189/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4470 - accuracy: 0.7918 - val_loss: 0.4561 - val_accuracy: 0.7711\n",
      "Epoch 190/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4391 - accuracy: 0.7951 - val_loss: 0.4527 - val_accuracy: 0.7723\n",
      "Epoch 191/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4471 - accuracy: 0.7935 - val_loss: 0.4455 - val_accuracy: 0.7821\n",
      "Epoch 192/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4416 - accuracy: 0.7959 - val_loss: 0.4534 - val_accuracy: 0.7729\n",
      "Epoch 193/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4356 - accuracy: 0.7991 - val_loss: 0.4593 - val_accuracy: 0.7683\n",
      "Epoch 194/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4448 - accuracy: 0.7980 - val_loss: 0.4553 - val_accuracy: 0.7757\n",
      "Epoch 195/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4418 - accuracy: 0.7913 - val_loss: 0.4502 - val_accuracy: 0.7775\n",
      "Epoch 196/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4431 - accuracy: 0.7972 - val_loss: 0.4521 - val_accuracy: 0.7757\n",
      "Epoch 197/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4399 - accuracy: 0.7975 - val_loss: 0.4491 - val_accuracy: 0.7803\n",
      "Epoch 198/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4432 - accuracy: 0.7952 - val_loss: 0.4577 - val_accuracy: 0.7752\n",
      "Epoch 199/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4408 - accuracy: 0.7954 - val_loss: 0.4464 - val_accuracy: 0.7769\n",
      "Epoch 200/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4452 - accuracy: 0.7935 - val_loss: 0.4524 - val_accuracy: 0.7752\n",
      "Epoch 201/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4429 - accuracy: 0.7938 - val_loss: 0.4569 - val_accuracy: 0.7694\n",
      "Epoch 202/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4460 - accuracy: 0.7954 - val_loss: 0.4506 - val_accuracy: 0.7763\n",
      "Epoch 203/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4448 - accuracy: 0.7916 - val_loss: 0.4449 - val_accuracy: 0.7769\n",
      "Epoch 204/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4382 - accuracy: 0.7967 - val_loss: 0.4467 - val_accuracy: 0.7786\n",
      "Epoch 205/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4379 - accuracy: 0.8005 - val_loss: 0.4472 - val_accuracy: 0.7838\n",
      "Epoch 206/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4378 - accuracy: 0.7994 - val_loss: 0.4495 - val_accuracy: 0.7775\n",
      "Epoch 207/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4403 - accuracy: 0.7984 - val_loss: 0.4496 - val_accuracy: 0.7844\n",
      "Epoch 208/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4370 - accuracy: 0.7964 - val_loss: 0.4477 - val_accuracy: 0.7775\n",
      "Epoch 209/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4386 - accuracy: 0.7968 - val_loss: 0.4570 - val_accuracy: 0.7677\n",
      "Epoch 210/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4375 - accuracy: 0.7977 - val_loss: 0.4572 - val_accuracy: 0.7792\n",
      "Epoch 211/1500\n",
      "28/28 [==============================] - 2s 64ms/step - loss: 0.4373 - accuracy: 0.7949 - val_loss: 0.4556 - val_accuracy: 0.7763\n",
      "Epoch 212/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4405 - accuracy: 0.7929 - val_loss: 0.4454 - val_accuracy: 0.7826\n",
      "Epoch 213/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4342 - accuracy: 0.7980 - val_loss: 0.4452 - val_accuracy: 0.7740\n",
      "Epoch 214/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4404 - accuracy: 0.7951 - val_loss: 0.4443 - val_accuracy: 0.7815\n",
      "Epoch 215/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4406 - accuracy: 0.7959 - val_loss: 0.4575 - val_accuracy: 0.7763\n",
      "Epoch 216/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4416 - accuracy: 0.7984 - val_loss: 0.5333 - val_accuracy: 0.7602\n",
      "Epoch 217/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4393 - accuracy: 0.7919 - val_loss: 0.4558 - val_accuracy: 0.7786\n",
      "Epoch 218/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4409 - accuracy: 0.7934 - val_loss: 0.4479 - val_accuracy: 0.7809\n",
      "Epoch 219/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4415 - accuracy: 0.7948 - val_loss: 0.4571 - val_accuracy: 0.7757\n",
      "Epoch 220/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4363 - accuracy: 0.7922 - val_loss: 0.4588 - val_accuracy: 0.7723\n",
      "Epoch 221/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4345 - accuracy: 0.7965 - val_loss: 0.4474 - val_accuracy: 0.7792\n",
      "Epoch 222/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4397 - accuracy: 0.7952 - val_loss: 0.4500 - val_accuracy: 0.7786\n",
      "Epoch 223/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4399 - accuracy: 0.7916 - val_loss: 0.4488 - val_accuracy: 0.7792\n",
      "Epoch 224/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4431 - accuracy: 0.7877 - val_loss: 0.4428 - val_accuracy: 0.7821\n",
      "Epoch 225/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4351 - accuracy: 0.7977 - val_loss: 0.4489 - val_accuracy: 0.7734\n",
      "Epoch 226/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4409 - accuracy: 0.7961 - val_loss: 0.4547 - val_accuracy: 0.7746\n",
      "Epoch 227/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4429 - accuracy: 0.7890 - val_loss: 0.4458 - val_accuracy: 0.7723\n",
      "Epoch 228/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4381 - accuracy: 0.7978 - val_loss: 0.4448 - val_accuracy: 0.7780\n",
      "Epoch 229/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4377 - accuracy: 0.7947 - val_loss: 0.4430 - val_accuracy: 0.7769\n",
      "Epoch 230/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4354 - accuracy: 0.7968 - val_loss: 0.4416 - val_accuracy: 0.7769\n",
      "Epoch 231/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4388 - accuracy: 0.7967 - val_loss: 0.4382 - val_accuracy: 0.7775\n",
      "Epoch 232/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4351 - accuracy: 0.7981 - val_loss: 0.4386 - val_accuracy: 0.7752\n",
      "Epoch 233/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4383 - accuracy: 0.7975 - val_loss: 0.4461 - val_accuracy: 0.7757\n",
      "Epoch 234/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4410 - accuracy: 0.7936 - val_loss: 0.4437 - val_accuracy: 0.7809\n",
      "Epoch 235/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4433 - accuracy: 0.7957 - val_loss: 0.4458 - val_accuracy: 0.7861\n",
      "Epoch 236/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4469 - accuracy: 0.7899 - val_loss: 0.4452 - val_accuracy: 0.7775\n",
      "Epoch 237/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4370 - accuracy: 0.7959 - val_loss: 0.4429 - val_accuracy: 0.7809\n",
      "Epoch 238/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4392 - accuracy: 0.7941 - val_loss: 0.4510 - val_accuracy: 0.7723\n",
      "Epoch 239/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4424 - accuracy: 0.7971 - val_loss: 0.4554 - val_accuracy: 0.7660\n",
      "Epoch 240/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4385 - accuracy: 0.7928 - val_loss: 0.4402 - val_accuracy: 0.7752\n",
      "Epoch 241/1500\n",
      "28/28 [==============================] - 2s 64ms/step - loss: 0.4342 - accuracy: 0.7982 - val_loss: 0.4372 - val_accuracy: 0.7803\n",
      "Epoch 242/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4417 - accuracy: 0.7949 - val_loss: 0.4421 - val_accuracy: 0.7775\n",
      "Epoch 243/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4395 - accuracy: 0.7944 - val_loss: 0.4533 - val_accuracy: 0.7706\n",
      "Epoch 244/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4399 - accuracy: 0.7949 - val_loss: 0.4419 - val_accuracy: 0.7798\n",
      "Epoch 245/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4383 - accuracy: 0.7975 - val_loss: 0.4553 - val_accuracy: 0.7700\n",
      "Epoch 246/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4428 - accuracy: 0.7941 - val_loss: 0.4408 - val_accuracy: 0.7815\n",
      "Epoch 247/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4357 - accuracy: 0.7958 - val_loss: 0.4434 - val_accuracy: 0.7815\n",
      "Epoch 248/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4395 - accuracy: 0.7962 - val_loss: 0.4503 - val_accuracy: 0.7688\n",
      "Epoch 249/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4390 - accuracy: 0.7935 - val_loss: 0.4421 - val_accuracy: 0.7798\n",
      "Epoch 250/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4347 - accuracy: 0.7987 - val_loss: 0.4390 - val_accuracy: 0.7832\n",
      "Epoch 251/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4385 - accuracy: 0.7959 - val_loss: 0.4399 - val_accuracy: 0.7775\n",
      "Epoch 252/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4430 - accuracy: 0.7948 - val_loss: 0.4410 - val_accuracy: 0.7786\n",
      "Epoch 253/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4340 - accuracy: 0.7985 - val_loss: 0.4400 - val_accuracy: 0.7815\n",
      "Epoch 254/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4407 - accuracy: 0.7972 - val_loss: 0.4542 - val_accuracy: 0.7688\n",
      "Epoch 255/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4408 - accuracy: 0.7952 - val_loss: 0.4475 - val_accuracy: 0.7815\n",
      "Epoch 256/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4411 - accuracy: 0.7938 - val_loss: 0.4481 - val_accuracy: 0.7706\n",
      "Epoch 257/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4354 - accuracy: 0.7948 - val_loss: 0.4485 - val_accuracy: 0.7752\n",
      "Epoch 258/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4376 - accuracy: 0.7970 - val_loss: 0.4543 - val_accuracy: 0.7602\n",
      "Epoch 259/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4430 - accuracy: 0.7922 - val_loss: 0.4491 - val_accuracy: 0.7792\n",
      "Epoch 260/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4313 - accuracy: 0.7952 - val_loss: 0.4515 - val_accuracy: 0.7815\n",
      "Epoch 261/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4355 - accuracy: 0.8005 - val_loss: 0.4477 - val_accuracy: 0.7792\n",
      "Epoch 262/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4339 - accuracy: 0.7958 - val_loss: 0.4511 - val_accuracy: 0.7792\n",
      "Epoch 263/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4396 - accuracy: 0.7955 - val_loss: 0.4421 - val_accuracy: 0.7832\n",
      "Epoch 264/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4382 - accuracy: 0.7945 - val_loss: 0.4488 - val_accuracy: 0.7763\n",
      "Epoch 265/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4360 - accuracy: 0.7967 - val_loss: 0.4600 - val_accuracy: 0.7717\n",
      "Epoch 266/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4348 - accuracy: 0.7977 - val_loss: 0.4454 - val_accuracy: 0.7832\n",
      "Epoch 267/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4378 - accuracy: 0.7961 - val_loss: 0.4497 - val_accuracy: 0.7729\n",
      "Epoch 268/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4364 - accuracy: 0.7938 - val_loss: 0.4479 - val_accuracy: 0.7723\n",
      "Epoch 269/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4345 - accuracy: 0.7970 - val_loss: 0.4645 - val_accuracy: 0.7683\n",
      "Epoch 270/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4385 - accuracy: 0.7980 - val_loss: 0.4557 - val_accuracy: 0.7711\n",
      "Epoch 271/1500\n",
      "28/28 [==============================] - 2s 62ms/step - loss: 0.4372 - accuracy: 0.7959 - val_loss: 0.4434 - val_accuracy: 0.7792\n",
      "Epoch 272/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4335 - accuracy: 0.7951 - val_loss: 0.4547 - val_accuracy: 0.7740\n",
      "Epoch 273/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4428 - accuracy: 0.7934 - val_loss: 0.4439 - val_accuracy: 0.7798\n",
      "Epoch 274/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4341 - accuracy: 0.7967 - val_loss: 0.4544 - val_accuracy: 0.7700\n",
      "Epoch 275/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4343 - accuracy: 0.8007 - val_loss: 0.4424 - val_accuracy: 0.7815\n",
      "Epoch 276/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4356 - accuracy: 0.7938 - val_loss: 0.4434 - val_accuracy: 0.7809\n",
      "Epoch 277/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4348 - accuracy: 0.7970 - val_loss: 0.4419 - val_accuracy: 0.7832\n",
      "Epoch 278/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4363 - accuracy: 0.7974 - val_loss: 0.4443 - val_accuracy: 0.7861\n",
      "Epoch 279/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4342 - accuracy: 0.7978 - val_loss: 0.4455 - val_accuracy: 0.7775\n",
      "Epoch 280/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4357 - accuracy: 0.7980 - val_loss: 0.4477 - val_accuracy: 0.7763\n",
      "Epoch 281/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4367 - accuracy: 0.7959 - val_loss: 0.4416 - val_accuracy: 0.7792\n",
      "Epoch 282/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4341 - accuracy: 0.7967 - val_loss: 0.4404 - val_accuracy: 0.7803\n",
      "Epoch 283/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4393 - accuracy: 0.7993 - val_loss: 0.4437 - val_accuracy: 0.7769\n",
      "Epoch 284/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4336 - accuracy: 0.7982 - val_loss: 0.4446 - val_accuracy: 0.7734\n",
      "Epoch 285/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4401 - accuracy: 0.7975 - val_loss: 0.4455 - val_accuracy: 0.7740\n",
      "Epoch 286/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4395 - accuracy: 0.7939 - val_loss: 0.4432 - val_accuracy: 0.7763\n",
      "Epoch 287/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4373 - accuracy: 0.7971 - val_loss: 0.4550 - val_accuracy: 0.7775\n",
      "Epoch 288/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4419 - accuracy: 0.7959 - val_loss: 0.4438 - val_accuracy: 0.7786\n",
      "Epoch 289/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4382 - accuracy: 0.7926 - val_loss: 0.4384 - val_accuracy: 0.7815\n",
      "Epoch 290/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4381 - accuracy: 0.7970 - val_loss: 0.4432 - val_accuracy: 0.7798\n",
      "Epoch 291/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4407 - accuracy: 0.7945 - val_loss: 0.4377 - val_accuracy: 0.7832\n",
      "Epoch 292/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4359 - accuracy: 0.7972 - val_loss: 0.4376 - val_accuracy: 0.7803\n",
      "Epoch 293/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4367 - accuracy: 0.7972 - val_loss: 0.4416 - val_accuracy: 0.7786\n",
      "Epoch 294/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4384 - accuracy: 0.7961 - val_loss: 0.4516 - val_accuracy: 0.7798\n",
      "Epoch 295/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4423 - accuracy: 0.7945 - val_loss: 0.4606 - val_accuracy: 0.7677\n",
      "Epoch 296/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4355 - accuracy: 0.7949 - val_loss: 0.4426 - val_accuracy: 0.7775\n",
      "Epoch 297/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4319 - accuracy: 0.8001 - val_loss: 0.4481 - val_accuracy: 0.7752\n",
      "Epoch 298/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4372 - accuracy: 0.7967 - val_loss: 0.4494 - val_accuracy: 0.7792\n",
      "Epoch 299/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4354 - accuracy: 0.7975 - val_loss: 0.4665 - val_accuracy: 0.7648\n",
      "Epoch 300/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4326 - accuracy: 0.7965 - val_loss: 0.4476 - val_accuracy: 0.7775\n",
      "Epoch 301/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4354 - accuracy: 0.8028 - val_loss: 0.4520 - val_accuracy: 0.7775\n",
      "Epoch 302/1500\n",
      "28/28 [==============================] - 2s 59ms/step - loss: 0.4317 - accuracy: 0.7957 - val_loss: 0.4543 - val_accuracy: 0.7752\n",
      "Epoch 303/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4367 - accuracy: 0.7962 - val_loss: 0.4413 - val_accuracy: 0.7815\n",
      "Epoch 304/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4359 - accuracy: 0.7964 - val_loss: 0.4523 - val_accuracy: 0.7740\n",
      "Epoch 305/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4381 - accuracy: 0.7959 - val_loss: 0.4484 - val_accuracy: 0.7826\n",
      "Epoch 306/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4364 - accuracy: 0.7975 - val_loss: 0.4421 - val_accuracy: 0.7809\n",
      "Epoch 307/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4322 - accuracy: 0.7978 - val_loss: 0.4469 - val_accuracy: 0.7809\n",
      "Epoch 308/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4364 - accuracy: 0.7975 - val_loss: 0.4439 - val_accuracy: 0.7821\n",
      "Epoch 309/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4350 - accuracy: 0.7967 - val_loss: 0.4502 - val_accuracy: 0.7792\n",
      "Epoch 310/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4462 - accuracy: 0.7925 - val_loss: 0.4493 - val_accuracy: 0.7763\n",
      "Epoch 311/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4394 - accuracy: 0.7938 - val_loss: 0.4511 - val_accuracy: 0.7688\n",
      "Epoch 312/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4350 - accuracy: 0.7958 - val_loss: 0.4470 - val_accuracy: 0.7763\n",
      "Epoch 313/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4328 - accuracy: 0.7968 - val_loss: 0.4501 - val_accuracy: 0.7729\n",
      "Epoch 314/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4401 - accuracy: 0.7929 - val_loss: 0.4559 - val_accuracy: 0.7700\n",
      "Epoch 315/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4359 - accuracy: 0.7998 - val_loss: 0.4579 - val_accuracy: 0.7769\n",
      "Epoch 316/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4392 - accuracy: 0.7955 - val_loss: 0.4492 - val_accuracy: 0.7786\n",
      "Epoch 317/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4421 - accuracy: 0.7944 - val_loss: 0.4416 - val_accuracy: 0.7826\n",
      "Epoch 318/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4354 - accuracy: 0.7968 - val_loss: 0.4441 - val_accuracy: 0.7815\n",
      "Epoch 319/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4428 - accuracy: 0.7932 - val_loss: 0.4500 - val_accuracy: 0.7717\n",
      "Epoch 320/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4414 - accuracy: 0.7935 - val_loss: 0.4446 - val_accuracy: 0.7711\n",
      "Epoch 321/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4394 - accuracy: 0.7967 - val_loss: 0.4479 - val_accuracy: 0.7746\n",
      "Epoch 322/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4397 - accuracy: 0.7931 - val_loss: 0.4467 - val_accuracy: 0.7798\n",
      "Epoch 323/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4341 - accuracy: 0.7998 - val_loss: 0.4430 - val_accuracy: 0.7763\n",
      "Epoch 324/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4335 - accuracy: 0.7985 - val_loss: 0.4487 - val_accuracy: 0.7700\n",
      "Epoch 325/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4381 - accuracy: 0.7993 - val_loss: 0.4390 - val_accuracy: 0.7757\n",
      "Epoch 326/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4354 - accuracy: 0.7974 - val_loss: 0.4406 - val_accuracy: 0.7769\n",
      "Epoch 327/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4350 - accuracy: 0.7981 - val_loss: 0.4408 - val_accuracy: 0.7815\n",
      "Epoch 328/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4380 - accuracy: 0.7962 - val_loss: 0.4456 - val_accuracy: 0.7711\n",
      "Epoch 329/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4336 - accuracy: 0.7994 - val_loss: 0.4481 - val_accuracy: 0.7717\n",
      "Epoch 330/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4352 - accuracy: 0.7959 - val_loss: 0.4431 - val_accuracy: 0.7792\n",
      "Epoch 331/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4346 - accuracy: 0.7962 - val_loss: 0.4449 - val_accuracy: 0.7769\n",
      "Epoch 332/1500\n",
      "28/28 [==============================] - 2s 63ms/step - loss: 0.4337 - accuracy: 0.7981 - val_loss: 0.4449 - val_accuracy: 0.7769\n",
      "Epoch 333/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4331 - accuracy: 0.7970 - val_loss: 0.4436 - val_accuracy: 0.7821\n",
      "Epoch 334/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4329 - accuracy: 0.8001 - val_loss: 0.4489 - val_accuracy: 0.7734\n",
      "Epoch 335/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4349 - accuracy: 0.7988 - val_loss: 0.4494 - val_accuracy: 0.7740\n",
      "Epoch 336/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4331 - accuracy: 0.7975 - val_loss: 0.4493 - val_accuracy: 0.7740\n",
      "Epoch 337/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4401 - accuracy: 0.7961 - val_loss: 0.4461 - val_accuracy: 0.7803\n",
      "Epoch 338/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4364 - accuracy: 0.7970 - val_loss: 0.4438 - val_accuracy: 0.7821\n",
      "Epoch 339/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4328 - accuracy: 0.7984 - val_loss: 0.4500 - val_accuracy: 0.7752\n",
      "Epoch 340/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4338 - accuracy: 0.7997 - val_loss: 0.4474 - val_accuracy: 0.7861\n",
      "Epoch 341/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4369 - accuracy: 0.7935 - val_loss: 0.4485 - val_accuracy: 0.7792\n",
      "Epoch 342/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4326 - accuracy: 0.7993 - val_loss: 0.4477 - val_accuracy: 0.7775\n",
      "Epoch 343/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4348 - accuracy: 0.7952 - val_loss: 0.4446 - val_accuracy: 0.7780\n",
      "Epoch 344/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4351 - accuracy: 0.7980 - val_loss: 0.4441 - val_accuracy: 0.7746\n",
      "Epoch 345/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4307 - accuracy: 0.8001 - val_loss: 0.4469 - val_accuracy: 0.7792\n",
      "Epoch 346/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4317 - accuracy: 0.8003 - val_loss: 0.4511 - val_accuracy: 0.7757\n",
      "Epoch 347/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4335 - accuracy: 0.7972 - val_loss: 0.4440 - val_accuracy: 0.7775\n",
      "Epoch 348/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4298 - accuracy: 0.7975 - val_loss: 0.4487 - val_accuracy: 0.7798\n",
      "Epoch 349/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4366 - accuracy: 0.7954 - val_loss: 0.4440 - val_accuracy: 0.7780\n",
      "Epoch 350/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4311 - accuracy: 0.7991 - val_loss: 0.4496 - val_accuracy: 0.7826\n",
      "Epoch 351/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4370 - accuracy: 0.7967 - val_loss: 0.4625 - val_accuracy: 0.7821\n",
      "Epoch 352/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4393 - accuracy: 0.7962 - val_loss: 0.4669 - val_accuracy: 0.7562\n",
      "Epoch 353/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4399 - accuracy: 0.7971 - val_loss: 0.4450 - val_accuracy: 0.7798\n",
      "Epoch 354/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4373 - accuracy: 0.7975 - val_loss: 0.4479 - val_accuracy: 0.7826\n",
      "Epoch 355/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4328 - accuracy: 0.8017 - val_loss: 0.4507 - val_accuracy: 0.7648\n",
      "Epoch 356/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4356 - accuracy: 0.7977 - val_loss: 0.4412 - val_accuracy: 0.7849\n",
      "Epoch 357/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4300 - accuracy: 0.7991 - val_loss: 0.4449 - val_accuracy: 0.7763\n",
      "Epoch 358/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4334 - accuracy: 0.8013 - val_loss: 0.4414 - val_accuracy: 0.7838\n",
      "Epoch 359/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4319 - accuracy: 0.8007 - val_loss: 0.4408 - val_accuracy: 0.7815\n",
      "Epoch 360/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4426 - accuracy: 0.7942 - val_loss: 0.4481 - val_accuracy: 0.7780\n",
      "Epoch 361/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4350 - accuracy: 0.7990 - val_loss: 0.4438 - val_accuracy: 0.7849\n",
      "Epoch 362/1500\n",
      "28/28 [==============================] - 2s 63ms/step - loss: 0.4310 - accuracy: 0.7984 - val_loss: 0.4454 - val_accuracy: 0.7792\n",
      "Epoch 363/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4323 - accuracy: 0.7949 - val_loss: 0.4579 - val_accuracy: 0.7700\n",
      "Epoch 364/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4347 - accuracy: 0.7948 - val_loss: 0.4440 - val_accuracy: 0.7798\n",
      "Epoch 365/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4331 - accuracy: 0.7968 - val_loss: 0.4533 - val_accuracy: 0.7763\n",
      "Epoch 366/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4496 - accuracy: 0.7895 - val_loss: 0.4715 - val_accuracy: 0.7757\n",
      "Epoch 367/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4358 - accuracy: 0.7955 - val_loss: 0.4536 - val_accuracy: 0.7458\n",
      "Epoch 368/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4323 - accuracy: 0.7978 - val_loss: 0.4443 - val_accuracy: 0.7838\n",
      "Epoch 369/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4347 - accuracy: 0.7975 - val_loss: 0.4518 - val_accuracy: 0.7792\n",
      "Epoch 370/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4324 - accuracy: 0.7975 - val_loss: 0.4477 - val_accuracy: 0.7757\n",
      "Epoch 371/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4313 - accuracy: 0.7984 - val_loss: 0.4424 - val_accuracy: 0.7849\n",
      "Epoch 372/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4296 - accuracy: 0.8001 - val_loss: 0.4495 - val_accuracy: 0.7688\n",
      "Epoch 373/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4331 - accuracy: 0.7994 - val_loss: 0.4403 - val_accuracy: 0.7855\n",
      "Epoch 374/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4353 - accuracy: 0.7971 - val_loss: 0.4453 - val_accuracy: 0.7717\n",
      "Epoch 375/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4296 - accuracy: 0.8004 - val_loss: 0.4423 - val_accuracy: 0.7838\n",
      "Epoch 376/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4343 - accuracy: 0.7977 - val_loss: 0.4418 - val_accuracy: 0.7786\n",
      "Epoch 377/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4323 - accuracy: 0.8008 - val_loss: 0.4464 - val_accuracy: 0.7723\n",
      "Epoch 378/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4382 - accuracy: 0.7928 - val_loss: 0.4425 - val_accuracy: 0.7838\n",
      "Epoch 379/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4562 - accuracy: 0.7902 - val_loss: 0.5194 - val_accuracy: 0.7631\n",
      "Epoch 380/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4506 - accuracy: 0.7853 - val_loss: 0.4913 - val_accuracy: 0.7619\n",
      "Epoch 381/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4353 - accuracy: 0.7970 - val_loss: 0.4831 - val_accuracy: 0.7665\n",
      "Epoch 382/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4400 - accuracy: 0.7923 - val_loss: 0.4511 - val_accuracy: 0.7815\n",
      "Epoch 383/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4345 - accuracy: 0.7984 - val_loss: 0.4541 - val_accuracy: 0.7775\n",
      "Epoch 384/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4362 - accuracy: 0.8001 - val_loss: 0.4493 - val_accuracy: 0.7803\n",
      "Epoch 385/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4345 - accuracy: 0.7948 - val_loss: 0.4606 - val_accuracy: 0.7677\n",
      "Epoch 386/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4340 - accuracy: 0.7965 - val_loss: 0.4568 - val_accuracy: 0.7654\n",
      "Epoch 387/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4400 - accuracy: 0.7952 - val_loss: 0.4722 - val_accuracy: 0.7504\n",
      "Epoch 388/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4319 - accuracy: 0.7995 - val_loss: 0.4807 - val_accuracy: 0.7435\n",
      "Epoch 389/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4334 - accuracy: 0.7988 - val_loss: 0.4779 - val_accuracy: 0.7389\n",
      "Epoch 390/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4348 - accuracy: 0.7971 - val_loss: 0.4651 - val_accuracy: 0.7596\n",
      "Epoch 391/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4354 - accuracy: 0.7967 - val_loss: 0.4544 - val_accuracy: 0.7642\n",
      "Epoch 392/1500\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.4312 - accuracy: 0.7971 - val_loss: 0.4422 - val_accuracy: 0.7752\n",
      "Epoch 393/1500\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.4333 - accuracy: 0.7980 - val_loss: 0.4516 - val_accuracy: 0.7671\n",
      "Epoch 394/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4293 - accuracy: 0.8004 - val_loss: 0.4456 - val_accuracy: 0.7723\n",
      "Epoch 395/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4309 - accuracy: 0.8004 - val_loss: 0.4432 - val_accuracy: 0.7752\n",
      "Epoch 396/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4335 - accuracy: 0.7990 - val_loss: 0.4395 - val_accuracy: 0.7786\n",
      "Epoch 397/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4322 - accuracy: 0.7974 - val_loss: 0.4383 - val_accuracy: 0.7803\n",
      "Epoch 398/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4327 - accuracy: 0.8000 - val_loss: 0.4489 - val_accuracy: 0.7700\n",
      "Epoch 399/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4337 - accuracy: 0.8007 - val_loss: 0.4619 - val_accuracy: 0.7510\n",
      "Epoch 400/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4324 - accuracy: 0.7958 - val_loss: 0.4423 - val_accuracy: 0.7752\n",
      "Epoch 401/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4320 - accuracy: 0.8014 - val_loss: 0.4420 - val_accuracy: 0.7792\n",
      "Epoch 402/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4322 - accuracy: 0.7990 - val_loss: 0.4427 - val_accuracy: 0.7757\n",
      "Epoch 403/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4267 - accuracy: 0.7975 - val_loss: 0.4471 - val_accuracy: 0.7786\n",
      "Epoch 404/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4295 - accuracy: 0.7990 - val_loss: 0.4456 - val_accuracy: 0.7826\n",
      "Epoch 405/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4374 - accuracy: 0.7938 - val_loss: 0.4441 - val_accuracy: 0.7780\n",
      "Epoch 406/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4376 - accuracy: 0.7968 - val_loss: 0.4440 - val_accuracy: 0.7775\n",
      "Epoch 407/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4320 - accuracy: 0.7990 - val_loss: 0.4454 - val_accuracy: 0.7780\n",
      "Epoch 408/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4304 - accuracy: 0.8008 - val_loss: 0.4390 - val_accuracy: 0.7821\n",
      "Epoch 409/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4317 - accuracy: 0.8014 - val_loss: 0.4458 - val_accuracy: 0.7769\n",
      "Epoch 410/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4301 - accuracy: 0.8004 - val_loss: 0.4453 - val_accuracy: 0.7815\n",
      "Epoch 411/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4331 - accuracy: 0.7998 - val_loss: 0.4520 - val_accuracy: 0.7660\n",
      "Epoch 412/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4287 - accuracy: 0.7970 - val_loss: 0.4578 - val_accuracy: 0.7734\n",
      "Epoch 413/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4342 - accuracy: 0.7991 - val_loss: 0.4441 - val_accuracy: 0.7740\n",
      "Epoch 414/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4285 - accuracy: 0.7985 - val_loss: 0.4400 - val_accuracy: 0.7815\n",
      "Epoch 415/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4300 - accuracy: 0.7961 - val_loss: 0.4501 - val_accuracy: 0.7769\n",
      "Epoch 416/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4298 - accuracy: 0.7993 - val_loss: 0.4476 - val_accuracy: 0.7711\n",
      "Epoch 417/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4309 - accuracy: 0.8000 - val_loss: 0.4376 - val_accuracy: 0.7826\n",
      "Epoch 418/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4322 - accuracy: 0.8007 - val_loss: 0.4492 - val_accuracy: 0.7740\n",
      "Epoch 419/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4313 - accuracy: 0.7965 - val_loss: 0.4486 - val_accuracy: 0.7786\n",
      "Epoch 420/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4348 - accuracy: 0.7991 - val_loss: 0.4521 - val_accuracy: 0.7688\n",
      "Epoch 421/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4329 - accuracy: 0.8005 - val_loss: 0.4441 - val_accuracy: 0.7815\n",
      "Epoch 422/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4302 - accuracy: 0.7991 - val_loss: 0.4402 - val_accuracy: 0.7832\n",
      "Epoch 423/1500\n",
      "28/28 [==============================] - 2s 63ms/step - loss: 0.4336 - accuracy: 0.7971 - val_loss: 0.4461 - val_accuracy: 0.7780\n",
      "Epoch 424/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4270 - accuracy: 0.8000 - val_loss: 0.4396 - val_accuracy: 0.7855\n",
      "Epoch 425/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4304 - accuracy: 0.7997 - val_loss: 0.4434 - val_accuracy: 0.7740\n",
      "Epoch 426/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4299 - accuracy: 0.7972 - val_loss: 0.4402 - val_accuracy: 0.7763\n",
      "Epoch 427/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4298 - accuracy: 0.7975 - val_loss: 0.4466 - val_accuracy: 0.7780\n",
      "Epoch 428/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4254 - accuracy: 0.8027 - val_loss: 0.4428 - val_accuracy: 0.7792\n",
      "Epoch 429/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4352 - accuracy: 0.7991 - val_loss: 0.4639 - val_accuracy: 0.7596\n",
      "Epoch 430/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4345 - accuracy: 0.7980 - val_loss: 0.4442 - val_accuracy: 0.7757\n",
      "Epoch 431/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4308 - accuracy: 0.8014 - val_loss: 0.4452 - val_accuracy: 0.7792\n",
      "Epoch 432/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.4484 - val_accuracy: 0.7780\n",
      "Epoch 433/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4318 - accuracy: 0.7988 - val_loss: 0.4445 - val_accuracy: 0.7769\n",
      "Epoch 434/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4334 - accuracy: 0.7980 - val_loss: 0.4471 - val_accuracy: 0.7769\n",
      "Epoch 435/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4313 - accuracy: 0.7984 - val_loss: 0.4505 - val_accuracy: 0.7769\n",
      "Epoch 436/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4319 - accuracy: 0.8004 - val_loss: 0.4447 - val_accuracy: 0.7780\n",
      "Epoch 437/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4336 - accuracy: 0.7988 - val_loss: 0.4459 - val_accuracy: 0.7798\n",
      "Epoch 438/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4317 - accuracy: 0.7968 - val_loss: 0.4426 - val_accuracy: 0.7792\n",
      "Epoch 439/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4253 - accuracy: 0.8014 - val_loss: 0.4486 - val_accuracy: 0.7815\n",
      "Epoch 440/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4298 - accuracy: 0.8011 - val_loss: 0.4482 - val_accuracy: 0.7826\n",
      "Epoch 441/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4317 - accuracy: 0.7972 - val_loss: 0.4418 - val_accuracy: 0.7798\n",
      "Epoch 442/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4281 - accuracy: 0.8010 - val_loss: 0.4482 - val_accuracy: 0.7740\n",
      "Epoch 443/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4286 - accuracy: 0.8018 - val_loss: 0.4531 - val_accuracy: 0.7803\n",
      "Epoch 444/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4293 - accuracy: 0.8001 - val_loss: 0.4585 - val_accuracy: 0.7683\n",
      "Epoch 445/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4306 - accuracy: 0.7980 - val_loss: 0.4446 - val_accuracy: 0.7798\n",
      "Epoch 446/1500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4330 - accuracy: 0.7991 - val_loss: 0.4434 - val_accuracy: 0.7786\n",
      "Epoch 447/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4291 - accuracy: 0.7978 - val_loss: 0.4410 - val_accuracy: 0.7809\n",
      "Epoch 448/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4296 - accuracy: 0.7968 - val_loss: 0.4465 - val_accuracy: 0.7844\n",
      "Epoch 449/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4270 - accuracy: 0.8007 - val_loss: 0.4491 - val_accuracy: 0.7809\n",
      "Epoch 450/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4269 - accuracy: 0.8028 - val_loss: 0.4468 - val_accuracy: 0.7763\n",
      "Epoch 451/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4287 - accuracy: 0.7997 - val_loss: 0.4403 - val_accuracy: 0.7821\n",
      "Epoch 452/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4281 - accuracy: 0.8014 - val_loss: 0.4481 - val_accuracy: 0.7752\n",
      "Epoch 453/1500\n",
      "28/28 [==============================] - 2s 63ms/step - loss: 0.4298 - accuracy: 0.8010 - val_loss: 0.4488 - val_accuracy: 0.7821\n",
      "Epoch 454/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4283 - accuracy: 0.7957 - val_loss: 0.4535 - val_accuracy: 0.7792\n",
      "Epoch 455/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4290 - accuracy: 0.7997 - val_loss: 0.4435 - val_accuracy: 0.7849\n",
      "Epoch 456/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4282 - accuracy: 0.8020 - val_loss: 0.4464 - val_accuracy: 0.7729\n",
      "Epoch 457/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4268 - accuracy: 0.8020 - val_loss: 0.4486 - val_accuracy: 0.7775\n",
      "Epoch 458/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4291 - accuracy: 0.8014 - val_loss: 0.4433 - val_accuracy: 0.7775\n",
      "Epoch 459/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4277 - accuracy: 0.7964 - val_loss: 0.4477 - val_accuracy: 0.7763\n",
      "Epoch 460/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4291 - accuracy: 0.7952 - val_loss: 0.4467 - val_accuracy: 0.7821\n",
      "Epoch 461/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4318 - accuracy: 0.8003 - val_loss: 0.4388 - val_accuracy: 0.7792\n",
      "Epoch 462/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4329 - accuracy: 0.7991 - val_loss: 0.4427 - val_accuracy: 0.7775\n",
      "Epoch 463/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4271 - accuracy: 0.7987 - val_loss: 0.4432 - val_accuracy: 0.7752\n",
      "Epoch 464/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4287 - accuracy: 0.8014 - val_loss: 0.4417 - val_accuracy: 0.7780\n",
      "Epoch 465/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4316 - accuracy: 0.7998 - val_loss: 0.4416 - val_accuracy: 0.7798\n",
      "Epoch 466/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.4490 - val_accuracy: 0.7757\n",
      "Epoch 467/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4274 - accuracy: 0.8021 - val_loss: 0.4392 - val_accuracy: 0.7844\n",
      "Epoch 468/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4258 - accuracy: 0.7954 - val_loss: 0.4454 - val_accuracy: 0.7746\n",
      "Epoch 469/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4293 - accuracy: 0.7982 - val_loss: 0.4413 - val_accuracy: 0.7803\n",
      "Epoch 470/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4255 - accuracy: 0.8013 - val_loss: 0.4426 - val_accuracy: 0.7849\n",
      "Epoch 471/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4279 - accuracy: 0.7978 - val_loss: 0.4418 - val_accuracy: 0.7832\n",
      "Epoch 472/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4307 - accuracy: 0.7985 - val_loss: 0.4394 - val_accuracy: 0.7809\n",
      "Epoch 473/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4249 - accuracy: 0.8026 - val_loss: 0.4401 - val_accuracy: 0.7809\n",
      "Epoch 474/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4275 - accuracy: 0.7988 - val_loss: 0.4644 - val_accuracy: 0.7798\n",
      "Epoch 475/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4280 - accuracy: 0.8024 - val_loss: 0.4423 - val_accuracy: 0.7752\n",
      "Epoch 476/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4299 - accuracy: 0.8001 - val_loss: 0.4444 - val_accuracy: 0.7798\n",
      "Epoch 477/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4321 - accuracy: 0.8028 - val_loss: 0.4541 - val_accuracy: 0.7809\n",
      "Epoch 478/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4297 - accuracy: 0.7990 - val_loss: 0.4417 - val_accuracy: 0.7884\n",
      "Epoch 479/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4305 - accuracy: 0.8020 - val_loss: 0.4503 - val_accuracy: 0.7769\n",
      "Epoch 480/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4267 - accuracy: 0.8007 - val_loss: 0.4428 - val_accuracy: 0.7861\n",
      "Epoch 481/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4274 - accuracy: 0.7982 - val_loss: 0.4456 - val_accuracy: 0.7757\n",
      "Epoch 482/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4293 - accuracy: 0.7971 - val_loss: 0.4479 - val_accuracy: 0.7769\n",
      "Epoch 483/1500\n",
      "28/28 [==============================] - 2s 63ms/step - loss: 0.4299 - accuracy: 0.7978 - val_loss: 0.4583 - val_accuracy: 0.7683\n",
      "Epoch 484/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4275 - accuracy: 0.8003 - val_loss: 0.4412 - val_accuracy: 0.7798\n",
      "Epoch 485/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4251 - accuracy: 0.7997 - val_loss: 0.4465 - val_accuracy: 0.7798\n",
      "Epoch 486/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4295 - accuracy: 0.7980 - val_loss: 0.4427 - val_accuracy: 0.7792\n",
      "Epoch 487/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4290 - accuracy: 0.7982 - val_loss: 0.4411 - val_accuracy: 0.7821\n",
      "Epoch 488/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4275 - accuracy: 0.7988 - val_loss: 0.4478 - val_accuracy: 0.7780\n",
      "Epoch 489/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4289 - accuracy: 0.7967 - val_loss: 0.4388 - val_accuracy: 0.7786\n",
      "Epoch 490/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4246 - accuracy: 0.8013 - val_loss: 0.4452 - val_accuracy: 0.7746\n",
      "Epoch 491/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4265 - accuracy: 0.7993 - val_loss: 0.4475 - val_accuracy: 0.7729\n",
      "Epoch 492/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4267 - accuracy: 0.7987 - val_loss: 0.4448 - val_accuracy: 0.7826\n",
      "Epoch 493/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4305 - accuracy: 0.7988 - val_loss: 0.4413 - val_accuracy: 0.7786\n",
      "Epoch 494/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4284 - accuracy: 0.8020 - val_loss: 0.4575 - val_accuracy: 0.7694\n",
      "Epoch 495/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4270 - accuracy: 0.8008 - val_loss: 0.4408 - val_accuracy: 0.7780\n",
      "Epoch 496/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4319 - accuracy: 0.7997 - val_loss: 0.4411 - val_accuracy: 0.7798\n",
      "Epoch 497/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4303 - accuracy: 0.8023 - val_loss: 0.4466 - val_accuracy: 0.7775\n",
      "Epoch 498/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4265 - accuracy: 0.7985 - val_loss: 0.4470 - val_accuracy: 0.7763\n",
      "Epoch 499/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4268 - accuracy: 0.8013 - val_loss: 0.4427 - val_accuracy: 0.7821\n",
      "Epoch 500/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4270 - accuracy: 0.7974 - val_loss: 0.4415 - val_accuracy: 0.7803\n",
      "Epoch 501/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4294 - accuracy: 0.8024 - val_loss: 0.4542 - val_accuracy: 0.7694\n",
      "Epoch 502/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4270 - accuracy: 0.7993 - val_loss: 0.4476 - val_accuracy: 0.7769\n",
      "Epoch 503/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4271 - accuracy: 0.7987 - val_loss: 0.4434 - val_accuracy: 0.7780\n",
      "Epoch 504/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.4418 - val_accuracy: 0.7832\n",
      "Epoch 505/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4226 - accuracy: 0.8008 - val_loss: 0.4576 - val_accuracy: 0.7700\n",
      "Epoch 506/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4290 - accuracy: 0.7968 - val_loss: 0.4388 - val_accuracy: 0.7832\n",
      "Epoch 507/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4236 - accuracy: 0.8021 - val_loss: 0.4588 - val_accuracy: 0.7579\n",
      "Epoch 508/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4256 - accuracy: 0.7993 - val_loss: 0.4428 - val_accuracy: 0.7826\n",
      "Epoch 509/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4325 - accuracy: 0.8040 - val_loss: 0.4622 - val_accuracy: 0.7769\n",
      "Epoch 510/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4264 - accuracy: 0.8031 - val_loss: 0.4495 - val_accuracy: 0.7803\n",
      "Epoch 511/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4270 - accuracy: 0.8007 - val_loss: 0.4477 - val_accuracy: 0.7803\n",
      "Epoch 512/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4317 - accuracy: 0.7993 - val_loss: 0.4648 - val_accuracy: 0.7556\n",
      "Epoch 513/1500\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.4316 - accuracy: 0.8001 - val_loss: 0.4457 - val_accuracy: 0.7803\n",
      "Epoch 514/1500\n",
      "28/28 [==============================] - 2s 56ms/step - loss: 0.4270 - accuracy: 0.8034 - val_loss: 0.4485 - val_accuracy: 0.7752\n",
      "Epoch 515/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4234 - accuracy: 0.8014 - val_loss: 0.4405 - val_accuracy: 0.7844\n",
      "Epoch 516/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4199 - accuracy: 0.8044 - val_loss: 0.4520 - val_accuracy: 0.7746\n",
      "Epoch 517/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4273 - accuracy: 0.8013 - val_loss: 0.4437 - val_accuracy: 0.7798\n",
      "Epoch 518/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4249 - accuracy: 0.8040 - val_loss: 0.4383 - val_accuracy: 0.7821\n",
      "Epoch 519/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4234 - accuracy: 0.8026 - val_loss: 0.4471 - val_accuracy: 0.7786\n",
      "Epoch 520/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4302 - accuracy: 0.7977 - val_loss: 0.4465 - val_accuracy: 0.7821\n",
      "Epoch 521/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4296 - accuracy: 0.7998 - val_loss: 0.4418 - val_accuracy: 0.7809\n",
      "Epoch 522/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4244 - accuracy: 0.8028 - val_loss: 0.4465 - val_accuracy: 0.7734\n",
      "Epoch 523/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4277 - accuracy: 0.8003 - val_loss: 0.4387 - val_accuracy: 0.7832\n",
      "Epoch 524/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4285 - accuracy: 0.7997 - val_loss: 0.4434 - val_accuracy: 0.7838\n",
      "Epoch 525/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4254 - accuracy: 0.8017 - val_loss: 0.4554 - val_accuracy: 0.7798\n",
      "Epoch 526/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4227 - accuracy: 0.8001 - val_loss: 0.4526 - val_accuracy: 0.7803\n",
      "Epoch 527/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4337 - accuracy: 0.7965 - val_loss: 0.4460 - val_accuracy: 0.7752\n",
      "Epoch 528/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4231 - accuracy: 0.8034 - val_loss: 0.4480 - val_accuracy: 0.7798\n",
      "Epoch 529/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4252 - accuracy: 0.8017 - val_loss: 0.4426 - val_accuracy: 0.7780\n",
      "Epoch 530/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4234 - accuracy: 0.8028 - val_loss: 0.4381 - val_accuracy: 0.7826\n",
      "Epoch 531/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4224 - accuracy: 0.8017 - val_loss: 0.4354 - val_accuracy: 0.7832\n",
      "Epoch 532/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4279 - accuracy: 0.8021 - val_loss: 0.4407 - val_accuracy: 0.7775\n",
      "Epoch 533/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4272 - accuracy: 0.8011 - val_loss: 0.4415 - val_accuracy: 0.7803\n",
      "Epoch 534/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4283 - accuracy: 0.8027 - val_loss: 0.4399 - val_accuracy: 0.7878\n",
      "Epoch 535/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4228 - accuracy: 0.8026 - val_loss: 0.4415 - val_accuracy: 0.7803\n",
      "Epoch 536/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4267 - accuracy: 0.7968 - val_loss: 0.4450 - val_accuracy: 0.7723\n",
      "Epoch 537/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4256 - accuracy: 0.7998 - val_loss: 0.4587 - val_accuracy: 0.7671\n",
      "Epoch 538/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4258 - accuracy: 0.7997 - val_loss: 0.4593 - val_accuracy: 0.7683\n",
      "Epoch 539/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4291 - accuracy: 0.7994 - val_loss: 0.4447 - val_accuracy: 0.7815\n",
      "Epoch 540/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4296 - accuracy: 0.7984 - val_loss: 0.4433 - val_accuracy: 0.7809\n",
      "Epoch 541/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4237 - accuracy: 0.7994 - val_loss: 0.4497 - val_accuracy: 0.7832\n",
      "Epoch 542/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4261 - accuracy: 0.7990 - val_loss: 0.4463 - val_accuracy: 0.7780\n",
      "Epoch 543/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4260 - accuracy: 0.7981 - val_loss: 0.4502 - val_accuracy: 0.7780\n",
      "Epoch 544/1500\n",
      "28/28 [==============================] - 2s 64ms/step - loss: 0.4322 - accuracy: 0.7951 - val_loss: 0.4606 - val_accuracy: 0.7637\n",
      "Epoch 545/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4285 - accuracy: 0.8063 - val_loss: 0.4414 - val_accuracy: 0.7849\n",
      "Epoch 546/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4265 - accuracy: 0.8021 - val_loss: 0.4430 - val_accuracy: 0.7809\n",
      "Epoch 547/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4249 - accuracy: 0.8043 - val_loss: 0.4506 - val_accuracy: 0.7792\n",
      "Epoch 548/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4276 - accuracy: 0.8036 - val_loss: 0.4453 - val_accuracy: 0.7838\n",
      "Epoch 549/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4204 - accuracy: 0.8028 - val_loss: 0.4466 - val_accuracy: 0.7826\n",
      "Epoch 550/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4255 - accuracy: 0.8016 - val_loss: 0.4595 - val_accuracy: 0.7677\n",
      "Epoch 551/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4224 - accuracy: 0.8011 - val_loss: 0.4436 - val_accuracy: 0.7780\n",
      "Epoch 552/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4289 - accuracy: 0.8018 - val_loss: 0.4428 - val_accuracy: 0.7786\n",
      "Epoch 553/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4294 - accuracy: 0.7987 - val_loss: 0.4488 - val_accuracy: 0.7832\n",
      "Epoch 554/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4255 - accuracy: 0.8008 - val_loss: 0.4386 - val_accuracy: 0.7792\n",
      "Epoch 555/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4264 - accuracy: 0.7997 - val_loss: 0.4430 - val_accuracy: 0.7792\n",
      "Epoch 556/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4259 - accuracy: 0.8034 - val_loss: 0.4398 - val_accuracy: 0.7780\n",
      "Epoch 557/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4267 - accuracy: 0.8017 - val_loss: 0.4466 - val_accuracy: 0.7798\n",
      "Epoch 558/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4251 - accuracy: 0.8016 - val_loss: 0.4476 - val_accuracy: 0.7786\n",
      "Epoch 559/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4216 - accuracy: 0.8059 - val_loss: 0.4411 - val_accuracy: 0.7826\n",
      "Epoch 560/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4243 - accuracy: 0.7993 - val_loss: 0.4440 - val_accuracy: 0.7775\n",
      "Epoch 561/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4251 - accuracy: 0.8059 - val_loss: 0.4759 - val_accuracy: 0.7539\n",
      "Epoch 562/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4238 - accuracy: 0.8018 - val_loss: 0.4408 - val_accuracy: 0.7815\n",
      "Epoch 563/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4236 - accuracy: 0.8000 - val_loss: 0.4383 - val_accuracy: 0.7803\n",
      "Epoch 564/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4264 - accuracy: 0.7997 - val_loss: 0.4395 - val_accuracy: 0.7849\n",
      "Epoch 565/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4232 - accuracy: 0.8016 - val_loss: 0.4515 - val_accuracy: 0.7757\n",
      "Epoch 566/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4211 - accuracy: 0.8010 - val_loss: 0.4497 - val_accuracy: 0.7798\n",
      "Epoch 567/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4283 - accuracy: 0.8036 - val_loss: 0.4487 - val_accuracy: 0.7821\n",
      "Epoch 568/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4251 - accuracy: 0.8028 - val_loss: 0.4527 - val_accuracy: 0.7786\n",
      "Epoch 569/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4201 - accuracy: 0.8041 - val_loss: 0.4481 - val_accuracy: 0.7780\n",
      "Epoch 570/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4289 - accuracy: 0.7980 - val_loss: 0.4422 - val_accuracy: 0.7821\n",
      "Epoch 571/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4229 - accuracy: 0.8003 - val_loss: 0.4556 - val_accuracy: 0.7729\n",
      "Epoch 572/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4243 - accuracy: 0.8018 - val_loss: 0.4461 - val_accuracy: 0.7809\n",
      "Epoch 573/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4264 - accuracy: 0.7971 - val_loss: 0.4640 - val_accuracy: 0.7729\n",
      "Epoch 574/1500\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.4268 - accuracy: 0.7955 - val_loss: 0.4399 - val_accuracy: 0.7809\n",
      "Epoch 575/1500\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.4255 - accuracy: 0.8001 - val_loss: 0.4393 - val_accuracy: 0.7832\n",
      "Epoch 576/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4227 - accuracy: 0.8011 - val_loss: 0.4440 - val_accuracy: 0.7821\n",
      "Epoch 577/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4244 - accuracy: 0.7995 - val_loss: 0.4504 - val_accuracy: 0.7815\n",
      "Epoch 578/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4283 - accuracy: 0.8027 - val_loss: 0.4522 - val_accuracy: 0.7803\n",
      "Epoch 579/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4227 - accuracy: 0.8007 - val_loss: 0.4515 - val_accuracy: 0.7752\n",
      "Epoch 580/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4234 - accuracy: 0.8030 - val_loss: 0.4463 - val_accuracy: 0.7809\n",
      "Epoch 581/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4343 - accuracy: 0.7952 - val_loss: 0.4733 - val_accuracy: 0.7734\n",
      "Epoch 582/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4182 - accuracy: 0.8011 - val_loss: 0.4396 - val_accuracy: 0.7861\n",
      "Epoch 583/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4235 - accuracy: 0.8003 - val_loss: 0.4373 - val_accuracy: 0.7775\n",
      "Epoch 584/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4247 - accuracy: 0.8030 - val_loss: 0.4740 - val_accuracy: 0.7447\n",
      "Epoch 585/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4229 - accuracy: 0.8007 - val_loss: 0.4487 - val_accuracy: 0.7780\n",
      "Epoch 586/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4228 - accuracy: 0.7981 - val_loss: 0.4497 - val_accuracy: 0.7775\n",
      "Epoch 587/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4229 - accuracy: 0.8051 - val_loss: 0.4522 - val_accuracy: 0.7752\n",
      "Epoch 588/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4229 - accuracy: 0.8040 - val_loss: 0.4432 - val_accuracy: 0.7792\n",
      "Epoch 589/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4239 - accuracy: 0.8000 - val_loss: 0.4499 - val_accuracy: 0.7757\n",
      "Epoch 590/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4285 - accuracy: 0.7988 - val_loss: 0.4453 - val_accuracy: 0.7798\n",
      "Epoch 591/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4250 - accuracy: 0.8007 - val_loss: 0.4400 - val_accuracy: 0.7798\n",
      "Epoch 592/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4234 - accuracy: 0.8039 - val_loss: 0.4421 - val_accuracy: 0.7809\n",
      "Epoch 593/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4232 - accuracy: 0.8020 - val_loss: 0.4475 - val_accuracy: 0.7809\n",
      "Epoch 594/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4265 - accuracy: 0.8021 - val_loss: 0.4474 - val_accuracy: 0.7844\n",
      "Epoch 595/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4249 - accuracy: 0.8004 - val_loss: 0.4572 - val_accuracy: 0.7734\n",
      "Epoch 596/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4279 - accuracy: 0.8016 - val_loss: 0.4427 - val_accuracy: 0.7798\n",
      "Epoch 597/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4194 - accuracy: 0.8024 - val_loss: 0.4566 - val_accuracy: 0.7637\n",
      "Epoch 598/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4281 - accuracy: 0.8011 - val_loss: 0.4443 - val_accuracy: 0.7844\n",
      "Epoch 599/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4223 - accuracy: 0.8040 - val_loss: 0.4453 - val_accuracy: 0.7815\n",
      "Epoch 600/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4186 - accuracy: 0.7998 - val_loss: 0.4480 - val_accuracy: 0.7734\n",
      "Epoch 601/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4216 - accuracy: 0.8020 - val_loss: 0.4496 - val_accuracy: 0.7792\n",
      "Epoch 602/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4219 - accuracy: 0.8026 - val_loss: 0.4475 - val_accuracy: 0.7838\n",
      "Epoch 603/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4199 - accuracy: 0.8020 - val_loss: 0.4439 - val_accuracy: 0.7746\n",
      "Epoch 604/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4203 - accuracy: 0.8031 - val_loss: 0.4529 - val_accuracy: 0.7763\n",
      "Epoch 605/1500\n",
      "28/28 [==============================] - 2s 63ms/step - loss: 0.4238 - accuracy: 0.8031 - val_loss: 0.4418 - val_accuracy: 0.7763\n",
      "Epoch 606/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4223 - accuracy: 0.8013 - val_loss: 0.4461 - val_accuracy: 0.7780\n",
      "Epoch 607/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4223 - accuracy: 0.8053 - val_loss: 0.4508 - val_accuracy: 0.7780\n",
      "Epoch 608/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4186 - accuracy: 0.8033 - val_loss: 0.4378 - val_accuracy: 0.7792\n",
      "Epoch 609/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4231 - accuracy: 0.8020 - val_loss: 0.4433 - val_accuracy: 0.7838\n",
      "Epoch 610/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4213 - accuracy: 0.7991 - val_loss: 0.4438 - val_accuracy: 0.7780\n",
      "Epoch 611/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4234 - accuracy: 0.8007 - val_loss: 0.4609 - val_accuracy: 0.7844\n",
      "Epoch 612/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4216 - accuracy: 0.8060 - val_loss: 0.4592 - val_accuracy: 0.7660\n",
      "Epoch 613/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4216 - accuracy: 0.8034 - val_loss: 0.4459 - val_accuracy: 0.7821\n",
      "Epoch 614/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4246 - accuracy: 0.8046 - val_loss: 0.4591 - val_accuracy: 0.7683\n",
      "Epoch 615/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4198 - accuracy: 0.8050 - val_loss: 0.4552 - val_accuracy: 0.7786\n",
      "Epoch 616/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4219 - accuracy: 0.8024 - val_loss: 0.4515 - val_accuracy: 0.7803\n",
      "Epoch 617/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4246 - accuracy: 0.7995 - val_loss: 0.4518 - val_accuracy: 0.7706\n",
      "Epoch 618/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4217 - accuracy: 0.8003 - val_loss: 0.4446 - val_accuracy: 0.7798\n",
      "Epoch 619/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4208 - accuracy: 0.8026 - val_loss: 0.4491 - val_accuracy: 0.7798\n",
      "Epoch 620/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4227 - accuracy: 0.8040 - val_loss: 0.4518 - val_accuracy: 0.7706\n",
      "Epoch 621/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4196 - accuracy: 0.8000 - val_loss: 0.4411 - val_accuracy: 0.7769\n",
      "Epoch 622/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4214 - accuracy: 0.8051 - val_loss: 0.4419 - val_accuracy: 0.7798\n",
      "Epoch 623/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4158 - accuracy: 0.8020 - val_loss: 0.4519 - val_accuracy: 0.7723\n",
      "Epoch 624/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4165 - accuracy: 0.8041 - val_loss: 0.4452 - val_accuracy: 0.7798\n",
      "Epoch 625/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4205 - accuracy: 0.8026 - val_loss: 0.4558 - val_accuracy: 0.7775\n",
      "Epoch 626/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4265 - accuracy: 0.7978 - val_loss: 0.4408 - val_accuracy: 0.7798\n",
      "Epoch 627/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4227 - accuracy: 0.8020 - val_loss: 0.4411 - val_accuracy: 0.7780\n",
      "Epoch 628/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4143 - accuracy: 0.8050 - val_loss: 0.4450 - val_accuracy: 0.7757\n",
      "Epoch 629/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4257 - accuracy: 0.8053 - val_loss: 0.4416 - val_accuracy: 0.7757\n",
      "Epoch 630/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4192 - accuracy: 0.8030 - val_loss: 0.4414 - val_accuracy: 0.7786\n",
      "Epoch 631/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4203 - accuracy: 0.8047 - val_loss: 0.4555 - val_accuracy: 0.7757\n",
      "Epoch 632/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4231 - accuracy: 0.8020 - val_loss: 0.4532 - val_accuracy: 0.7729\n",
      "Epoch 633/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4212 - accuracy: 0.7993 - val_loss: 0.4422 - val_accuracy: 0.7792\n",
      "Epoch 634/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4201 - accuracy: 0.8026 - val_loss: 0.4459 - val_accuracy: 0.7763\n",
      "Epoch 635/1500\n",
      "28/28 [==============================] - 2s 64ms/step - loss: 0.4245 - accuracy: 0.7991 - val_loss: 0.4539 - val_accuracy: 0.7752\n",
      "Epoch 636/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4223 - accuracy: 0.8026 - val_loss: 0.4511 - val_accuracy: 0.7734\n",
      "Epoch 637/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4175 - accuracy: 0.8063 - val_loss: 0.4419 - val_accuracy: 0.7780\n",
      "Epoch 638/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4183 - accuracy: 0.8053 - val_loss: 0.4519 - val_accuracy: 0.7763\n",
      "Epoch 639/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4228 - accuracy: 0.7990 - val_loss: 0.4544 - val_accuracy: 0.7815\n",
      "Epoch 640/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4249 - accuracy: 0.8036 - val_loss: 0.4465 - val_accuracy: 0.7780\n",
      "Epoch 641/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4226 - accuracy: 0.8000 - val_loss: 0.4570 - val_accuracy: 0.7809\n",
      "Epoch 642/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4171 - accuracy: 0.8037 - val_loss: 0.4597 - val_accuracy: 0.7694\n",
      "Epoch 643/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4233 - accuracy: 0.8024 - val_loss: 0.4413 - val_accuracy: 0.7821\n",
      "Epoch 644/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4242 - accuracy: 0.7998 - val_loss: 0.4403 - val_accuracy: 0.7803\n",
      "Epoch 645/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4203 - accuracy: 0.8049 - val_loss: 0.4520 - val_accuracy: 0.7769\n",
      "Epoch 646/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4181 - accuracy: 0.8062 - val_loss: 0.4411 - val_accuracy: 0.7792\n",
      "Epoch 647/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4224 - accuracy: 0.8034 - val_loss: 0.4491 - val_accuracy: 0.7752\n",
      "Epoch 648/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4267 - accuracy: 0.8039 - val_loss: 0.4513 - val_accuracy: 0.7723\n",
      "Epoch 649/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4250 - accuracy: 0.8008 - val_loss: 0.4530 - val_accuracy: 0.7757\n",
      "Epoch 650/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4222 - accuracy: 0.8017 - val_loss: 0.4493 - val_accuracy: 0.7786\n",
      "Epoch 651/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4225 - accuracy: 0.8030 - val_loss: 0.4485 - val_accuracy: 0.7740\n",
      "Epoch 652/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.4533 - val_accuracy: 0.7683\n",
      "Epoch 653/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4217 - accuracy: 0.8011 - val_loss: 0.4390 - val_accuracy: 0.7803\n",
      "Epoch 654/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4174 - accuracy: 0.8059 - val_loss: 0.4517 - val_accuracy: 0.7775\n",
      "Epoch 655/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4249 - accuracy: 0.8053 - val_loss: 0.4513 - val_accuracy: 0.7752\n",
      "Epoch 656/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4196 - accuracy: 0.8023 - val_loss: 0.4412 - val_accuracy: 0.7803\n",
      "Epoch 657/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4180 - accuracy: 0.8047 - val_loss: 0.4512 - val_accuracy: 0.7711\n",
      "Epoch 658/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4233 - accuracy: 0.8001 - val_loss: 0.4533 - val_accuracy: 0.7711\n",
      "Epoch 659/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4200 - accuracy: 0.8039 - val_loss: 0.4483 - val_accuracy: 0.7780\n",
      "Epoch 660/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4207 - accuracy: 0.8044 - val_loss: 0.4531 - val_accuracy: 0.7717\n",
      "Epoch 661/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4218 - accuracy: 0.8062 - val_loss: 0.4505 - val_accuracy: 0.7734\n",
      "Epoch 662/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4237 - accuracy: 0.8023 - val_loss: 0.4533 - val_accuracy: 0.7769\n",
      "Epoch 663/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4186 - accuracy: 0.8021 - val_loss: 0.4477 - val_accuracy: 0.7763\n",
      "Epoch 664/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4190 - accuracy: 0.8024 - val_loss: 0.4495 - val_accuracy: 0.7821\n",
      "Epoch 665/1500\n",
      "28/28 [==============================] - 2s 63ms/step - loss: 0.4263 - accuracy: 0.8010 - val_loss: 0.4451 - val_accuracy: 0.7792\n",
      "Epoch 666/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4247 - accuracy: 0.8011 - val_loss: 0.4399 - val_accuracy: 0.7752\n",
      "Epoch 667/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4236 - accuracy: 0.8023 - val_loss: 0.4454 - val_accuracy: 0.7746\n",
      "Epoch 668/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4254 - accuracy: 0.8043 - val_loss: 0.4477 - val_accuracy: 0.7838\n",
      "Epoch 669/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4214 - accuracy: 0.8047 - val_loss: 0.4474 - val_accuracy: 0.7769\n",
      "Epoch 670/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4205 - accuracy: 0.8039 - val_loss: 0.4669 - val_accuracy: 0.7556\n",
      "Epoch 671/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4224 - accuracy: 0.7997 - val_loss: 0.4393 - val_accuracy: 0.7809\n",
      "Epoch 672/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4164 - accuracy: 0.8023 - val_loss: 0.4519 - val_accuracy: 0.7803\n",
      "Epoch 673/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4272 - accuracy: 0.8011 - val_loss: 0.4409 - val_accuracy: 0.7786\n",
      "Epoch 674/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4194 - accuracy: 0.8013 - val_loss: 0.4453 - val_accuracy: 0.7775\n",
      "Epoch 675/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4231 - accuracy: 0.8030 - val_loss: 0.4563 - val_accuracy: 0.7706\n",
      "Epoch 676/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4151 - accuracy: 0.8040 - val_loss: 0.4487 - val_accuracy: 0.7780\n",
      "Epoch 677/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4227 - accuracy: 0.8040 - val_loss: 0.4503 - val_accuracy: 0.7769\n",
      "Epoch 678/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4204 - accuracy: 0.8040 - val_loss: 0.4560 - val_accuracy: 0.7688\n",
      "Epoch 679/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4194 - accuracy: 0.8039 - val_loss: 0.4520 - val_accuracy: 0.7706\n",
      "Epoch 680/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4213 - accuracy: 0.8010 - val_loss: 0.4483 - val_accuracy: 0.7809\n",
      "Epoch 681/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4170 - accuracy: 0.8051 - val_loss: 0.4559 - val_accuracy: 0.7798\n",
      "Epoch 682/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4242 - accuracy: 0.8026 - val_loss: 0.4544 - val_accuracy: 0.7711\n",
      "Epoch 683/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4149 - accuracy: 0.8039 - val_loss: 0.4460 - val_accuracy: 0.7775\n",
      "Epoch 684/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4249 - accuracy: 0.8023 - val_loss: 0.4412 - val_accuracy: 0.7752\n",
      "Epoch 685/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4180 - accuracy: 0.8043 - val_loss: 0.4610 - val_accuracy: 0.7763\n",
      "Epoch 686/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4200 - accuracy: 0.8064 - val_loss: 0.4682 - val_accuracy: 0.7694\n",
      "Epoch 687/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4200 - accuracy: 0.8021 - val_loss: 0.4468 - val_accuracy: 0.7763\n",
      "Epoch 688/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4222 - accuracy: 0.8033 - val_loss: 0.4533 - val_accuracy: 0.7717\n",
      "Epoch 689/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4230 - accuracy: 0.8041 - val_loss: 0.4472 - val_accuracy: 0.7803\n",
      "Epoch 690/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4223 - accuracy: 0.8018 - val_loss: 0.4409 - val_accuracy: 0.7792\n",
      "Epoch 691/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4163 - accuracy: 0.8072 - val_loss: 0.4468 - val_accuracy: 0.7729\n",
      "Epoch 692/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4236 - accuracy: 0.8037 - val_loss: 0.4471 - val_accuracy: 0.7786\n",
      "Epoch 693/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4190 - accuracy: 0.8067 - val_loss: 0.4431 - val_accuracy: 0.7821\n",
      "Epoch 694/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4283 - accuracy: 0.8036 - val_loss: 0.4473 - val_accuracy: 0.7752\n",
      "Epoch 695/1500\n",
      "28/28 [==============================] - 2s 57ms/step - loss: 0.4155 - accuracy: 0.8039 - val_loss: 0.4412 - val_accuracy: 0.7786\n",
      "Epoch 696/1500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4205 - accuracy: 0.8066 - val_loss: 0.4561 - val_accuracy: 0.7683\n",
      "Epoch 697/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4177 - accuracy: 0.8041 - val_loss: 0.4469 - val_accuracy: 0.7769\n",
      "Epoch 698/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4231 - accuracy: 0.8018 - val_loss: 0.4457 - val_accuracy: 0.7769\n",
      "Epoch 699/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4176 - accuracy: 0.8041 - val_loss: 0.4435 - val_accuracy: 0.7786\n",
      "Epoch 700/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4180 - accuracy: 0.8054 - val_loss: 0.4416 - val_accuracy: 0.7821\n",
      "Epoch 701/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4184 - accuracy: 0.8031 - val_loss: 0.4436 - val_accuracy: 0.7844\n",
      "Epoch 702/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4224 - accuracy: 0.8053 - val_loss: 0.4534 - val_accuracy: 0.7723\n",
      "Epoch 703/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4157 - accuracy: 0.8085 - val_loss: 0.4443 - val_accuracy: 0.7821\n",
      "Epoch 704/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4213 - accuracy: 0.8051 - val_loss: 0.4466 - val_accuracy: 0.7763\n",
      "Epoch 705/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4186 - accuracy: 0.8057 - val_loss: 0.4457 - val_accuracy: 0.7826\n",
      "Epoch 706/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4167 - accuracy: 0.8059 - val_loss: 0.4541 - val_accuracy: 0.7694\n",
      "Epoch 707/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4215 - accuracy: 0.8041 - val_loss: 0.4506 - val_accuracy: 0.7786\n",
      "Epoch 708/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4140 - accuracy: 0.8028 - val_loss: 0.4556 - val_accuracy: 0.7711\n",
      "Epoch 709/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4147 - accuracy: 0.8039 - val_loss: 0.4455 - val_accuracy: 0.7809\n",
      "Epoch 710/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4181 - accuracy: 0.8049 - val_loss: 0.4476 - val_accuracy: 0.7775\n",
      "Epoch 711/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4247 - accuracy: 0.8016 - val_loss: 0.4451 - val_accuracy: 0.7775\n",
      "Epoch 712/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4156 - accuracy: 0.8037 - val_loss: 0.4607 - val_accuracy: 0.7752\n",
      "Epoch 713/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4198 - accuracy: 0.8013 - val_loss: 0.4554 - val_accuracy: 0.7660\n",
      "Epoch 714/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4143 - accuracy: 0.8051 - val_loss: 0.4595 - val_accuracy: 0.7602\n",
      "Epoch 715/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4175 - accuracy: 0.8072 - val_loss: 0.4436 - val_accuracy: 0.7734\n",
      "Epoch 716/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4200 - accuracy: 0.8037 - val_loss: 0.4441 - val_accuracy: 0.7746\n",
      "Epoch 717/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4218 - accuracy: 0.8005 - val_loss: 0.4420 - val_accuracy: 0.7780\n",
      "Epoch 718/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4167 - accuracy: 0.8060 - val_loss: 0.4486 - val_accuracy: 0.7826\n",
      "Epoch 719/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4121 - accuracy: 0.8024 - val_loss: 0.4404 - val_accuracy: 0.7826\n",
      "Epoch 720/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4173 - accuracy: 0.8046 - val_loss: 0.4639 - val_accuracy: 0.7792\n",
      "Epoch 721/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4155 - accuracy: 0.8063 - val_loss: 0.4476 - val_accuracy: 0.7780\n",
      "Epoch 722/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4214 - accuracy: 0.8016 - val_loss: 0.4524 - val_accuracy: 0.7711\n",
      "Epoch 723/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4144 - accuracy: 0.8054 - val_loss: 0.4490 - val_accuracy: 0.7763\n",
      "Epoch 724/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4124 - accuracy: 0.8053 - val_loss: 0.4487 - val_accuracy: 0.7815\n",
      "Epoch 725/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4158 - accuracy: 0.8023 - val_loss: 0.4645 - val_accuracy: 0.7602\n",
      "Epoch 726/1500\n",
      "28/28 [==============================] - 2s 62ms/step - loss: 0.4230 - accuracy: 0.7990 - val_loss: 0.4628 - val_accuracy: 0.7792\n",
      "Epoch 727/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4202 - accuracy: 0.8028 - val_loss: 0.4677 - val_accuracy: 0.7625\n",
      "Epoch 728/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4204 - accuracy: 0.8057 - val_loss: 0.4459 - val_accuracy: 0.7798\n",
      "Epoch 729/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4221 - accuracy: 0.8000 - val_loss: 0.4460 - val_accuracy: 0.7775\n",
      "Epoch 730/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4209 - accuracy: 0.8036 - val_loss: 0.4758 - val_accuracy: 0.7556\n",
      "Epoch 731/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4182 - accuracy: 0.8028 - val_loss: 0.4507 - val_accuracy: 0.7769\n",
      "Epoch 732/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4224 - accuracy: 0.8049 - val_loss: 0.4521 - val_accuracy: 0.7660\n",
      "Epoch 733/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4202 - accuracy: 0.8033 - val_loss: 0.4400 - val_accuracy: 0.7803\n",
      "Epoch 734/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4165 - accuracy: 0.8026 - val_loss: 0.4627 - val_accuracy: 0.7648\n",
      "Epoch 735/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4216 - accuracy: 0.8043 - val_loss: 0.4418 - val_accuracy: 0.7757\n",
      "Epoch 736/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4168 - accuracy: 0.8069 - val_loss: 0.4489 - val_accuracy: 0.7752\n",
      "Epoch 737/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4193 - accuracy: 0.8036 - val_loss: 0.4457 - val_accuracy: 0.7821\n",
      "Epoch 738/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4199 - accuracy: 0.8041 - val_loss: 0.4458 - val_accuracy: 0.7775\n",
      "Epoch 739/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4161 - accuracy: 0.8076 - val_loss: 0.4516 - val_accuracy: 0.7723\n",
      "Epoch 740/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4187 - accuracy: 0.8053 - val_loss: 0.4433 - val_accuracy: 0.7775\n",
      "Epoch 741/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4154 - accuracy: 0.8070 - val_loss: 0.4433 - val_accuracy: 0.7826\n",
      "Epoch 742/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4119 - accuracy: 0.8085 - val_loss: 0.4480 - val_accuracy: 0.7786\n",
      "Epoch 743/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4165 - accuracy: 0.8031 - val_loss: 0.4409 - val_accuracy: 0.7763\n",
      "Epoch 744/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4146 - accuracy: 0.8067 - val_loss: 0.4533 - val_accuracy: 0.7786\n",
      "Epoch 745/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4151 - accuracy: 0.8064 - val_loss: 0.4526 - val_accuracy: 0.7803\n",
      "Epoch 746/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4169 - accuracy: 0.8054 - val_loss: 0.4510 - val_accuracy: 0.7740\n",
      "Epoch 747/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4148 - accuracy: 0.8049 - val_loss: 0.4668 - val_accuracy: 0.7562\n",
      "Epoch 748/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4186 - accuracy: 0.8021 - val_loss: 0.4443 - val_accuracy: 0.7798\n",
      "Epoch 749/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4159 - accuracy: 0.8057 - val_loss: 0.4657 - val_accuracy: 0.7579\n",
      "Epoch 750/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4181 - accuracy: 0.8047 - val_loss: 0.4468 - val_accuracy: 0.7706\n",
      "Epoch 751/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4167 - accuracy: 0.8041 - val_loss: 0.4436 - val_accuracy: 0.7763\n",
      "Epoch 752/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4202 - accuracy: 0.8037 - val_loss: 0.4409 - val_accuracy: 0.7792\n",
      "Epoch 753/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4176 - accuracy: 0.8036 - val_loss: 0.4434 - val_accuracy: 0.7809\n",
      "Epoch 754/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4141 - accuracy: 0.8018 - val_loss: 0.4422 - val_accuracy: 0.7821\n",
      "Epoch 755/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4222 - accuracy: 0.8021 - val_loss: 0.4536 - val_accuracy: 0.7798\n",
      "Epoch 756/1500\n",
      "28/28 [==============================] - 2s 63ms/step - loss: 0.4219 - accuracy: 0.8014 - val_loss: 0.4434 - val_accuracy: 0.7786\n",
      "Epoch 757/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4157 - accuracy: 0.8043 - val_loss: 0.4444 - val_accuracy: 0.7821\n",
      "Epoch 758/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4167 - accuracy: 0.8086 - val_loss: 0.4460 - val_accuracy: 0.7809\n",
      "Epoch 759/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4201 - accuracy: 0.8003 - val_loss: 0.4783 - val_accuracy: 0.7591\n",
      "Epoch 760/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4153 - accuracy: 0.8062 - val_loss: 0.4568 - val_accuracy: 0.7723\n",
      "Epoch 761/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4202 - accuracy: 0.8036 - val_loss: 0.4498 - val_accuracy: 0.7752\n",
      "Epoch 762/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4176 - accuracy: 0.8064 - val_loss: 0.4438 - val_accuracy: 0.7798\n",
      "Epoch 763/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4166 - accuracy: 0.8040 - val_loss: 0.4413 - val_accuracy: 0.7821\n",
      "Epoch 764/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4119 - accuracy: 0.8059 - val_loss: 0.4453 - val_accuracy: 0.7832\n",
      "Epoch 765/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4168 - accuracy: 0.8057 - val_loss: 0.4465 - val_accuracy: 0.7763\n",
      "Epoch 766/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4147 - accuracy: 0.8041 - val_loss: 0.4428 - val_accuracy: 0.7849\n",
      "Epoch 767/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4147 - accuracy: 0.8070 - val_loss: 0.4455 - val_accuracy: 0.7821\n",
      "Epoch 768/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4181 - accuracy: 0.8051 - val_loss: 0.4544 - val_accuracy: 0.7740\n",
      "Epoch 769/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4157 - accuracy: 0.8039 - val_loss: 0.4407 - val_accuracy: 0.7763\n",
      "Epoch 770/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4214 - accuracy: 0.8044 - val_loss: 0.4449 - val_accuracy: 0.7757\n",
      "Epoch 771/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4141 - accuracy: 0.8069 - val_loss: 0.4412 - val_accuracy: 0.7786\n",
      "Epoch 772/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4127 - accuracy: 0.8060 - val_loss: 0.4396 - val_accuracy: 0.7775\n",
      "Epoch 773/1500\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.4123 - accuracy: 0.8064 - val_loss: 0.4418 - val_accuracy: 0.7769\n",
      "Epoch 774/1500\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.4175 - accuracy: 0.8046 - val_loss: 0.4618 - val_accuracy: 0.7625\n",
      "Epoch 775/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4191 - accuracy: 0.8018 - val_loss: 0.4472 - val_accuracy: 0.7740\n",
      "Epoch 776/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4169 - accuracy: 0.8082 - val_loss: 0.4424 - val_accuracy: 0.7769\n",
      "Epoch 777/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4175 - accuracy: 0.8016 - val_loss: 0.4449 - val_accuracy: 0.7757\n",
      "Epoch 778/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4177 - accuracy: 0.8062 - val_loss: 0.4479 - val_accuracy: 0.7729\n",
      "Epoch 779/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4179 - accuracy: 0.8053 - val_loss: 0.4513 - val_accuracy: 0.7740\n",
      "Epoch 780/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4165 - accuracy: 0.8082 - val_loss: 0.4462 - val_accuracy: 0.7838\n",
      "Epoch 781/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4139 - accuracy: 0.8102 - val_loss: 0.4457 - val_accuracy: 0.7815\n",
      "Epoch 782/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4246 - accuracy: 0.8016 - val_loss: 0.4518 - val_accuracy: 0.7786\n",
      "Epoch 783/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4246 - accuracy: 0.8024 - val_loss: 0.4645 - val_accuracy: 0.7734\n",
      "Epoch 784/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4181 - accuracy: 0.8053 - val_loss: 0.4530 - val_accuracy: 0.7757\n",
      "Epoch 785/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4157 - accuracy: 0.8060 - val_loss: 0.4399 - val_accuracy: 0.7821\n",
      "Epoch 786/1500\n",
      "28/28 [==============================] - 2s 63ms/step - loss: 0.4102 - accuracy: 0.8066 - val_loss: 0.4416 - val_accuracy: 0.7826\n",
      "Epoch 787/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4108 - accuracy: 0.8067 - val_loss: 0.4482 - val_accuracy: 0.7803\n",
      "Epoch 788/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4170 - accuracy: 0.8059 - val_loss: 0.4482 - val_accuracy: 0.7752\n",
      "Epoch 789/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4183 - accuracy: 0.8039 - val_loss: 0.4437 - val_accuracy: 0.7821\n",
      "Epoch 790/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4142 - accuracy: 0.8092 - val_loss: 0.4415 - val_accuracy: 0.7821\n",
      "Epoch 791/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4148 - accuracy: 0.8056 - val_loss: 0.4428 - val_accuracy: 0.7809\n",
      "Epoch 792/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4171 - accuracy: 0.8049 - val_loss: 0.4595 - val_accuracy: 0.7625\n",
      "Epoch 793/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4160 - accuracy: 0.8077 - val_loss: 0.4491 - val_accuracy: 0.7723\n",
      "Epoch 794/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4170 - accuracy: 0.8051 - val_loss: 0.4426 - val_accuracy: 0.7752\n",
      "Epoch 795/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4163 - accuracy: 0.8044 - val_loss: 0.4446 - val_accuracy: 0.7780\n",
      "Epoch 796/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4255 - accuracy: 0.8011 - val_loss: 0.4659 - val_accuracy: 0.7798\n",
      "Epoch 797/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4189 - accuracy: 0.7998 - val_loss: 0.4429 - val_accuracy: 0.7792\n",
      "Epoch 798/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4198 - accuracy: 0.8064 - val_loss: 0.4440 - val_accuracy: 0.7792\n",
      "Epoch 799/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4179 - accuracy: 0.8027 - val_loss: 0.4399 - val_accuracy: 0.7826\n",
      "Epoch 800/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4167 - accuracy: 0.8056 - val_loss: 0.4431 - val_accuracy: 0.7746\n",
      "Epoch 801/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4127 - accuracy: 0.8013 - val_loss: 0.4418 - val_accuracy: 0.7786\n",
      "Epoch 802/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4158 - accuracy: 0.8063 - val_loss: 0.4539 - val_accuracy: 0.7757\n",
      "Epoch 803/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4185 - accuracy: 0.8028 - val_loss: 0.4403 - val_accuracy: 0.7809\n",
      "Epoch 804/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4142 - accuracy: 0.8000 - val_loss: 0.4442 - val_accuracy: 0.7757\n",
      "Epoch 805/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4176 - accuracy: 0.8049 - val_loss: 0.4510 - val_accuracy: 0.7792\n",
      "Epoch 806/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4111 - accuracy: 0.8125 - val_loss: 0.4407 - val_accuracy: 0.7798\n",
      "Epoch 807/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4112 - accuracy: 0.8060 - val_loss: 0.4508 - val_accuracy: 0.7780\n",
      "Epoch 808/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4161 - accuracy: 0.8070 - val_loss: 0.4470 - val_accuracy: 0.7740\n",
      "Epoch 809/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4148 - accuracy: 0.8073 - val_loss: 0.4435 - val_accuracy: 0.7815\n",
      "Epoch 810/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4154 - accuracy: 0.8053 - val_loss: 0.4427 - val_accuracy: 0.7786\n",
      "Epoch 811/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4163 - accuracy: 0.8034 - val_loss: 0.4542 - val_accuracy: 0.7763\n",
      "Epoch 812/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4139 - accuracy: 0.8073 - val_loss: 0.4510 - val_accuracy: 0.7792\n",
      "Epoch 813/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4111 - accuracy: 0.8047 - val_loss: 0.4468 - val_accuracy: 0.7798\n",
      "Epoch 814/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4089 - accuracy: 0.8064 - val_loss: 0.4503 - val_accuracy: 0.7694\n",
      "Epoch 815/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4125 - accuracy: 0.8024 - val_loss: 0.4422 - val_accuracy: 0.7780\n",
      "Epoch 816/1500\n",
      "28/28 [==============================] - 2s 64ms/step - loss: 0.4125 - accuracy: 0.8036 - val_loss: 0.4460 - val_accuracy: 0.7757\n",
      "Epoch 817/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4209 - accuracy: 0.8089 - val_loss: 0.4457 - val_accuracy: 0.7769\n",
      "Epoch 818/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4178 - accuracy: 0.8020 - val_loss: 0.4492 - val_accuracy: 0.7729\n",
      "Epoch 819/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4146 - accuracy: 0.8059 - val_loss: 0.4431 - val_accuracy: 0.7832\n",
      "Epoch 820/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4113 - accuracy: 0.8064 - val_loss: 0.4440 - val_accuracy: 0.7780\n",
      "Epoch 821/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4149 - accuracy: 0.8072 - val_loss: 0.4500 - val_accuracy: 0.7752\n",
      "Epoch 822/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4164 - accuracy: 0.8073 - val_loss: 0.4465 - val_accuracy: 0.7826\n",
      "Epoch 823/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4168 - accuracy: 0.8036 - val_loss: 0.4440 - val_accuracy: 0.7769\n",
      "Epoch 824/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4128 - accuracy: 0.8079 - val_loss: 0.4465 - val_accuracy: 0.7734\n",
      "Epoch 825/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4104 - accuracy: 0.8089 - val_loss: 0.4424 - val_accuracy: 0.7821\n",
      "Epoch 826/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4122 - accuracy: 0.8077 - val_loss: 0.4538 - val_accuracy: 0.7838\n",
      "Epoch 827/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4144 - accuracy: 0.8050 - val_loss: 0.4468 - val_accuracy: 0.7803\n",
      "Epoch 828/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4206 - accuracy: 0.8051 - val_loss: 0.4681 - val_accuracy: 0.7665\n",
      "Epoch 829/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4137 - accuracy: 0.8066 - val_loss: 0.4439 - val_accuracy: 0.7821\n",
      "Epoch 830/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4172 - accuracy: 0.8037 - val_loss: 0.4498 - val_accuracy: 0.7867\n",
      "Epoch 831/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4124 - accuracy: 0.8092 - val_loss: 0.4468 - val_accuracy: 0.7792\n",
      "Epoch 832/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4212 - accuracy: 0.8056 - val_loss: 0.4550 - val_accuracy: 0.7832\n",
      "Epoch 833/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4187 - accuracy: 0.8072 - val_loss: 0.4648 - val_accuracy: 0.7734\n",
      "Epoch 834/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4173 - accuracy: 0.8054 - val_loss: 0.4543 - val_accuracy: 0.7832\n",
      "Epoch 835/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4134 - accuracy: 0.8037 - val_loss: 0.4489 - val_accuracy: 0.7832\n",
      "Epoch 836/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4104 - accuracy: 0.8064 - val_loss: 0.4533 - val_accuracy: 0.7855\n",
      "Epoch 837/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4125 - accuracy: 0.8080 - val_loss: 0.4497 - val_accuracy: 0.7821\n",
      "Epoch 838/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4154 - accuracy: 0.8013 - val_loss: 0.4597 - val_accuracy: 0.7752\n",
      "Epoch 839/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4351 - accuracy: 0.7954 - val_loss: 0.4656 - val_accuracy: 0.7671\n",
      "Epoch 840/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4241 - accuracy: 0.8024 - val_loss: 0.4439 - val_accuracy: 0.7780\n",
      "Epoch 841/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4135 - accuracy: 0.8034 - val_loss: 0.4454 - val_accuracy: 0.7786\n",
      "Epoch 842/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4191 - accuracy: 0.8044 - val_loss: 0.4493 - val_accuracy: 0.7723\n",
      "Epoch 843/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4143 - accuracy: 0.8089 - val_loss: 0.4554 - val_accuracy: 0.7775\n",
      "Epoch 844/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4158 - accuracy: 0.8033 - val_loss: 0.4488 - val_accuracy: 0.7775\n",
      "Epoch 845/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4134 - accuracy: 0.8047 - val_loss: 0.4502 - val_accuracy: 0.7734\n",
      "Epoch 846/1500\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.4139 - accuracy: 0.8064 - val_loss: 0.4485 - val_accuracy: 0.7826\n",
      "Epoch 847/1500\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.4155 - accuracy: 0.8036 - val_loss: 0.4563 - val_accuracy: 0.7757\n",
      "Epoch 848/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4135 - accuracy: 0.8070 - val_loss: 0.4506 - val_accuracy: 0.7746\n",
      "Epoch 849/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4163 - accuracy: 0.8028 - val_loss: 0.4576 - val_accuracy: 0.7757\n",
      "Epoch 850/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4090 - accuracy: 0.8079 - val_loss: 0.4599 - val_accuracy: 0.7757\n",
      "Epoch 851/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4181 - accuracy: 0.8070 - val_loss: 0.4470 - val_accuracy: 0.7775\n",
      "Epoch 852/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4220 - accuracy: 0.8008 - val_loss: 0.4519 - val_accuracy: 0.7660\n",
      "Epoch 853/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4147 - accuracy: 0.8087 - val_loss: 0.4462 - val_accuracy: 0.7826\n",
      "Epoch 854/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4156 - accuracy: 0.8056 - val_loss: 0.4453 - val_accuracy: 0.7821\n",
      "Epoch 855/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4130 - accuracy: 0.8089 - val_loss: 0.4460 - val_accuracy: 0.7798\n",
      "Epoch 856/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4167 - accuracy: 0.8053 - val_loss: 0.4567 - val_accuracy: 0.7734\n",
      "Epoch 857/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4118 - accuracy: 0.8036 - val_loss: 0.4482 - val_accuracy: 0.7734\n",
      "Epoch 858/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4133 - accuracy: 0.8041 - val_loss: 0.4506 - val_accuracy: 0.7752\n",
      "Epoch 859/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4119 - accuracy: 0.8073 - val_loss: 0.4527 - val_accuracy: 0.7803\n",
      "Epoch 860/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4137 - accuracy: 0.8054 - val_loss: 0.4467 - val_accuracy: 0.7786\n",
      "Epoch 861/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4151 - accuracy: 0.8056 - val_loss: 0.4453 - val_accuracy: 0.7809\n",
      "Epoch 862/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4146 - accuracy: 0.8073 - val_loss: 0.4479 - val_accuracy: 0.7844\n",
      "Epoch 863/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4139 - accuracy: 0.8056 - val_loss: 0.4459 - val_accuracy: 0.7849\n",
      "Epoch 864/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4141 - accuracy: 0.8118 - val_loss: 0.4436 - val_accuracy: 0.7821\n",
      "Epoch 865/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4106 - accuracy: 0.8086 - val_loss: 0.4422 - val_accuracy: 0.7826\n",
      "Epoch 866/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4107 - accuracy: 0.8077 - val_loss: 0.4472 - val_accuracy: 0.7855\n",
      "Epoch 867/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4092 - accuracy: 0.8056 - val_loss: 0.4454 - val_accuracy: 0.7809\n",
      "Epoch 868/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4154 - accuracy: 0.8073 - val_loss: 0.4470 - val_accuracy: 0.7826\n",
      "Epoch 869/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4102 - accuracy: 0.8080 - val_loss: 0.4480 - val_accuracy: 0.7717\n",
      "Epoch 870/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4128 - accuracy: 0.8086 - val_loss: 0.4487 - val_accuracy: 0.7729\n",
      "Epoch 871/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4122 - accuracy: 0.8064 - val_loss: 0.4466 - val_accuracy: 0.7803\n",
      "Epoch 872/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4135 - accuracy: 0.8037 - val_loss: 0.4449 - val_accuracy: 0.7832\n",
      "Epoch 873/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4103 - accuracy: 0.8049 - val_loss: 0.4485 - val_accuracy: 0.7849\n",
      "Epoch 874/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4123 - accuracy: 0.8064 - val_loss: 0.4456 - val_accuracy: 0.7769\n",
      "Epoch 875/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4122 - accuracy: 0.8074 - val_loss: 0.4471 - val_accuracy: 0.7757\n",
      "Epoch 876/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4085 - accuracy: 0.8086 - val_loss: 0.4499 - val_accuracy: 0.7798\n",
      "Epoch 877/1500\n",
      "28/28 [==============================] - 2s 62ms/step - loss: 0.4092 - accuracy: 0.8067 - val_loss: 0.4511 - val_accuracy: 0.7729\n",
      "Epoch 878/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4164 - accuracy: 0.8092 - val_loss: 0.4422 - val_accuracy: 0.7798\n",
      "Epoch 879/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4124 - accuracy: 0.8074 - val_loss: 0.4533 - val_accuracy: 0.7786\n",
      "Epoch 880/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4096 - accuracy: 0.8077 - val_loss: 0.4651 - val_accuracy: 0.7683\n",
      "Epoch 881/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4197 - accuracy: 0.8043 - val_loss: 0.4585 - val_accuracy: 0.7734\n",
      "Epoch 882/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4121 - accuracy: 0.8092 - val_loss: 0.4496 - val_accuracy: 0.7769\n",
      "Epoch 883/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4138 - accuracy: 0.8072 - val_loss: 0.4482 - val_accuracy: 0.7878\n",
      "Epoch 884/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4173 - accuracy: 0.8047 - val_loss: 0.4469 - val_accuracy: 0.7792\n",
      "Epoch 885/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4095 - accuracy: 0.8073 - val_loss: 0.4442 - val_accuracy: 0.7775\n",
      "Epoch 886/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4127 - accuracy: 0.8067 - val_loss: 0.4536 - val_accuracy: 0.7746\n",
      "Epoch 887/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4142 - accuracy: 0.8085 - val_loss: 0.4408 - val_accuracy: 0.7815\n",
      "Epoch 888/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4111 - accuracy: 0.8077 - val_loss: 0.4517 - val_accuracy: 0.7729\n",
      "Epoch 889/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4095 - accuracy: 0.8074 - val_loss: 0.4387 - val_accuracy: 0.7809\n",
      "Epoch 890/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4147 - accuracy: 0.8066 - val_loss: 0.4458 - val_accuracy: 0.7729\n",
      "Epoch 891/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4184 - accuracy: 0.8057 - val_loss: 0.4461 - val_accuracy: 0.7809\n",
      "Epoch 892/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4133 - accuracy: 0.8054 - val_loss: 0.4462 - val_accuracy: 0.7803\n",
      "Epoch 893/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4106 - accuracy: 0.8049 - val_loss: 0.4453 - val_accuracy: 0.7792\n",
      "Epoch 894/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4171 - accuracy: 0.8086 - val_loss: 0.4484 - val_accuracy: 0.7815\n",
      "Epoch 895/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4146 - accuracy: 0.8039 - val_loss: 0.4440 - val_accuracy: 0.7815\n",
      "Epoch 896/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4136 - accuracy: 0.8039 - val_loss: 0.4411 - val_accuracy: 0.7815\n",
      "Epoch 897/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4122 - accuracy: 0.8069 - val_loss: 0.4368 - val_accuracy: 0.7838\n",
      "Epoch 898/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4141 - accuracy: 0.8060 - val_loss: 0.4489 - val_accuracy: 0.7803\n",
      "Epoch 899/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4123 - accuracy: 0.8093 - val_loss: 0.4540 - val_accuracy: 0.7780\n",
      "Epoch 900/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4064 - accuracy: 0.8106 - val_loss: 0.4622 - val_accuracy: 0.7729\n",
      "Epoch 901/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4185 - accuracy: 0.8047 - val_loss: 0.4639 - val_accuracy: 0.7677\n",
      "Epoch 902/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4125 - accuracy: 0.8057 - val_loss: 0.4480 - val_accuracy: 0.7832\n",
      "Epoch 903/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4155 - accuracy: 0.8064 - val_loss: 0.4701 - val_accuracy: 0.7769\n",
      "Epoch 904/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4122 - accuracy: 0.8041 - val_loss: 0.4468 - val_accuracy: 0.7780\n",
      "Epoch 905/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4119 - accuracy: 0.8034 - val_loss: 0.4461 - val_accuracy: 0.7792\n",
      "Epoch 906/1500\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 0.4102 - accuracy: 0.8050 - val_loss: 0.4514 - val_accuracy: 0.7809\n",
      "Epoch 907/1500\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.4046 - accuracy: 0.8085 - val_loss: 0.4521 - val_accuracy: 0.7706\n",
      "Epoch 908/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4164 - accuracy: 0.8093 - val_loss: 0.4870 - val_accuracy: 0.7556\n",
      "Epoch 909/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4153 - accuracy: 0.8023 - val_loss: 0.4444 - val_accuracy: 0.7786\n",
      "Epoch 910/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4173 - accuracy: 0.8043 - val_loss: 0.4466 - val_accuracy: 0.7717\n",
      "Epoch 911/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4075 - accuracy: 0.8067 - val_loss: 0.4521 - val_accuracy: 0.7752\n",
      "Epoch 912/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4131 - accuracy: 0.8060 - val_loss: 0.4547 - val_accuracy: 0.7798\n",
      "Epoch 913/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4104 - accuracy: 0.8090 - val_loss: 0.4478 - val_accuracy: 0.7798\n",
      "Epoch 914/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4091 - accuracy: 0.8076 - val_loss: 0.4527 - val_accuracy: 0.7844\n",
      "Epoch 915/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4420 - accuracy: 0.7888 - val_loss: 0.4796 - val_accuracy: 0.7677\n",
      "Epoch 916/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4212 - accuracy: 0.8043 - val_loss: 0.4436 - val_accuracy: 0.7803\n",
      "Epoch 917/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4131 - accuracy: 0.8037 - val_loss: 0.4528 - val_accuracy: 0.7631\n",
      "Epoch 918/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4176 - accuracy: 0.8044 - val_loss: 0.4501 - val_accuracy: 0.7660\n",
      "Epoch 919/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4097 - accuracy: 0.8099 - val_loss: 0.4433 - val_accuracy: 0.7809\n",
      "Epoch 920/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4068 - accuracy: 0.8072 - val_loss: 0.4434 - val_accuracy: 0.7798\n",
      "Epoch 921/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4115 - accuracy: 0.8072 - val_loss: 0.4538 - val_accuracy: 0.7706\n",
      "Epoch 922/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4083 - accuracy: 0.8105 - val_loss: 0.4441 - val_accuracy: 0.7786\n",
      "Epoch 923/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4097 - accuracy: 0.8056 - val_loss: 0.4483 - val_accuracy: 0.7798\n",
      "Epoch 924/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4075 - accuracy: 0.8056 - val_loss: 0.4629 - val_accuracy: 0.7642\n",
      "Epoch 925/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4107 - accuracy: 0.8113 - val_loss: 0.4402 - val_accuracy: 0.7803\n",
      "Epoch 926/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4091 - accuracy: 0.8043 - val_loss: 0.4526 - val_accuracy: 0.7740\n",
      "Epoch 927/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4109 - accuracy: 0.8060 - val_loss: 0.4522 - val_accuracy: 0.7792\n",
      "Epoch 928/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4138 - accuracy: 0.8063 - val_loss: 0.4533 - val_accuracy: 0.7734\n",
      "Epoch 929/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4089 - accuracy: 0.8056 - val_loss: 0.4506 - val_accuracy: 0.7734\n",
      "Epoch 930/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4121 - accuracy: 0.8067 - val_loss: 0.4534 - val_accuracy: 0.7895\n",
      "Epoch 931/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4104 - accuracy: 0.8072 - val_loss: 0.4472 - val_accuracy: 0.7763\n",
      "Epoch 932/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4103 - accuracy: 0.8064 - val_loss: 0.4453 - val_accuracy: 0.7780\n",
      "Epoch 933/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4112 - accuracy: 0.8097 - val_loss: 0.4513 - val_accuracy: 0.7780\n",
      "Epoch 934/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4175 - accuracy: 0.8050 - val_loss: 0.4535 - val_accuracy: 0.7838\n",
      "Epoch 935/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4135 - accuracy: 0.8056 - val_loss: 0.4425 - val_accuracy: 0.7803\n",
      "Epoch 936/1500\n",
      "28/28 [==============================] - 2s 64ms/step - loss: 0.4088 - accuracy: 0.8099 - val_loss: 0.4424 - val_accuracy: 0.7792\n",
      "Epoch 937/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4073 - accuracy: 0.8122 - val_loss: 0.4434 - val_accuracy: 0.7769\n",
      "Epoch 938/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4087 - accuracy: 0.8073 - val_loss: 0.4476 - val_accuracy: 0.7780\n",
      "Epoch 939/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4112 - accuracy: 0.8089 - val_loss: 0.4458 - val_accuracy: 0.7763\n",
      "Epoch 940/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4074 - accuracy: 0.8044 - val_loss: 0.4505 - val_accuracy: 0.7769\n",
      "Epoch 941/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4133 - accuracy: 0.8041 - val_loss: 0.4451 - val_accuracy: 0.7815\n",
      "Epoch 942/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4122 - accuracy: 0.8067 - val_loss: 0.4497 - val_accuracy: 0.7792\n",
      "Epoch 943/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4130 - accuracy: 0.8069 - val_loss: 0.4550 - val_accuracy: 0.7775\n",
      "Epoch 944/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4158 - accuracy: 0.8072 - val_loss: 0.4569 - val_accuracy: 0.7752\n",
      "Epoch 945/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4074 - accuracy: 0.8109 - val_loss: 0.4494 - val_accuracy: 0.7775\n",
      "Epoch 946/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4082 - accuracy: 0.8080 - val_loss: 0.4541 - val_accuracy: 0.7798\n",
      "Epoch 947/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4071 - accuracy: 0.8109 - val_loss: 0.4543 - val_accuracy: 0.7786\n",
      "Epoch 948/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4040 - accuracy: 0.8089 - val_loss: 0.4499 - val_accuracy: 0.7826\n",
      "Epoch 949/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4074 - accuracy: 0.8073 - val_loss: 0.4475 - val_accuracy: 0.7769\n",
      "Epoch 950/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4088 - accuracy: 0.8073 - val_loss: 0.4557 - val_accuracy: 0.7821\n",
      "Epoch 951/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4101 - accuracy: 0.8076 - val_loss: 0.4547 - val_accuracy: 0.7688\n",
      "Epoch 952/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4067 - accuracy: 0.8074 - val_loss: 0.4448 - val_accuracy: 0.7769\n",
      "Epoch 953/1500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4129 - accuracy: 0.8082 - val_loss: 0.4485 - val_accuracy: 0.7786\n",
      "Epoch 954/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4081 - accuracy: 0.8103 - val_loss: 0.4505 - val_accuracy: 0.7861\n",
      "Epoch 955/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4089 - accuracy: 0.8080 - val_loss: 0.4471 - val_accuracy: 0.7792\n",
      "Epoch 956/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4091 - accuracy: 0.8097 - val_loss: 0.4497 - val_accuracy: 0.7763\n",
      "Epoch 957/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4033 - accuracy: 0.8067 - val_loss: 0.4555 - val_accuracy: 0.7729\n",
      "Epoch 958/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4053 - accuracy: 0.8109 - val_loss: 0.4545 - val_accuracy: 0.7706\n",
      "Epoch 959/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4076 - accuracy: 0.8141 - val_loss: 0.4550 - val_accuracy: 0.7792\n",
      "Epoch 960/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4045 - accuracy: 0.8139 - val_loss: 0.4506 - val_accuracy: 0.7826\n",
      "Epoch 961/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4081 - accuracy: 0.8100 - val_loss: 0.4524 - val_accuracy: 0.7780\n",
      "Epoch 962/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4079 - accuracy: 0.8060 - val_loss: 0.4607 - val_accuracy: 0.7700\n",
      "Epoch 963/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4038 - accuracy: 0.8105 - val_loss: 0.4495 - val_accuracy: 0.7780\n",
      "Epoch 964/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4072 - accuracy: 0.8060 - val_loss: 0.4516 - val_accuracy: 0.7844\n",
      "Epoch 965/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4093 - accuracy: 0.8064 - val_loss: 0.4528 - val_accuracy: 0.7780\n",
      "Epoch 966/1500\n",
      "28/28 [==============================] - 2s 63ms/step - loss: 0.4074 - accuracy: 0.8085 - val_loss: 0.4504 - val_accuracy: 0.7763\n",
      "Epoch 967/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4063 - accuracy: 0.8044 - val_loss: 0.4486 - val_accuracy: 0.7769\n",
      "Epoch 968/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4068 - accuracy: 0.8089 - val_loss: 0.4629 - val_accuracy: 0.7706\n",
      "Epoch 969/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4101 - accuracy: 0.8085 - val_loss: 0.4575 - val_accuracy: 0.7740\n",
      "Epoch 970/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4139 - accuracy: 0.8076 - val_loss: 0.4515 - val_accuracy: 0.7786\n",
      "Epoch 971/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4097 - accuracy: 0.8087 - val_loss: 0.4514 - val_accuracy: 0.7792\n",
      "Epoch 972/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4085 - accuracy: 0.8083 - val_loss: 0.4741 - val_accuracy: 0.7665\n",
      "Epoch 973/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4091 - accuracy: 0.8067 - val_loss: 0.4491 - val_accuracy: 0.7803\n",
      "Epoch 974/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4094 - accuracy: 0.8067 - val_loss: 0.4551 - val_accuracy: 0.7752\n",
      "Epoch 975/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4093 - accuracy: 0.8085 - val_loss: 0.4540 - val_accuracy: 0.7798\n",
      "Epoch 976/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4162 - accuracy: 0.8074 - val_loss: 0.4532 - val_accuracy: 0.7792\n",
      "Epoch 977/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4093 - accuracy: 0.8062 - val_loss: 0.4547 - val_accuracy: 0.7763\n",
      "Epoch 978/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4074 - accuracy: 0.8100 - val_loss: 0.4563 - val_accuracy: 0.7769\n",
      "Epoch 979/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4027 - accuracy: 0.8110 - val_loss: 0.4504 - val_accuracy: 0.7849\n",
      "Epoch 980/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4078 - accuracy: 0.8051 - val_loss: 0.4615 - val_accuracy: 0.7809\n",
      "Epoch 981/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4075 - accuracy: 0.8073 - val_loss: 0.4524 - val_accuracy: 0.7752\n",
      "Epoch 982/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4111 - accuracy: 0.8036 - val_loss: 0.4514 - val_accuracy: 0.7803\n",
      "Epoch 983/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4019 - accuracy: 0.8112 - val_loss: 0.4561 - val_accuracy: 0.7769\n",
      "Epoch 984/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4020 - accuracy: 0.8086 - val_loss: 0.4556 - val_accuracy: 0.7803\n",
      "Epoch 985/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4083 - accuracy: 0.8096 - val_loss: 0.4558 - val_accuracy: 0.7815\n",
      "Epoch 986/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4054 - accuracy: 0.8103 - val_loss: 0.4544 - val_accuracy: 0.7763\n",
      "Epoch 987/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4107 - accuracy: 0.8050 - val_loss: 0.5115 - val_accuracy: 0.7504\n",
      "Epoch 988/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4105 - accuracy: 0.8050 - val_loss: 0.5584 - val_accuracy: 0.7458\n",
      "Epoch 989/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4089 - accuracy: 0.8070 - val_loss: 0.4470 - val_accuracy: 0.7832\n",
      "Epoch 990/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4051 - accuracy: 0.8100 - val_loss: 0.4552 - val_accuracy: 0.7780\n",
      "Epoch 991/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4053 - accuracy: 0.8089 - val_loss: 0.4510 - val_accuracy: 0.7844\n",
      "Epoch 992/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4092 - accuracy: 0.8095 - val_loss: 0.4535 - val_accuracy: 0.7746\n",
      "Epoch 993/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4075 - accuracy: 0.8113 - val_loss: 0.4554 - val_accuracy: 0.7792\n",
      "Epoch 994/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4102 - accuracy: 0.8139 - val_loss: 0.4491 - val_accuracy: 0.7792\n",
      "Epoch 995/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4050 - accuracy: 0.8115 - val_loss: 0.4557 - val_accuracy: 0.7780\n",
      "Epoch 996/1500\n",
      "28/28 [==============================] - 2s 64ms/step - loss: 0.4074 - accuracy: 0.8059 - val_loss: 0.4470 - val_accuracy: 0.7821\n",
      "Epoch 997/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4056 - accuracy: 0.8122 - val_loss: 0.4505 - val_accuracy: 0.7809\n",
      "Epoch 998/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4091 - accuracy: 0.8082 - val_loss: 0.4494 - val_accuracy: 0.7798\n",
      "Epoch 999/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4071 - accuracy: 0.8079 - val_loss: 0.4434 - val_accuracy: 0.7826\n",
      "Epoch 1000/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4086 - accuracy: 0.8074 - val_loss: 0.4553 - val_accuracy: 0.7723\n",
      "Epoch 1001/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4079 - accuracy: 0.8113 - val_loss: 0.4584 - val_accuracy: 0.7734\n",
      "Epoch 1002/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4131 - accuracy: 0.8031 - val_loss: 0.4519 - val_accuracy: 0.7740\n",
      "Epoch 1003/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4071 - accuracy: 0.8086 - val_loss: 0.4453 - val_accuracy: 0.7821\n",
      "Epoch 1004/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4021 - accuracy: 0.8105 - val_loss: 0.4617 - val_accuracy: 0.7729\n",
      "Epoch 1005/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4087 - accuracy: 0.8082 - val_loss: 0.4685 - val_accuracy: 0.7746\n",
      "Epoch 1006/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4032 - accuracy: 0.8115 - val_loss: 0.4586 - val_accuracy: 0.7815\n",
      "Epoch 1007/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4038 - accuracy: 0.8103 - val_loss: 0.4530 - val_accuracy: 0.7803\n",
      "Epoch 1008/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4057 - accuracy: 0.8131 - val_loss: 0.4544 - val_accuracy: 0.7775\n",
      "Epoch 1009/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4015 - accuracy: 0.8128 - val_loss: 0.4502 - val_accuracy: 0.7809\n",
      "Epoch 1010/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4103 - accuracy: 0.8090 - val_loss: 0.4588 - val_accuracy: 0.7757\n",
      "Epoch 1011/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4076 - accuracy: 0.8112 - val_loss: 0.4477 - val_accuracy: 0.7821\n",
      "Epoch 1012/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4074 - accuracy: 0.8095 - val_loss: 0.4538 - val_accuracy: 0.7826\n",
      "Epoch 1013/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4066 - accuracy: 0.8066 - val_loss: 0.4604 - val_accuracy: 0.7734\n",
      "Epoch 1014/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4109 - accuracy: 0.8096 - val_loss: 0.4527 - val_accuracy: 0.7809\n",
      "Epoch 1015/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4086 - accuracy: 0.8083 - val_loss: 0.4830 - val_accuracy: 0.7464\n",
      "Epoch 1016/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4115 - accuracy: 0.8080 - val_loss: 0.4738 - val_accuracy: 0.7648\n",
      "Epoch 1017/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4073 - accuracy: 0.8051 - val_loss: 0.4483 - val_accuracy: 0.7803\n",
      "Epoch 1018/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4082 - accuracy: 0.8072 - val_loss: 0.4529 - val_accuracy: 0.7740\n",
      "Epoch 1019/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4046 - accuracy: 0.8074 - val_loss: 0.4540 - val_accuracy: 0.7849\n",
      "Epoch 1020/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4084 - accuracy: 0.8095 - val_loss: 0.4489 - val_accuracy: 0.7821\n",
      "Epoch 1021/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4024 - accuracy: 0.8090 - val_loss: 0.4490 - val_accuracy: 0.7757\n",
      "Epoch 1022/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4037 - accuracy: 0.8110 - val_loss: 0.4598 - val_accuracy: 0.7729\n",
      "Epoch 1023/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4090 - accuracy: 0.8043 - val_loss: 0.4602 - val_accuracy: 0.7752\n",
      "Epoch 1024/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4062 - accuracy: 0.8103 - val_loss: 0.4540 - val_accuracy: 0.7769\n",
      "Epoch 1025/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4090 - accuracy: 0.8090 - val_loss: 0.4450 - val_accuracy: 0.7832\n",
      "Epoch 1026/1500\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.4084 - accuracy: 0.8076 - val_loss: 0.4463 - val_accuracy: 0.7757\n",
      "Epoch 1027/1500\n",
      "28/28 [==============================] - 1s 45ms/step - loss: 0.4042 - accuracy: 0.8119 - val_loss: 0.4496 - val_accuracy: 0.7798\n",
      "Epoch 1028/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4036 - accuracy: 0.8135 - val_loss: 0.4501 - val_accuracy: 0.7786\n",
      "Epoch 1029/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4033 - accuracy: 0.8115 - val_loss: 0.4561 - val_accuracy: 0.7798\n",
      "Epoch 1030/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4038 - accuracy: 0.8105 - val_loss: 0.4542 - val_accuracy: 0.7711\n",
      "Epoch 1031/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4011 - accuracy: 0.8110 - val_loss: 0.4532 - val_accuracy: 0.7826\n",
      "Epoch 1032/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4054 - accuracy: 0.8110 - val_loss: 0.4488 - val_accuracy: 0.7780\n",
      "Epoch 1033/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4067 - accuracy: 0.8112 - val_loss: 0.4577 - val_accuracy: 0.7717\n",
      "Epoch 1034/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4066 - accuracy: 0.8123 - val_loss: 0.4555 - val_accuracy: 0.7798\n",
      "Epoch 1035/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4014 - accuracy: 0.8095 - val_loss: 0.4490 - val_accuracy: 0.7792\n",
      "Epoch 1036/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4074 - accuracy: 0.8070 - val_loss: 0.4488 - val_accuracy: 0.7832\n",
      "Epoch 1037/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4004 - accuracy: 0.8109 - val_loss: 0.4642 - val_accuracy: 0.7746\n",
      "Epoch 1038/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4032 - accuracy: 0.8115 - val_loss: 0.4620 - val_accuracy: 0.7815\n",
      "Epoch 1039/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4008 - accuracy: 0.8105 - val_loss: 0.4542 - val_accuracy: 0.7838\n",
      "Epoch 1040/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4043 - accuracy: 0.8079 - val_loss: 0.4587 - val_accuracy: 0.7849\n",
      "Epoch 1041/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4056 - accuracy: 0.8069 - val_loss: 0.4622 - val_accuracy: 0.7838\n",
      "Epoch 1042/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4003 - accuracy: 0.8113 - val_loss: 0.4615 - val_accuracy: 0.7769\n",
      "Epoch 1043/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4064 - accuracy: 0.8082 - val_loss: 0.4560 - val_accuracy: 0.7740\n",
      "Epoch 1044/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4071 - accuracy: 0.8102 - val_loss: 0.4498 - val_accuracy: 0.7861\n",
      "Epoch 1045/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4033 - accuracy: 0.8087 - val_loss: 0.4590 - val_accuracy: 0.7769\n",
      "Epoch 1046/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4057 - accuracy: 0.8057 - val_loss: 0.4479 - val_accuracy: 0.7838\n",
      "Epoch 1047/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4062 - accuracy: 0.8115 - val_loss: 0.4594 - val_accuracy: 0.7677\n",
      "Epoch 1048/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4094 - accuracy: 0.8064 - val_loss: 0.4593 - val_accuracy: 0.7792\n",
      "Epoch 1049/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4070 - accuracy: 0.8077 - val_loss: 0.4481 - val_accuracy: 0.7792\n",
      "Epoch 1050/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4061 - accuracy: 0.8097 - val_loss: 0.4430 - val_accuracy: 0.7844\n",
      "Epoch 1051/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4028 - accuracy: 0.8131 - val_loss: 0.4489 - val_accuracy: 0.7792\n",
      "Epoch 1052/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4031 - accuracy: 0.8109 - val_loss: 0.4576 - val_accuracy: 0.7803\n",
      "Epoch 1053/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4018 - accuracy: 0.8074 - val_loss: 0.4516 - val_accuracy: 0.7757\n",
      "Epoch 1054/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4018 - accuracy: 0.8072 - val_loss: 0.4515 - val_accuracy: 0.7786\n",
      "Epoch 1055/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4026 - accuracy: 0.8122 - val_loss: 0.4548 - val_accuracy: 0.7792\n",
      "Epoch 1056/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4088 - accuracy: 0.8073 - val_loss: 0.4438 - val_accuracy: 0.7769\n",
      "Epoch 1057/1500\n",
      "28/28 [==============================] - 2s 64ms/step - loss: 0.4051 - accuracy: 0.8105 - val_loss: 0.4542 - val_accuracy: 0.7752\n",
      "Epoch 1058/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4021 - accuracy: 0.8097 - val_loss: 0.4560 - val_accuracy: 0.7786\n",
      "Epoch 1059/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4061 - accuracy: 0.8112 - val_loss: 0.4526 - val_accuracy: 0.7821\n",
      "Epoch 1060/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4065 - accuracy: 0.8118 - val_loss: 0.4500 - val_accuracy: 0.7821\n",
      "Epoch 1061/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4042 - accuracy: 0.8118 - val_loss: 0.4489 - val_accuracy: 0.7694\n",
      "Epoch 1062/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4061 - accuracy: 0.8064 - val_loss: 0.4517 - val_accuracy: 0.7734\n",
      "Epoch 1063/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4042 - accuracy: 0.8118 - val_loss: 0.4549 - val_accuracy: 0.7849\n",
      "Epoch 1064/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4020 - accuracy: 0.8082 - val_loss: 0.4549 - val_accuracy: 0.7746\n",
      "Epoch 1065/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4040 - accuracy: 0.8087 - val_loss: 0.4476 - val_accuracy: 0.7798\n",
      "Epoch 1066/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4064 - accuracy: 0.8115 - val_loss: 0.4471 - val_accuracy: 0.7809\n",
      "Epoch 1067/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4040 - accuracy: 0.8115 - val_loss: 0.4430 - val_accuracy: 0.7780\n",
      "Epoch 1068/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3974 - accuracy: 0.8105 - val_loss: 0.4524 - val_accuracy: 0.7786\n",
      "Epoch 1069/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4067 - accuracy: 0.8085 - val_loss: 0.4503 - val_accuracy: 0.7792\n",
      "Epoch 1070/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4059 - accuracy: 0.8108 - val_loss: 0.4466 - val_accuracy: 0.7775\n",
      "Epoch 1071/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4031 - accuracy: 0.8116 - val_loss: 0.4452 - val_accuracy: 0.7740\n",
      "Epoch 1072/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4019 - accuracy: 0.8096 - val_loss: 0.4619 - val_accuracy: 0.7688\n",
      "Epoch 1073/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4073 - accuracy: 0.8125 - val_loss: 0.4514 - val_accuracy: 0.7821\n",
      "Epoch 1074/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4080 - accuracy: 0.8118 - val_loss: 0.4581 - val_accuracy: 0.7775\n",
      "Epoch 1075/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4031 - accuracy: 0.8116 - val_loss: 0.4516 - val_accuracy: 0.7798\n",
      "Epoch 1076/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4024 - accuracy: 0.8069 - val_loss: 0.4496 - val_accuracy: 0.7798\n",
      "Epoch 1077/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4018 - accuracy: 0.8070 - val_loss: 0.4512 - val_accuracy: 0.7809\n",
      "Epoch 1078/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4077 - accuracy: 0.8109 - val_loss: 0.4548 - val_accuracy: 0.7723\n",
      "Epoch 1079/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4029 - accuracy: 0.8080 - val_loss: 0.4498 - val_accuracy: 0.7803\n",
      "Epoch 1080/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4005 - accuracy: 0.8109 - val_loss: 0.4561 - val_accuracy: 0.7798\n",
      "Epoch 1081/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4069 - accuracy: 0.8082 - val_loss: 0.4585 - val_accuracy: 0.7786\n",
      "Epoch 1082/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4081 - accuracy: 0.8102 - val_loss: 0.4542 - val_accuracy: 0.7861\n",
      "Epoch 1083/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.3968 - accuracy: 0.8128 - val_loss: 0.4540 - val_accuracy: 0.7809\n",
      "Epoch 1084/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4013 - accuracy: 0.8113 - val_loss: 0.4620 - val_accuracy: 0.7815\n",
      "Epoch 1085/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4084 - accuracy: 0.8097 - val_loss: 0.4589 - val_accuracy: 0.7780\n",
      "Epoch 1086/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4089 - accuracy: 0.8083 - val_loss: 0.4645 - val_accuracy: 0.7746\n",
      "Epoch 1087/1500\n",
      "28/28 [==============================] - 2s 64ms/step - loss: 0.4077 - accuracy: 0.8095 - val_loss: 0.4585 - val_accuracy: 0.7717\n",
      "Epoch 1088/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4043 - accuracy: 0.8102 - val_loss: 0.4616 - val_accuracy: 0.7792\n",
      "Epoch 1089/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4057 - accuracy: 0.8083 - val_loss: 0.4522 - val_accuracy: 0.7832\n",
      "Epoch 1090/1500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4005 - accuracy: 0.8118 - val_loss: 0.4550 - val_accuracy: 0.7809\n",
      "Epoch 1091/1500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4069 - accuracy: 0.8073 - val_loss: 0.4682 - val_accuracy: 0.7803\n",
      "Epoch 1092/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4101 - accuracy: 0.8100 - val_loss: 0.4590 - val_accuracy: 0.7826\n",
      "Epoch 1093/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4010 - accuracy: 0.8092 - val_loss: 0.4497 - val_accuracy: 0.7798\n",
      "Epoch 1094/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4089 - accuracy: 0.8128 - val_loss: 0.4668 - val_accuracy: 0.7637\n",
      "Epoch 1095/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4045 - accuracy: 0.8090 - val_loss: 0.4463 - val_accuracy: 0.7844\n",
      "Epoch 1096/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4020 - accuracy: 0.8085 - val_loss: 0.4528 - val_accuracy: 0.7746\n",
      "Epoch 1097/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4085 - accuracy: 0.8070 - val_loss: 0.4857 - val_accuracy: 0.7631\n",
      "Epoch 1098/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4066 - accuracy: 0.8049 - val_loss: 0.4566 - val_accuracy: 0.7798\n",
      "Epoch 1099/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4025 - accuracy: 0.8087 - val_loss: 0.4593 - val_accuracy: 0.7821\n",
      "Epoch 1100/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4055 - accuracy: 0.8159 - val_loss: 0.4671 - val_accuracy: 0.7614\n",
      "Epoch 1101/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.3959 - accuracy: 0.8099 - val_loss: 0.4519 - val_accuracy: 0.7780\n",
      "Epoch 1102/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4015 - accuracy: 0.8123 - val_loss: 0.4681 - val_accuracy: 0.7700\n",
      "Epoch 1103/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4099 - accuracy: 0.8072 - val_loss: 0.4681 - val_accuracy: 0.7809\n",
      "Epoch 1104/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4057 - accuracy: 0.8077 - val_loss: 0.4559 - val_accuracy: 0.7752\n",
      "Epoch 1105/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3985 - accuracy: 0.8097 - val_loss: 0.4567 - val_accuracy: 0.7746\n",
      "Epoch 1106/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4068 - accuracy: 0.8102 - val_loss: 0.4594 - val_accuracy: 0.7775\n",
      "Epoch 1107/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4041 - accuracy: 0.8132 - val_loss: 0.4556 - val_accuracy: 0.7775\n",
      "Epoch 1108/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4032 - accuracy: 0.8136 - val_loss: 0.4550 - val_accuracy: 0.7798\n",
      "Epoch 1109/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4054 - accuracy: 0.8125 - val_loss: 0.4563 - val_accuracy: 0.7729\n",
      "Epoch 1110/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4047 - accuracy: 0.8089 - val_loss: 0.4497 - val_accuracy: 0.7844\n",
      "Epoch 1111/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4051 - accuracy: 0.8106 - val_loss: 0.4634 - val_accuracy: 0.7723\n",
      "Epoch 1112/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4013 - accuracy: 0.8110 - val_loss: 0.4623 - val_accuracy: 0.7757\n",
      "Epoch 1113/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4032 - accuracy: 0.8131 - val_loss: 0.4508 - val_accuracy: 0.7746\n",
      "Epoch 1114/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3988 - accuracy: 0.8115 - val_loss: 0.4712 - val_accuracy: 0.7752\n",
      "Epoch 1115/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3999 - accuracy: 0.8132 - val_loss: 0.4528 - val_accuracy: 0.7821\n",
      "Epoch 1116/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4002 - accuracy: 0.8148 - val_loss: 0.4645 - val_accuracy: 0.7723\n",
      "Epoch 1117/1500\n",
      "28/28 [==============================] - 2s 60ms/step - loss: 0.4047 - accuracy: 0.8102 - val_loss: 0.4525 - val_accuracy: 0.7763\n",
      "Epoch 1118/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4006 - accuracy: 0.8146 - val_loss: 0.4512 - val_accuracy: 0.7821\n",
      "Epoch 1119/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4009 - accuracy: 0.8136 - val_loss: 0.4544 - val_accuracy: 0.7763\n",
      "Epoch 1120/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4023 - accuracy: 0.8105 - val_loss: 0.4582 - val_accuracy: 0.7729\n",
      "Epoch 1121/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4008 - accuracy: 0.8131 - val_loss: 0.4743 - val_accuracy: 0.7654\n",
      "Epoch 1122/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4052 - accuracy: 0.8139 - val_loss: 0.4566 - val_accuracy: 0.7752\n",
      "Epoch 1123/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3996 - accuracy: 0.8141 - val_loss: 0.4569 - val_accuracy: 0.7798\n",
      "Epoch 1124/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4033 - accuracy: 0.8082 - val_loss: 0.4529 - val_accuracy: 0.7763\n",
      "Epoch 1125/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4072 - accuracy: 0.8110 - val_loss: 0.4635 - val_accuracy: 0.7694\n",
      "Epoch 1126/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3964 - accuracy: 0.8158 - val_loss: 0.4588 - val_accuracy: 0.7757\n",
      "Epoch 1127/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4034 - accuracy: 0.8129 - val_loss: 0.4551 - val_accuracy: 0.7763\n",
      "Epoch 1128/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3981 - accuracy: 0.8122 - val_loss: 0.4576 - val_accuracy: 0.7775\n",
      "Epoch 1129/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3982 - accuracy: 0.8131 - val_loss: 0.4583 - val_accuracy: 0.7815\n",
      "Epoch 1130/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4048 - accuracy: 0.8097 - val_loss: 0.4708 - val_accuracy: 0.7821\n",
      "Epoch 1131/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4100 - accuracy: 0.8102 - val_loss: 0.4714 - val_accuracy: 0.7706\n",
      "Epoch 1132/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4040 - accuracy: 0.8099 - val_loss: 0.4588 - val_accuracy: 0.7826\n",
      "Epoch 1133/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4030 - accuracy: 0.8105 - val_loss: 0.4571 - val_accuracy: 0.7780\n",
      "Epoch 1134/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.3981 - accuracy: 0.8119 - val_loss: 0.4548 - val_accuracy: 0.7803\n",
      "Epoch 1135/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4125 - accuracy: 0.8054 - val_loss: 0.4519 - val_accuracy: 0.7798\n",
      "Epoch 1136/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4019 - accuracy: 0.8097 - val_loss: 0.4586 - val_accuracy: 0.7694\n",
      "Epoch 1137/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4042 - accuracy: 0.8086 - val_loss: 0.4570 - val_accuracy: 0.7734\n",
      "Epoch 1138/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4097 - accuracy: 0.8039 - val_loss: 0.4574 - val_accuracy: 0.7815\n",
      "Epoch 1139/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4007 - accuracy: 0.8132 - val_loss: 0.4556 - val_accuracy: 0.7792\n",
      "Epoch 1140/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4002 - accuracy: 0.8102 - val_loss: 0.4611 - val_accuracy: 0.7809\n",
      "Epoch 1141/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4001 - accuracy: 0.8115 - val_loss: 0.4667 - val_accuracy: 0.7752\n",
      "Epoch 1142/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4048 - accuracy: 0.8085 - val_loss: 0.4586 - val_accuracy: 0.7729\n",
      "Epoch 1143/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4028 - accuracy: 0.8129 - val_loss: 0.4654 - val_accuracy: 0.7792\n",
      "Epoch 1144/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4003 - accuracy: 0.8095 - val_loss: 0.4561 - val_accuracy: 0.7757\n",
      "Epoch 1145/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4044 - accuracy: 0.8128 - val_loss: 0.4614 - val_accuracy: 0.7769\n",
      "Epoch 1146/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4020 - accuracy: 0.8148 - val_loss: 0.4595 - val_accuracy: 0.7826\n",
      "Epoch 1147/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4016 - accuracy: 0.8106 - val_loss: 0.4591 - val_accuracy: 0.7706\n",
      "Epoch 1148/1500\n",
      "28/28 [==============================] - 2s 63ms/step - loss: 0.4099 - accuracy: 0.8063 - val_loss: 0.4563 - val_accuracy: 0.7780\n",
      "Epoch 1149/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4013 - accuracy: 0.8105 - val_loss: 0.4595 - val_accuracy: 0.7780\n",
      "Epoch 1150/1500\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.4025 - accuracy: 0.8093 - val_loss: 0.4575 - val_accuracy: 0.7763\n",
      "Epoch 1151/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4005 - accuracy: 0.8041 - val_loss: 0.4522 - val_accuracy: 0.7734\n",
      "Epoch 1152/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3986 - accuracy: 0.8118 - val_loss: 0.4580 - val_accuracy: 0.7775\n",
      "Epoch 1153/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3993 - accuracy: 0.8110 - val_loss: 0.4617 - val_accuracy: 0.7757\n",
      "Epoch 1154/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4022 - accuracy: 0.8079 - val_loss: 0.4626 - val_accuracy: 0.7792\n",
      "Epoch 1155/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4048 - accuracy: 0.8096 - val_loss: 0.4518 - val_accuracy: 0.7769\n",
      "Epoch 1156/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4024 - accuracy: 0.8115 - val_loss: 0.4632 - val_accuracy: 0.7734\n",
      "Epoch 1157/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4012 - accuracy: 0.8072 - val_loss: 0.4579 - val_accuracy: 0.7809\n",
      "Epoch 1158/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4017 - accuracy: 0.8145 - val_loss: 0.4618 - val_accuracy: 0.7752\n",
      "Epoch 1159/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3988 - accuracy: 0.8162 - val_loss: 0.4630 - val_accuracy: 0.7752\n",
      "Epoch 1160/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4061 - accuracy: 0.8106 - val_loss: 0.4555 - val_accuracy: 0.7694\n",
      "Epoch 1161/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4008 - accuracy: 0.8138 - val_loss: 0.4562 - val_accuracy: 0.7769\n",
      "Epoch 1162/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4011 - accuracy: 0.8125 - val_loss: 0.4599 - val_accuracy: 0.7740\n",
      "Epoch 1163/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4029 - accuracy: 0.8106 - val_loss: 0.4524 - val_accuracy: 0.7752\n",
      "Epoch 1164/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4021 - accuracy: 0.8121 - val_loss: 0.4593 - val_accuracy: 0.7826\n",
      "Epoch 1165/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4008 - accuracy: 0.8139 - val_loss: 0.4545 - val_accuracy: 0.7798\n",
      "Epoch 1166/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4020 - accuracy: 0.8112 - val_loss: 0.4599 - val_accuracy: 0.7775\n",
      "Epoch 1167/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4033 - accuracy: 0.8145 - val_loss: 0.4557 - val_accuracy: 0.7752\n",
      "Epoch 1168/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3944 - accuracy: 0.8161 - val_loss: 0.4573 - val_accuracy: 0.7711\n",
      "Epoch 1169/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4030 - accuracy: 0.8095 - val_loss: 0.4593 - val_accuracy: 0.7711\n",
      "Epoch 1170/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4038 - accuracy: 0.8109 - val_loss: 0.4568 - val_accuracy: 0.7769\n",
      "Epoch 1171/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3990 - accuracy: 0.8148 - val_loss: 0.4599 - val_accuracy: 0.7700\n",
      "Epoch 1172/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3941 - accuracy: 0.8133 - val_loss: 0.4580 - val_accuracy: 0.7763\n",
      "Epoch 1173/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4021 - accuracy: 0.8141 - val_loss: 0.4780 - val_accuracy: 0.7746\n",
      "Epoch 1174/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4043 - accuracy: 0.8089 - val_loss: 0.4638 - val_accuracy: 0.7717\n",
      "Epoch 1175/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4017 - accuracy: 0.8131 - val_loss: 0.4594 - val_accuracy: 0.7671\n",
      "Epoch 1176/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3962 - accuracy: 0.8118 - val_loss: 0.4728 - val_accuracy: 0.7625\n",
      "Epoch 1177/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4038 - accuracy: 0.8133 - val_loss: 0.4659 - val_accuracy: 0.7752\n",
      "Epoch 1178/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3994 - accuracy: 0.8083 - val_loss: 0.4516 - val_accuracy: 0.7815\n",
      "Epoch 1179/1500\n",
      "28/28 [==============================] - 2s 61ms/step - loss: 0.3965 - accuracy: 0.8165 - val_loss: 0.4562 - val_accuracy: 0.7769\n",
      "Epoch 1180/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4119 - accuracy: 0.8069 - val_loss: 0.4554 - val_accuracy: 0.7786\n",
      "Epoch 1181/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3973 - accuracy: 0.8122 - val_loss: 0.4525 - val_accuracy: 0.7752\n",
      "Epoch 1182/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4037 - accuracy: 0.8074 - val_loss: 0.4638 - val_accuracy: 0.7769\n",
      "Epoch 1183/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3992 - accuracy: 0.8090 - val_loss: 0.4558 - val_accuracy: 0.7792\n",
      "Epoch 1184/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3964 - accuracy: 0.8113 - val_loss: 0.4539 - val_accuracy: 0.7821\n",
      "Epoch 1185/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3986 - accuracy: 0.8135 - val_loss: 0.4584 - val_accuracy: 0.7763\n",
      "Epoch 1186/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4028 - accuracy: 0.8096 - val_loss: 0.4522 - val_accuracy: 0.7809\n",
      "Epoch 1187/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4022 - accuracy: 0.8118 - val_loss: 0.4682 - val_accuracy: 0.7740\n",
      "Epoch 1188/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4058 - accuracy: 0.8123 - val_loss: 0.4601 - val_accuracy: 0.7757\n",
      "Epoch 1189/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4013 - accuracy: 0.8125 - val_loss: 0.4540 - val_accuracy: 0.7752\n",
      "Epoch 1190/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3969 - accuracy: 0.8159 - val_loss: 0.4561 - val_accuracy: 0.7809\n",
      "Epoch 1191/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4002 - accuracy: 0.8118 - val_loss: 0.4598 - val_accuracy: 0.7734\n",
      "Epoch 1192/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3964 - accuracy: 0.8174 - val_loss: 0.4565 - val_accuracy: 0.7769\n",
      "Epoch 1193/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4043 - accuracy: 0.8138 - val_loss: 0.4643 - val_accuracy: 0.7775\n",
      "Epoch 1194/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4095 - accuracy: 0.8109 - val_loss: 0.4733 - val_accuracy: 0.7746\n",
      "Epoch 1195/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4018 - accuracy: 0.8113 - val_loss: 0.4555 - val_accuracy: 0.7775\n",
      "Epoch 1196/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3979 - accuracy: 0.8122 - val_loss: 0.4573 - val_accuracy: 0.7757\n",
      "Epoch 1197/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4025 - accuracy: 0.8136 - val_loss: 0.4557 - val_accuracy: 0.7763\n",
      "Epoch 1198/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3975 - accuracy: 0.8135 - val_loss: 0.4600 - val_accuracy: 0.7746\n",
      "Epoch 1199/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3948 - accuracy: 0.8152 - val_loss: 0.4607 - val_accuracy: 0.7700\n",
      "Epoch 1200/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4033 - accuracy: 0.8053 - val_loss: 0.4760 - val_accuracy: 0.7619\n",
      "Epoch 1201/1500\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.3991 - accuracy: 0.8089 - val_loss: 0.4505 - val_accuracy: 0.7780\n",
      "Epoch 1202/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4003 - accuracy: 0.8106 - val_loss: 0.4504 - val_accuracy: 0.7711\n",
      "Epoch 1203/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4022 - accuracy: 0.8109 - val_loss: 0.4570 - val_accuracy: 0.7798\n",
      "Epoch 1204/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3998 - accuracy: 0.8146 - val_loss: 0.4592 - val_accuracy: 0.7757\n",
      "Epoch 1205/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3953 - accuracy: 0.8102 - val_loss: 0.4557 - val_accuracy: 0.7746\n",
      "Epoch 1206/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4034 - accuracy: 0.8099 - val_loss: 0.4672 - val_accuracy: 0.7746\n",
      "Epoch 1207/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4006 - accuracy: 0.8115 - val_loss: 0.4693 - val_accuracy: 0.7763\n",
      "Epoch 1208/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4141 - accuracy: 0.8043 - val_loss: 0.4573 - val_accuracy: 0.7740\n",
      "Epoch 1209/1500\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 0.4064 - accuracy: 0.8086 - val_loss: 0.4544 - val_accuracy: 0.7746\n",
      "Epoch 1210/1500\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.4017 - accuracy: 0.8095 - val_loss: 0.4542 - val_accuracy: 0.7826\n",
      "Epoch 1211/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4000 - accuracy: 0.8135 - val_loss: 0.4579 - val_accuracy: 0.7734\n",
      "Epoch 1212/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4022 - accuracy: 0.8089 - val_loss: 0.4536 - val_accuracy: 0.7769\n",
      "Epoch 1213/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3959 - accuracy: 0.8123 - val_loss: 0.4595 - val_accuracy: 0.7740\n",
      "Epoch 1214/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3991 - accuracy: 0.8131 - val_loss: 0.4580 - val_accuracy: 0.7757\n",
      "Epoch 1215/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3992 - accuracy: 0.8162 - val_loss: 0.4602 - val_accuracy: 0.7734\n",
      "Epoch 1216/1500\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.4066 - accuracy: 0.8116 - val_loss: 0.4567 - val_accuracy: 0.7700\n",
      "Epoch 1217/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3978 - accuracy: 0.8126 - val_loss: 0.4651 - val_accuracy: 0.7757\n",
      "Epoch 1218/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4024 - accuracy: 0.8131 - val_loss: 0.4500 - val_accuracy: 0.7752\n",
      "Epoch 1219/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3989 - accuracy: 0.8128 - val_loss: 0.4637 - val_accuracy: 0.7746\n",
      "Epoch 1220/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.3961 - accuracy: 0.8174 - val_loss: 0.4594 - val_accuracy: 0.7792\n",
      "Epoch 1221/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3982 - accuracy: 0.8095 - val_loss: 0.4772 - val_accuracy: 0.7602\n",
      "Epoch 1222/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4050 - accuracy: 0.8089 - val_loss: 0.4588 - val_accuracy: 0.7786\n",
      "Epoch 1223/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3963 - accuracy: 0.8132 - val_loss: 0.4582 - val_accuracy: 0.7798\n",
      "Epoch 1224/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3960 - accuracy: 0.8167 - val_loss: 0.4658 - val_accuracy: 0.7688\n",
      "Epoch 1225/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3987 - accuracy: 0.8116 - val_loss: 0.4586 - val_accuracy: 0.7780\n",
      "Epoch 1226/1500\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.3974 - accuracy: 0.8128 - val_loss: 0.4654 - val_accuracy: 0.7746\n",
      "Epoch 1227/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3957 - accuracy: 0.8154 - val_loss: 0.4692 - val_accuracy: 0.7786\n",
      "Epoch 1228/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3972 - accuracy: 0.8139 - val_loss: 0.4715 - val_accuracy: 0.7769\n",
      "Epoch 1229/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3987 - accuracy: 0.8133 - val_loss: 0.4636 - val_accuracy: 0.7803\n",
      "Epoch 1230/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4022 - accuracy: 0.8085 - val_loss: 0.4593 - val_accuracy: 0.7780\n",
      "Epoch 1231/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3987 - accuracy: 0.8112 - val_loss: 0.4571 - val_accuracy: 0.7729\n",
      "Epoch 1232/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.3962 - accuracy: 0.8155 - val_loss: 0.4553 - val_accuracy: 0.7826\n",
      "Epoch 1233/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3941 - accuracy: 0.8135 - val_loss: 0.4830 - val_accuracy: 0.7573\n",
      "Epoch 1234/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4040 - accuracy: 0.8113 - val_loss: 0.4622 - val_accuracy: 0.7746\n",
      "Epoch 1235/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3946 - accuracy: 0.8156 - val_loss: 0.4530 - val_accuracy: 0.7826\n",
      "Epoch 1236/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3966 - accuracy: 0.8138 - val_loss: 0.4518 - val_accuracy: 0.7775\n",
      "Epoch 1237/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4005 - accuracy: 0.8135 - val_loss: 0.4531 - val_accuracy: 0.7780\n",
      "Epoch 1238/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4024 - accuracy: 0.8133 - val_loss: 0.4545 - val_accuracy: 0.7763\n",
      "Epoch 1239/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3992 - accuracy: 0.8156 - val_loss: 0.4634 - val_accuracy: 0.7711\n",
      "Epoch 1240/1500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4001 - accuracy: 0.8115 - val_loss: 0.4619 - val_accuracy: 0.7671\n",
      "Epoch 1241/1500\n",
      "28/28 [==============================] - 2s 59ms/step - loss: 0.3963 - accuracy: 0.8164 - val_loss: 0.4633 - val_accuracy: 0.7746\n",
      "Epoch 1242/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3979 - accuracy: 0.8158 - val_loss: 0.4561 - val_accuracy: 0.7815\n",
      "Epoch 1243/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3990 - accuracy: 0.8138 - val_loss: 0.4573 - val_accuracy: 0.7734\n",
      "Epoch 1244/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4014 - accuracy: 0.8095 - val_loss: 0.4550 - val_accuracy: 0.7798\n",
      "Epoch 1245/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3973 - accuracy: 0.8141 - val_loss: 0.4600 - val_accuracy: 0.7769\n",
      "Epoch 1246/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3984 - accuracy: 0.8096 - val_loss: 0.4695 - val_accuracy: 0.7706\n",
      "Epoch 1247/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3970 - accuracy: 0.8133 - val_loss: 0.4616 - val_accuracy: 0.7746\n",
      "Epoch 1248/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3943 - accuracy: 0.8148 - val_loss: 0.4568 - val_accuracy: 0.7723\n",
      "Epoch 1249/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4007 - accuracy: 0.8100 - val_loss: 0.4561 - val_accuracy: 0.7746\n",
      "Epoch 1250/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3898 - accuracy: 0.8146 - val_loss: 0.4575 - val_accuracy: 0.7752\n",
      "Epoch 1251/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3980 - accuracy: 0.8151 - val_loss: 0.4643 - val_accuracy: 0.7786\n",
      "Epoch 1252/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3984 - accuracy: 0.8116 - val_loss: 0.4605 - val_accuracy: 0.7677\n",
      "Epoch 1253/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3985 - accuracy: 0.8155 - val_loss: 0.4644 - val_accuracy: 0.7677\n",
      "Epoch 1254/1500\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.4075 - accuracy: 0.8106 - val_loss: 0.4599 - val_accuracy: 0.7775\n",
      "Epoch 1255/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3995 - accuracy: 0.8123 - val_loss: 0.4552 - val_accuracy: 0.7752\n",
      "Epoch 1256/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3979 - accuracy: 0.8106 - val_loss: 0.4528 - val_accuracy: 0.7775\n",
      "Epoch 1257/1500\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.3949 - accuracy: 0.8158 - val_loss: 0.4609 - val_accuracy: 0.7798\n",
      "Epoch 1258/1500\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.4009 - accuracy: 0.8128 - val_loss: 0.4602 - val_accuracy: 0.7746\n",
      "Epoch 1259/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3977 - accuracy: 0.8099 - val_loss: 0.4569 - val_accuracy: 0.7815\n",
      "Epoch 1260/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4029 - accuracy: 0.8148 - val_loss: 0.4639 - val_accuracy: 0.7746\n",
      "Epoch 1261/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3989 - accuracy: 0.8119 - val_loss: 0.4499 - val_accuracy: 0.7780\n",
      "Epoch 1262/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4003 - accuracy: 0.8132 - val_loss: 0.4552 - val_accuracy: 0.7780\n",
      "Epoch 1263/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.3984 - accuracy: 0.8113 - val_loss: 0.4619 - val_accuracy: 0.7746\n",
      "Epoch 1264/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4080 - accuracy: 0.8087 - val_loss: 0.4762 - val_accuracy: 0.7769\n",
      "Epoch 1265/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4007 - accuracy: 0.8138 - val_loss: 0.4641 - val_accuracy: 0.7786\n",
      "Epoch 1266/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4018 - accuracy: 0.8092 - val_loss: 0.4661 - val_accuracy: 0.7734\n",
      "Epoch 1267/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3952 - accuracy: 0.8135 - val_loss: 0.4701 - val_accuracy: 0.7717\n",
      "Epoch 1268/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3994 - accuracy: 0.8123 - val_loss: 0.4741 - val_accuracy: 0.7637\n",
      "Epoch 1269/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3918 - accuracy: 0.8179 - val_loss: 0.4653 - val_accuracy: 0.7723\n",
      "Epoch 1270/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3965 - accuracy: 0.8149 - val_loss: 0.4588 - val_accuracy: 0.7769\n",
      "Epoch 1271/1500\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.3973 - accuracy: 0.8110 - val_loss: 0.4765 - val_accuracy: 0.7596\n",
      "Epoch 1272/1500\n",
      "28/28 [==============================] - 2s 60ms/step - loss: 0.4017 - accuracy: 0.8110 - val_loss: 0.4531 - val_accuracy: 0.7815\n",
      "Epoch 1273/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4003 - accuracy: 0.8126 - val_loss: 0.4568 - val_accuracy: 0.7838\n",
      "Epoch 1274/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3940 - accuracy: 0.8142 - val_loss: 0.4633 - val_accuracy: 0.7803\n",
      "Epoch 1275/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3941 - accuracy: 0.8131 - val_loss: 0.4595 - val_accuracy: 0.7803\n",
      "Epoch 1276/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3947 - accuracy: 0.8142 - val_loss: 0.4628 - val_accuracy: 0.7746\n",
      "Epoch 1277/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4047 - accuracy: 0.8099 - val_loss: 0.4683 - val_accuracy: 0.7706\n",
      "Epoch 1278/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3989 - accuracy: 0.8102 - val_loss: 0.4659 - val_accuracy: 0.7683\n",
      "Epoch 1279/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3954 - accuracy: 0.8164 - val_loss: 0.4558 - val_accuracy: 0.7826\n",
      "Epoch 1280/1500\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.3979 - accuracy: 0.8099 - val_loss: 0.4605 - val_accuracy: 0.7775\n",
      "Epoch 1281/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3965 - accuracy: 0.8131 - val_loss: 0.4579 - val_accuracy: 0.7763\n",
      "Epoch 1282/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3919 - accuracy: 0.8128 - val_loss: 0.4660 - val_accuracy: 0.7734\n",
      "Epoch 1283/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3943 - accuracy: 0.8139 - val_loss: 0.4628 - val_accuracy: 0.7769\n",
      "Epoch 1284/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3971 - accuracy: 0.8171 - val_loss: 0.4595 - val_accuracy: 0.7792\n",
      "Epoch 1285/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3986 - accuracy: 0.8125 - val_loss: 0.4712 - val_accuracy: 0.7775\n",
      "Epoch 1286/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3982 - accuracy: 0.8110 - val_loss: 0.4605 - val_accuracy: 0.7763\n",
      "Epoch 1287/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3950 - accuracy: 0.8133 - val_loss: 0.4563 - val_accuracy: 0.7815\n",
      "Epoch 1288/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3978 - accuracy: 0.8156 - val_loss: 0.4727 - val_accuracy: 0.7706\n",
      "Epoch 1289/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3960 - accuracy: 0.8156 - val_loss: 0.4674 - val_accuracy: 0.7677\n",
      "Epoch 1290/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3910 - accuracy: 0.8178 - val_loss: 0.4637 - val_accuracy: 0.7769\n",
      "Epoch 1291/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3912 - accuracy: 0.8171 - val_loss: 0.4594 - val_accuracy: 0.7775\n",
      "Epoch 1292/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3956 - accuracy: 0.8156 - val_loss: 0.4715 - val_accuracy: 0.7723\n",
      "Epoch 1293/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3999 - accuracy: 0.8156 - val_loss: 0.4641 - val_accuracy: 0.7740\n",
      "Epoch 1294/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3928 - accuracy: 0.8165 - val_loss: 0.4588 - val_accuracy: 0.7752\n",
      "Epoch 1295/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4036 - accuracy: 0.8103 - val_loss: 0.4683 - val_accuracy: 0.7798\n",
      "Epoch 1296/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4063 - accuracy: 0.8074 - val_loss: 0.4662 - val_accuracy: 0.7734\n",
      "Epoch 1297/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3990 - accuracy: 0.8136 - val_loss: 0.4569 - val_accuracy: 0.7775\n",
      "Epoch 1298/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3936 - accuracy: 0.8161 - val_loss: 0.4561 - val_accuracy: 0.7763\n",
      "Epoch 1299/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3989 - accuracy: 0.8151 - val_loss: 0.4711 - val_accuracy: 0.7798\n",
      "Epoch 1300/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4009 - accuracy: 0.8113 - val_loss: 0.4589 - val_accuracy: 0.7757\n",
      "Epoch 1301/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3984 - accuracy: 0.8152 - val_loss: 0.4690 - val_accuracy: 0.7809\n",
      "Epoch 1302/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4010 - accuracy: 0.8139 - val_loss: 0.4815 - val_accuracy: 0.7642\n",
      "Epoch 1303/1500\n",
      "28/28 [==============================] - 2s 61ms/step - loss: 0.3971 - accuracy: 0.8129 - val_loss: 0.4839 - val_accuracy: 0.7608\n",
      "Epoch 1304/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3991 - accuracy: 0.8148 - val_loss: 0.4637 - val_accuracy: 0.7780\n",
      "Epoch 1305/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3961 - accuracy: 0.8139 - val_loss: 0.4593 - val_accuracy: 0.7740\n",
      "Epoch 1306/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3920 - accuracy: 0.8185 - val_loss: 0.4593 - val_accuracy: 0.7740\n",
      "Epoch 1307/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.3938 - accuracy: 0.8146 - val_loss: 0.4644 - val_accuracy: 0.7648\n",
      "Epoch 1308/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3963 - accuracy: 0.8113 - val_loss: 0.4584 - val_accuracy: 0.7798\n",
      "Epoch 1309/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3963 - accuracy: 0.8146 - val_loss: 0.4635 - val_accuracy: 0.7757\n",
      "Epoch 1310/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3942 - accuracy: 0.8122 - val_loss: 0.4602 - val_accuracy: 0.7803\n",
      "Epoch 1311/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3903 - accuracy: 0.8155 - val_loss: 0.4636 - val_accuracy: 0.7826\n",
      "Epoch 1312/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3961 - accuracy: 0.8119 - val_loss: 0.4736 - val_accuracy: 0.7717\n",
      "Epoch 1313/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4036 - accuracy: 0.8132 - val_loss: 0.4664 - val_accuracy: 0.7798\n",
      "Epoch 1314/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3968 - accuracy: 0.8118 - val_loss: 0.4567 - val_accuracy: 0.7752\n",
      "Epoch 1315/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3985 - accuracy: 0.8145 - val_loss: 0.4590 - val_accuracy: 0.7763\n",
      "Epoch 1316/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3937 - accuracy: 0.8105 - val_loss: 0.4513 - val_accuracy: 0.7792\n",
      "Epoch 1317/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3974 - accuracy: 0.8119 - val_loss: 0.4646 - val_accuracy: 0.7711\n",
      "Epoch 1318/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3983 - accuracy: 0.8161 - val_loss: 0.4577 - val_accuracy: 0.7792\n",
      "Epoch 1319/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3968 - accuracy: 0.8146 - val_loss: 0.4599 - val_accuracy: 0.7786\n",
      "Epoch 1320/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3912 - accuracy: 0.8135 - val_loss: 0.4614 - val_accuracy: 0.7757\n",
      "Epoch 1321/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3969 - accuracy: 0.8125 - val_loss: 0.4655 - val_accuracy: 0.7792\n",
      "Epoch 1322/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3974 - accuracy: 0.8129 - val_loss: 0.4648 - val_accuracy: 0.7769\n",
      "Epoch 1323/1500\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.3932 - accuracy: 0.8159 - val_loss: 0.4649 - val_accuracy: 0.7798\n",
      "Epoch 1324/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3977 - accuracy: 0.8125 - val_loss: 0.4757 - val_accuracy: 0.7723\n",
      "Epoch 1325/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3975 - accuracy: 0.8139 - val_loss: 0.4719 - val_accuracy: 0.7706\n",
      "Epoch 1326/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3961 - accuracy: 0.8138 - val_loss: 0.4746 - val_accuracy: 0.7780\n",
      "Epoch 1327/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3944 - accuracy: 0.8152 - val_loss: 0.4830 - val_accuracy: 0.7723\n",
      "Epoch 1328/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3945 - accuracy: 0.8125 - val_loss: 0.4665 - val_accuracy: 0.7786\n",
      "Epoch 1329/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3959 - accuracy: 0.8159 - val_loss: 0.4662 - val_accuracy: 0.7723\n",
      "Epoch 1330/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3964 - accuracy: 0.8165 - val_loss: 0.4681 - val_accuracy: 0.7780\n",
      "Epoch 1331/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3964 - accuracy: 0.8148 - val_loss: 0.4644 - val_accuracy: 0.7798\n",
      "Epoch 1332/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3955 - accuracy: 0.8152 - val_loss: 0.4652 - val_accuracy: 0.7757\n",
      "Epoch 1333/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3942 - accuracy: 0.8156 - val_loss: 0.4675 - val_accuracy: 0.7723\n",
      "Epoch 1334/1500\n",
      "28/28 [==============================] - 2s 62ms/step - loss: 0.3955 - accuracy: 0.8139 - val_loss: 0.4777 - val_accuracy: 0.7763\n",
      "Epoch 1335/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3899 - accuracy: 0.8172 - val_loss: 0.4719 - val_accuracy: 0.7792\n",
      "Epoch 1336/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3931 - accuracy: 0.8154 - val_loss: 0.4698 - val_accuracy: 0.7792\n",
      "Epoch 1337/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3930 - accuracy: 0.8178 - val_loss: 0.4657 - val_accuracy: 0.7803\n",
      "Epoch 1338/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4000 - accuracy: 0.8142 - val_loss: 0.4762 - val_accuracy: 0.7717\n",
      "Epoch 1339/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3953 - accuracy: 0.8151 - val_loss: 0.4777 - val_accuracy: 0.7729\n",
      "Epoch 1340/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3928 - accuracy: 0.8174 - val_loss: 0.4605 - val_accuracy: 0.7763\n",
      "Epoch 1341/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3935 - accuracy: 0.8162 - val_loss: 0.4616 - val_accuracy: 0.7775\n",
      "Epoch 1342/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3930 - accuracy: 0.8128 - val_loss: 0.4573 - val_accuracy: 0.7763\n",
      "Epoch 1343/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3885 - accuracy: 0.8175 - val_loss: 0.4785 - val_accuracy: 0.7717\n",
      "Epoch 1344/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4127 - accuracy: 0.8070 - val_loss: 0.4823 - val_accuracy: 0.7757\n",
      "Epoch 1345/1500\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.4000 - accuracy: 0.8121 - val_loss: 0.4530 - val_accuracy: 0.7798\n",
      "Epoch 1346/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4014 - accuracy: 0.8103 - val_loss: 0.4545 - val_accuracy: 0.7740\n",
      "Epoch 1347/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3944 - accuracy: 0.8191 - val_loss: 0.4589 - val_accuracy: 0.7775\n",
      "Epoch 1348/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3934 - accuracy: 0.8123 - val_loss: 0.4592 - val_accuracy: 0.7769\n",
      "Epoch 1349/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3926 - accuracy: 0.8162 - val_loss: 0.4619 - val_accuracy: 0.7740\n",
      "Epoch 1350/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3941 - accuracy: 0.8144 - val_loss: 0.4658 - val_accuracy: 0.7769\n",
      "Epoch 1351/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3906 - accuracy: 0.8144 - val_loss: 0.4652 - val_accuracy: 0.7717\n",
      "Epoch 1352/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3937 - accuracy: 0.8145 - val_loss: 0.4734 - val_accuracy: 0.7763\n",
      "Epoch 1353/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3959 - accuracy: 0.8154 - val_loss: 0.4802 - val_accuracy: 0.7677\n",
      "Epoch 1354/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3969 - accuracy: 0.8148 - val_loss: 0.4737 - val_accuracy: 0.7671\n",
      "Epoch 1355/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3898 - accuracy: 0.8164 - val_loss: 0.4597 - val_accuracy: 0.7838\n",
      "Epoch 1356/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3906 - accuracy: 0.8194 - val_loss: 0.4698 - val_accuracy: 0.7706\n",
      "Epoch 1357/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3973 - accuracy: 0.8122 - val_loss: 0.4730 - val_accuracy: 0.7665\n",
      "Epoch 1358/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3971 - accuracy: 0.8122 - val_loss: 0.4612 - val_accuracy: 0.7780\n",
      "Epoch 1359/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3912 - accuracy: 0.8141 - val_loss: 0.4585 - val_accuracy: 0.7769\n",
      "Epoch 1360/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3910 - accuracy: 0.8169 - val_loss: 0.4720 - val_accuracy: 0.7752\n",
      "Epoch 1361/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3983 - accuracy: 0.8128 - val_loss: 0.4630 - val_accuracy: 0.7763\n",
      "Epoch 1362/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.3923 - accuracy: 0.8177 - val_loss: 0.4668 - val_accuracy: 0.7752\n",
      "Epoch 1363/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3961 - accuracy: 0.8178 - val_loss: 0.4685 - val_accuracy: 0.7792\n",
      "Epoch 1364/1500\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.3953 - accuracy: 0.8151 - val_loss: 0.4722 - val_accuracy: 0.7723\n",
      "Epoch 1365/1500\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.3917 - accuracy: 0.8146 - val_loss: 0.5112 - val_accuracy: 0.7556\n",
      "Epoch 1366/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3961 - accuracy: 0.8152 - val_loss: 0.4626 - val_accuracy: 0.7780\n",
      "Epoch 1367/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3958 - accuracy: 0.8168 - val_loss: 0.4654 - val_accuracy: 0.7723\n",
      "Epoch 1368/1500\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.3911 - accuracy: 0.8126 - val_loss: 0.4688 - val_accuracy: 0.7740\n",
      "Epoch 1369/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3948 - accuracy: 0.8161 - val_loss: 0.4669 - val_accuracy: 0.7740\n",
      "Epoch 1370/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3922 - accuracy: 0.8159 - val_loss: 0.4656 - val_accuracy: 0.7740\n",
      "Epoch 1371/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3917 - accuracy: 0.8169 - val_loss: 0.4683 - val_accuracy: 0.7763\n",
      "Epoch 1372/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3943 - accuracy: 0.8178 - val_loss: 0.4707 - val_accuracy: 0.7769\n",
      "Epoch 1373/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3944 - accuracy: 0.8142 - val_loss: 0.4702 - val_accuracy: 0.7775\n",
      "Epoch 1374/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3952 - accuracy: 0.8133 - val_loss: 0.4870 - val_accuracy: 0.7763\n",
      "Epoch 1375/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3925 - accuracy: 0.8109 - val_loss: 0.4837 - val_accuracy: 0.7694\n",
      "Epoch 1376/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3861 - accuracy: 0.8194 - val_loss: 0.4674 - val_accuracy: 0.7734\n",
      "Epoch 1377/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3915 - accuracy: 0.8128 - val_loss: 0.4784 - val_accuracy: 0.7769\n",
      "Epoch 1378/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3988 - accuracy: 0.8131 - val_loss: 0.4686 - val_accuracy: 0.7821\n",
      "Epoch 1379/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3927 - accuracy: 0.8171 - val_loss: 0.4650 - val_accuracy: 0.7711\n",
      "Epoch 1380/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3967 - accuracy: 0.8167 - val_loss: 0.4597 - val_accuracy: 0.7763\n",
      "Epoch 1381/1500\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.3871 - accuracy: 0.8197 - val_loss: 0.4661 - val_accuracy: 0.7792\n",
      "Epoch 1382/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3985 - accuracy: 0.8110 - val_loss: 0.4669 - val_accuracy: 0.7763\n",
      "Epoch 1383/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3962 - accuracy: 0.8073 - val_loss: 0.4718 - val_accuracy: 0.7769\n",
      "Epoch 1384/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3976 - accuracy: 0.8116 - val_loss: 0.4669 - val_accuracy: 0.7700\n",
      "Epoch 1385/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3990 - accuracy: 0.8162 - val_loss: 0.4679 - val_accuracy: 0.7757\n",
      "Epoch 1386/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3919 - accuracy: 0.8190 - val_loss: 0.4689 - val_accuracy: 0.7723\n",
      "Epoch 1387/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3953 - accuracy: 0.8145 - val_loss: 0.4837 - val_accuracy: 0.7677\n",
      "Epoch 1388/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3919 - accuracy: 0.8159 - val_loss: 0.4672 - val_accuracy: 0.7734\n",
      "Epoch 1389/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3920 - accuracy: 0.8159 - val_loss: 0.4618 - val_accuracy: 0.7769\n",
      "Epoch 1390/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3922 - accuracy: 0.8178 - val_loss: 0.4790 - val_accuracy: 0.7763\n",
      "Epoch 1391/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3910 - accuracy: 0.8151 - val_loss: 0.4697 - val_accuracy: 0.7723\n",
      "Epoch 1392/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3920 - accuracy: 0.8162 - val_loss: 0.4641 - val_accuracy: 0.7706\n",
      "Epoch 1393/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3990 - accuracy: 0.8138 - val_loss: 0.4671 - val_accuracy: 0.7809\n",
      "Epoch 1394/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.3938 - accuracy: 0.8125 - val_loss: 0.4711 - val_accuracy: 0.7729\n",
      "Epoch 1395/1500\n",
      "28/28 [==============================] - 2s 59ms/step - loss: 0.3904 - accuracy: 0.8135 - val_loss: 0.4739 - val_accuracy: 0.7711\n",
      "Epoch 1396/1500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3922 - accuracy: 0.8116 - val_loss: 0.4759 - val_accuracy: 0.7631\n",
      "Epoch 1397/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4039 - accuracy: 0.8090 - val_loss: 0.4924 - val_accuracy: 0.7832\n",
      "Epoch 1398/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3984 - accuracy: 0.8131 - val_loss: 0.4661 - val_accuracy: 0.7809\n",
      "Epoch 1399/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3914 - accuracy: 0.8181 - val_loss: 0.4751 - val_accuracy: 0.7717\n",
      "Epoch 1400/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3925 - accuracy: 0.8174 - val_loss: 0.4764 - val_accuracy: 0.7734\n",
      "Epoch 1401/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3935 - accuracy: 0.8136 - val_loss: 0.4617 - val_accuracy: 0.7763\n",
      "Epoch 1402/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3912 - accuracy: 0.8172 - val_loss: 0.4709 - val_accuracy: 0.7711\n",
      "Epoch 1403/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.3960 - accuracy: 0.8131 - val_loss: 0.4709 - val_accuracy: 0.7711\n",
      "Epoch 1404/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.3909 - accuracy: 0.8152 - val_loss: 0.4689 - val_accuracy: 0.7780\n",
      "Epoch 1405/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.3917 - accuracy: 0.8151 - val_loss: 0.4730 - val_accuracy: 0.7729\n",
      "Epoch 1406/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3888 - accuracy: 0.8191 - val_loss: 0.4869 - val_accuracy: 0.7723\n",
      "Epoch 1407/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3911 - accuracy: 0.8185 - val_loss: 0.4701 - val_accuracy: 0.7711\n",
      "Epoch 1408/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3895 - accuracy: 0.8139 - val_loss: 0.4895 - val_accuracy: 0.7798\n",
      "Epoch 1409/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3978 - accuracy: 0.8121 - val_loss: 0.4948 - val_accuracy: 0.7660\n",
      "Epoch 1410/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3886 - accuracy: 0.8161 - val_loss: 0.4684 - val_accuracy: 0.7729\n",
      "Epoch 1411/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3967 - accuracy: 0.8158 - val_loss: 0.4620 - val_accuracy: 0.7769\n",
      "Epoch 1412/1500\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.3952 - accuracy: 0.8112 - val_loss: 0.4628 - val_accuracy: 0.7752\n",
      "Epoch 1413/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3988 - accuracy: 0.8145 - val_loss: 0.4782 - val_accuracy: 0.7746\n",
      "Epoch 1414/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3982 - accuracy: 0.8136 - val_loss: 0.4673 - val_accuracy: 0.7752\n",
      "Epoch 1415/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3951 - accuracy: 0.8149 - val_loss: 0.4669 - val_accuracy: 0.7775\n",
      "Epoch 1416/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3993 - accuracy: 0.8131 - val_loss: 0.4622 - val_accuracy: 0.7769\n",
      "Epoch 1417/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3953 - accuracy: 0.8136 - val_loss: 0.4643 - val_accuracy: 0.7740\n",
      "Epoch 1418/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3955 - accuracy: 0.8154 - val_loss: 0.4639 - val_accuracy: 0.7752\n",
      "Epoch 1419/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3934 - accuracy: 0.8188 - val_loss: 0.4639 - val_accuracy: 0.7769\n",
      "Epoch 1420/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4016 - accuracy: 0.8139 - val_loss: 0.4650 - val_accuracy: 0.7780\n",
      "Epoch 1421/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3947 - accuracy: 0.8131 - val_loss: 0.4630 - val_accuracy: 0.7746\n",
      "Epoch 1422/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3875 - accuracy: 0.8174 - val_loss: 0.4634 - val_accuracy: 0.7734\n",
      "Epoch 1423/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3930 - accuracy: 0.8155 - val_loss: 0.4725 - val_accuracy: 0.7706\n",
      "Epoch 1424/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3938 - accuracy: 0.8179 - val_loss: 0.4648 - val_accuracy: 0.7809\n",
      "Epoch 1425/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3925 - accuracy: 0.8146 - val_loss: 0.4675 - val_accuracy: 0.7815\n",
      "Epoch 1426/1500\n",
      "28/28 [==============================] - 2s 64ms/step - loss: 0.3980 - accuracy: 0.8152 - val_loss: 0.4771 - val_accuracy: 0.7723\n",
      "Epoch 1427/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3921 - accuracy: 0.8144 - val_loss: 0.4749 - val_accuracy: 0.7665\n",
      "Epoch 1428/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3933 - accuracy: 0.8156 - val_loss: 0.4667 - val_accuracy: 0.7769\n",
      "Epoch 1429/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3856 - accuracy: 0.8201 - val_loss: 0.4749 - val_accuracy: 0.7706\n",
      "Epoch 1430/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3940 - accuracy: 0.8149 - val_loss: 0.4739 - val_accuracy: 0.7792\n",
      "Epoch 1431/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3863 - accuracy: 0.8172 - val_loss: 0.4765 - val_accuracy: 0.7786\n",
      "Epoch 1432/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3889 - accuracy: 0.8179 - val_loss: 0.4811 - val_accuracy: 0.7717\n",
      "Epoch 1433/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3870 - accuracy: 0.8165 - val_loss: 0.4844 - val_accuracy: 0.7734\n",
      "Epoch 1434/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3897 - accuracy: 0.8138 - val_loss: 0.4822 - val_accuracy: 0.7769\n",
      "Epoch 1435/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3922 - accuracy: 0.8138 - val_loss: 0.4698 - val_accuracy: 0.7729\n",
      "Epoch 1436/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3905 - accuracy: 0.8169 - val_loss: 0.4675 - val_accuracy: 0.7798\n",
      "Epoch 1437/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3904 - accuracy: 0.8169 - val_loss: 0.4646 - val_accuracy: 0.7757\n",
      "Epoch 1438/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3971 - accuracy: 0.8125 - val_loss: 0.4654 - val_accuracy: 0.7780\n",
      "Epoch 1439/1500\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.3919 - accuracy: 0.8177 - val_loss: 0.4689 - val_accuracy: 0.7855\n",
      "Epoch 1440/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3925 - accuracy: 0.8167 - val_loss: 0.4767 - val_accuracy: 0.7706\n",
      "Epoch 1441/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3997 - accuracy: 0.8141 - val_loss: 0.4806 - val_accuracy: 0.7815\n",
      "Epoch 1442/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3944 - accuracy: 0.8136 - val_loss: 0.4685 - val_accuracy: 0.7729\n",
      "Epoch 1443/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3936 - accuracy: 0.8162 - val_loss: 0.4732 - val_accuracy: 0.7729\n",
      "Epoch 1444/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3922 - accuracy: 0.8141 - val_loss: 0.4860 - val_accuracy: 0.7683\n",
      "Epoch 1445/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3907 - accuracy: 0.8182 - val_loss: 0.4767 - val_accuracy: 0.7683\n",
      "Epoch 1446/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3899 - accuracy: 0.8142 - val_loss: 0.4758 - val_accuracy: 0.7752\n",
      "Epoch 1447/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3902 - accuracy: 0.8187 - val_loss: 0.4725 - val_accuracy: 0.7798\n",
      "Epoch 1448/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3912 - accuracy: 0.8154 - val_loss: 0.4749 - val_accuracy: 0.7746\n",
      "Epoch 1449/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3881 - accuracy: 0.8220 - val_loss: 0.4732 - val_accuracy: 0.7809\n",
      "Epoch 1450/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3962 - accuracy: 0.8190 - val_loss: 0.4727 - val_accuracy: 0.7786\n",
      "Epoch 1451/1500\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.3855 - accuracy: 0.8172 - val_loss: 0.4757 - val_accuracy: 0.7775\n",
      "Epoch 1452/1500\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.3899 - accuracy: 0.8162 - val_loss: 0.4712 - val_accuracy: 0.7798\n",
      "Epoch 1453/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3927 - accuracy: 0.8119 - val_loss: 0.4790 - val_accuracy: 0.7734\n",
      "Epoch 1454/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3888 - accuracy: 0.8181 - val_loss: 0.4730 - val_accuracy: 0.7769\n",
      "Epoch 1455/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3937 - accuracy: 0.8181 - val_loss: 0.4726 - val_accuracy: 0.7769\n",
      "Epoch 1456/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3925 - accuracy: 0.8177 - val_loss: 0.4644 - val_accuracy: 0.7734\n",
      "Epoch 1457/1500\n",
      "28/28 [==============================] - 2s 62ms/step - loss: 0.3917 - accuracy: 0.8171 - val_loss: 0.4708 - val_accuracy: 0.7815\n",
      "Epoch 1458/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3933 - accuracy: 0.8116 - val_loss: 0.4791 - val_accuracy: 0.7769\n",
      "Epoch 1459/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3901 - accuracy: 0.8151 - val_loss: 0.4913 - val_accuracy: 0.7660\n",
      "Epoch 1460/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3896 - accuracy: 0.8168 - val_loss: 0.4680 - val_accuracy: 0.7780\n",
      "Epoch 1461/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3889 - accuracy: 0.8178 - val_loss: 0.4706 - val_accuracy: 0.7717\n",
      "Epoch 1462/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3874 - accuracy: 0.8198 - val_loss: 0.4668 - val_accuracy: 0.7723\n",
      "Epoch 1463/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3881 - accuracy: 0.8165 - val_loss: 0.4698 - val_accuracy: 0.7711\n",
      "Epoch 1464/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3919 - accuracy: 0.8168 - val_loss: 0.4838 - val_accuracy: 0.7706\n",
      "Epoch 1465/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3929 - accuracy: 0.8155 - val_loss: 0.4720 - val_accuracy: 0.7821\n",
      "Epoch 1466/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3856 - accuracy: 0.8184 - val_loss: 0.4700 - val_accuracy: 0.7763\n",
      "Epoch 1467/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3958 - accuracy: 0.8141 - val_loss: 0.4784 - val_accuracy: 0.7740\n",
      "Epoch 1468/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3862 - accuracy: 0.8220 - val_loss: 0.4710 - val_accuracy: 0.7740\n",
      "Epoch 1469/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3891 - accuracy: 0.8162 - val_loss: 0.4726 - val_accuracy: 0.7711\n",
      "Epoch 1470/1500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.3843 - accuracy: 0.8200 - val_loss: 0.4682 - val_accuracy: 0.7723\n",
      "Epoch 1471/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3933 - accuracy: 0.8139 - val_loss: 0.4707 - val_accuracy: 0.7786\n",
      "Epoch 1472/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3964 - accuracy: 0.8172 - val_loss: 0.4749 - val_accuracy: 0.7677\n",
      "Epoch 1473/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3873 - accuracy: 0.8182 - val_loss: 0.4714 - val_accuracy: 0.7757\n",
      "Epoch 1474/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3866 - accuracy: 0.8190 - val_loss: 0.4711 - val_accuracy: 0.7815\n",
      "Epoch 1475/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3914 - accuracy: 0.8181 - val_loss: 0.4801 - val_accuracy: 0.7700\n",
      "Epoch 1476/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3895 - accuracy: 0.8182 - val_loss: 0.4781 - val_accuracy: 0.7729\n",
      "Epoch 1477/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3887 - accuracy: 0.8188 - val_loss: 0.4770 - val_accuracy: 0.7757\n",
      "Epoch 1478/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3845 - accuracy: 0.8181 - val_loss: 0.4727 - val_accuracy: 0.7717\n",
      "Epoch 1479/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3867 - accuracy: 0.8220 - val_loss: 0.4743 - val_accuracy: 0.7700\n",
      "Epoch 1480/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3861 - accuracy: 0.8175 - val_loss: 0.4694 - val_accuracy: 0.7780\n",
      "Epoch 1481/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3932 - accuracy: 0.8136 - val_loss: 0.4715 - val_accuracy: 0.7792\n",
      "Epoch 1482/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3854 - accuracy: 0.8146 - val_loss: 0.4938 - val_accuracy: 0.7786\n",
      "Epoch 1483/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3887 - accuracy: 0.8187 - val_loss: 0.4871 - val_accuracy: 0.7683\n",
      "Epoch 1484/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3857 - accuracy: 0.8214 - val_loss: 0.4802 - val_accuracy: 0.7729\n",
      "Epoch 1485/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3861 - accuracy: 0.8217 - val_loss: 0.4756 - val_accuracy: 0.7729\n",
      "Epoch 1486/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3924 - accuracy: 0.8161 - val_loss: 0.4719 - val_accuracy: 0.7786\n",
      "Epoch 1487/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3883 - accuracy: 0.8158 - val_loss: 0.4800 - val_accuracy: 0.7740\n",
      "Epoch 1488/1500\n",
      "28/28 [==============================] - 2s 63ms/step - loss: 0.3902 - accuracy: 0.8146 - val_loss: 0.4814 - val_accuracy: 0.7723\n",
      "Epoch 1489/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3922 - accuracy: 0.8131 - val_loss: 0.4799 - val_accuracy: 0.7717\n",
      "Epoch 1490/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3936 - accuracy: 0.8171 - val_loss: 0.4786 - val_accuracy: 0.7671\n",
      "Epoch 1491/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3875 - accuracy: 0.8156 - val_loss: 0.4708 - val_accuracy: 0.7752\n",
      "Epoch 1492/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3917 - accuracy: 0.8129 - val_loss: 0.4682 - val_accuracy: 0.7752\n",
      "Epoch 1493/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3834 - accuracy: 0.8177 - val_loss: 0.4787 - val_accuracy: 0.7671\n",
      "Epoch 1494/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3883 - accuracy: 0.8159 - val_loss: 0.4819 - val_accuracy: 0.7717\n",
      "Epoch 1495/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3911 - accuracy: 0.8184 - val_loss: 0.4749 - val_accuracy: 0.7815\n",
      "Epoch 1496/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3899 - accuracy: 0.8133 - val_loss: 0.4743 - val_accuracy: 0.7740\n",
      "Epoch 1497/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3901 - accuracy: 0.8165 - val_loss: 0.4667 - val_accuracy: 0.7838\n",
      "Epoch 1498/1500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3951 - accuracy: 0.8122 - val_loss: 0.4754 - val_accuracy: 0.7729\n",
      "Epoch 1499/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3929 - accuracy: 0.8152 - val_loss: 0.4697 - val_accuracy: 0.7775\n",
      "Epoch 1500/1500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3862 - accuracy: 0.8139 - val_loss: 0.4670 - val_accuracy: 0.7763\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x,train_y,validation_data=(test_x,test_y),epochs=1500, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:44:30.488101Z",
     "iopub.status.busy": "2023-02-12T00:44:30.487726Z",
     "iopub.status.idle": "2023-02-12T00:44:31.440890Z",
     "shell.execute_reply": "2023-02-12T00:44:31.439998Z",
     "shell.execute_reply.started": "2023-02-12T00:44:30.488060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 1s 4ms/step - loss: 0.3746 - accuracy: 0.8197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3746030032634735, 0.8196721076965332]"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:44:31.443021Z",
     "iopub.status.busy": "2023-02-12T00:44:31.441988Z",
     "iopub.status.idle": "2023-02-12T00:44:31.753005Z",
     "shell.execute_reply": "2023-02-12T00:44:31.751729Z",
     "shell.execute_reply.started": "2023-02-12T00:44:31.442973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46700525283813477, 0.7763082385063171]"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:44:31.755536Z",
     "iopub.status.busy": "2023-02-12T00:44:31.755066Z",
     "iopub.status.idle": "2023-02-12T00:44:32.163457Z",
     "shell.execute_reply": "2023-02-12T00:44:32.162303Z",
     "shell.execute_reply.started": "2023-02-12T00:44:31.755482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Train\", \"Test\"], loc=\"upper left\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Train\", \"Test\"], loc=\"upper left\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:44:32.165383Z",
     "iopub.status.busy": "2023-02-12T00:44:32.164993Z",
     "iopub.status.idle": "2023-02-12T00:44:32.184017Z",
     "shell.execute_reply": "2023-02-12T00:44:32.182615Z",
     "shell.execute_reply.started": "2023-02-12T00:44:32.165348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>HomePlanet_Europa</th>\n",
       "      <th>HomePlanet_Mars</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Destination_PSO J318.5-22</th>\n",
       "      <th>Destination_TRAPPIST-1e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CryoSleep  RoomService     Spa  VRDeck  HomePlanet_Europa  HomePlanet_Mars  \\\n",
       "0          1          0.0     0.0     0.0                  0                0   \n",
       "1          0          0.0  2823.0     0.0                  0                0   \n",
       "2          1          0.0     0.0     0.0                  1                0   \n",
       "3          0          0.0   181.0   585.0                  1                0   \n",
       "4          0         10.0     0.0     0.0                  0                0   \n",
       "\n",
       "   Cabin_B  Cabin_C  Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_T  \\\n",
       "0        0        0        0        0        0        1        0   \n",
       "1        0        0        0        0        1        0        0   \n",
       "2        0        1        0        0        0        0        0   \n",
       "3        0        1        0        0        0        0        0   \n",
       "4        0        0        0        0        1        0        0   \n",
       "\n",
       "   Destination_PSO J318.5-22  Destination_TRAPPIST-1e  \n",
       "0                          0                        1  \n",
       "1                          0                        1  \n",
       "2                          0                        0  \n",
       "3                          0                        1  \n",
       "4                          0                        1  "
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:44:32.185664Z",
     "iopub.status.busy": "2023-02-12T00:44:32.185335Z",
     "iopub.status.idle": "2023-02-12T00:44:32.961506Z",
     "shell.execute_reply": "2023-02-12T00:44:32.960453Z",
     "shell.execute_reply.started": "2023-02-12T00:44:32.185634Z"
    }
   },
   "outputs": [],
   "source": [
    "tahmin = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:44:32.964207Z",
     "iopub.status.busy": "2023-02-12T00:44:32.963423Z",
     "iopub.status.idle": "2023-02-12T00:44:32.981060Z",
     "shell.execute_reply": "2023-02-12T00:44:32.979832Z",
     "shell.execute_reply.started": "2023-02-12T00:44:32.964159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded = [round(x[0]) for x in tahmin]\n",
    "rounded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:44:32.983558Z",
     "iopub.status.busy": "2023-02-12T00:44:32.983124Z",
     "iopub.status.idle": "2023-02-12T00:44:32.995271Z",
     "shell.execute_reply": "2023-02-12T00:44:32.993990Z",
     "shell.execute_reply.started": "2023-02-12T00:44:32.983520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4277"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:44:32.997343Z",
     "iopub.status.busy": "2023-02-12T00:44:32.996993Z",
     "iopub.status.idle": "2023-02-12T00:44:33.017666Z",
     "shell.execute_reply": "2023-02-12T00:44:33.016086Z",
     "shell.execute_reply.started": "2023-02-12T00:44:32.997313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01        False\n",
       "1     0018_01        False\n",
       "2     0019_01        False\n",
       "3     0021_01        False\n",
       "4     0023_01        False"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:44:33.019532Z",
     "iopub.status.busy": "2023-02-12T00:44:33.019091Z",
     "iopub.status.idle": "2023-02-12T00:44:33.026952Z",
     "shell.execute_reply": "2023-02-12T00:44:33.025926Z",
     "shell.execute_reply.started": "2023-02-12T00:44:33.019498Z"
    }
   },
   "outputs": [],
   "source": [
    "sample[\"Transported\"] = rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:44:33.028806Z",
     "iopub.status.busy": "2023-02-12T00:44:33.028473Z",
     "iopub.status.idle": "2023-02-12T00:44:33.044634Z",
     "shell.execute_reply": "2023-02-12T00:44:33.043441Z",
     "shell.execute_reply.started": "2023-02-12T00:44:33.028775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01            1\n",
       "1     0018_01            0\n",
       "2     0019_01            1\n",
       "3     0021_01            1\n",
       "4     0023_01            1"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:44:33.046615Z",
     "iopub.status.busy": "2023-02-12T00:44:33.045869Z",
     "iopub.status.idle": "2023-02-12T00:44:33.053220Z",
     "shell.execute_reply": "2023-02-12T00:44:33.052297Z",
     "shell.execute_reply.started": "2023-02-12T00:44:33.046581Z"
    }
   },
   "outputs": [],
   "source": [
    "sample.replace({1:True, 0:False}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T00:48:30.588978Z",
     "iopub.status.busy": "2023-02-12T00:48:30.588502Z",
     "iopub.status.idle": "2023-02-12T00:48:30.602134Z",
     "shell.execute_reply": "2023-02-12T00:48:30.600859Z",
     "shell.execute_reply.started": "2023-02-12T00:48:30.588943Z"
    }
   },
   "outputs": [],
   "source": [
    "sample.to_csv(\"my_pred1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
